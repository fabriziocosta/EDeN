#!/usr/bin/env python

DESCRIPTION = """
Explicit Decomposition with Neighborhood (EDeN) utility program.
Protease modelling driver. 


Note: the current implementation uses as estimator a regularized linear model
with stochastic  gradient descent (SGD) learning scheme: the gradient of the
loss is estimated each sample at  a time and the model is updated along the way
with a decreasing strength schedule (aka learning rate). """

EPILOG = """
Author: Fabrizio Costa
Copyright: 2015
License: GPL
Maintainer: Fabrizio Costa
Email: costa@informatik.uni-freiburg.de
Status: Production

Cite:  Costa, Fabrizio, and Kurt De Grave, 'Fast neighborhood subgraph pairwise
distance kernel', Proceedings of the 26th International Conference on Machine
Learning. 2010. """

import sys
import os
import random
import re
from time import time, clock
import multiprocessing as mp
import numpy as np
from itertools import tee, chain
from collections import defaultdict

import argparse
import logging
import logging.handlers
from eden.util import configure_logging
from eden.util import serialize_dict


from numpy.random import randint
from numpy.random import uniform

from sklearn.linear_model import SGDClassifier
from sklearn import metrics

from eden.graph import Vectorizer
from eden.util import save_output, store_matrix
from eden.converter.graph.node_link_data import node_link_data_to_eden


def load_data(fname):
    from eden.converter.fasta import fasta_to_sequence
    seqs = fasta_to_sequence(fname)
    return seqs


def pre_processor(seqs, **args):
    # insert landmark in the cleavage site after pos 4, in our case this means always in the middle position
    from eden.modifier.seq import seq_to_seq, mark_modifier
    seqs = seq_to_seq(seqs, modifier=mark_modifier, position=0.5, mark='%')
    seqs = seq_to_seq(seqs, modifier=mark_modifier, position=0.0, mark='@')
    seqs = seq_to_seq(seqs, modifier=mark_modifier, position=1.0, mark='*')
    # convert to graph
    from eden.converter.fasta import sequence_to_eden
    graphs = sequence_to_eden(seqs)
    return graphs


def pre_processor_init(n_iter):
    pre_processor_parameters = {}
    return pre_processor, pre_processor_parameters


def vectorizer_init(n_iter):
    vectorizer = Vectorizer()
    vectorizer_parameters = {'complexity': [2, 3, 4, 5, 6]}
    return vectorizer, vectorizer_parameters


def estimator_init(n_iter):
    estimator = SGDClassifier(average=True, class_weight='auto', shuffle=True)
    estimator_parameters = {'n_iter': randint(5, 200, size=n_iter),
                            'penalty': ['l1', 'l2', 'elasticnet'],
                            'l1_ratio': uniform(0.1, 0.9, size=n_iter),
                            'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],
                            'power_t': uniform(0.1, size=n_iter),
                            'alpha': [10 ** x for x in range(-8, 0)],
                            'eta0': [10 ** x for x in range(-4, -1)],
                            'learning_rate': ["invscaling", "constant", "optimal"],
                            'n_jobs': [-1]}
    return estimator, estimator_parameters


def main_fit(args):
    iterator = load_data(args.input_file)
    from itertools import tee
    seqs, seqs_ = tee(iterator)
    pos_train_iterator = seqs
    from eden.modifier.seq import seq_to_seq, shuffle_modifier
    neg_train_iterator = seq_to_seq(seqs_, modifier=shuffle_modifier, times=args.negative_ratio, order=args.shuffle_order)

    pre_processor, pre_processor_parameters = pre_processor_init(args.n_iter)
    vectorizer, vectorizer_parameters = vectorizer_init(args.n_iter)
    estimator, estimator_parameters = estimator_init(args.n_iter)
    from eden.model import ActiveLearningBinaryClassificationModel
    model = ActiveLearningBinaryClassificationModel(pre_processor=pre_processor,
                                                    estimator=estimator,
                                                    vectorizer=vectorizer,
                                                    fit_vectorizer=args.fit_vectorizer,
                                                    n_jobs=args.n_jobs,
                                                    n_blocks=args.n_blocks,
                                                    block_size=args.block_size,
                                                    pre_processor_n_jobs=args.pre_processor_n_jobs,
                                                    pre_processor_n_blocks=args.pre_processor_n_blocks,
                                                    pre_processor_block_size=args.pre_processor_block_size,
                                                    random_state=args.random_state)
    # save model
    if not os.path.exists(args.output_dir_path):
        os.mkdir(args.output_dir_path)
    full_out_file_name = os.path.join(args.output_dir_path, args.model_file)

    model.optimize(pos_train_iterator, neg_train_iterator,
                   model_name=full_out_file_name,
                   n_iter=args.n_iter,
                   pre_processor_parameters=pre_processor_parameters,
                   vectorizer_parameters=vectorizer_parameters,
                   estimator_parameters=estimator_parameters,
                   n_active_learning_iterations=args.n_active_learning_iterations,
                   size_positive=args.size_positive,
                   size_negative=args.size_negative,
                   lower_bound_threshold_positive=args.lower_bound_threshold_positive,
                   upper_bound_threshold_positive=args.upper_bound_threshold_positive,
                   lower_bound_threshold_negative=args.lower_bound_threshold_negative,
                   upper_bound_threshold_negative=args.upper_bound_threshold_negative,
                   max_total_time=args.max_total_time,
                   cv=args.cv,
                   scoring=args.scoring,
                   score_func=lambda u, s: u - s,
                   two_steps_optimization=args.two_steps_optimization)


def main_estimate(args):
    iterator = load_data(args.input_file)
    from itertools import tee
    seqs, seqs_ = tee(iterator)
    pos_train_iterator = seqs
    from eden.modifier.seq import seq_to_seq, shuffle_modifier
    neg_train_iterator = seq_to_seq(seqs_, modifier=shuffle_modifier, times=args.negative_ratio, order=args.shuffle_order)

    from eden.model import ActiveLearningBinaryClassificationModel
    model = ActiveLearningBinaryClassificationModel()
    model.load(args.model_file)
    logger.info(model.get_parameters())
    apr, rocauc = model.estimate(pos_test_iterator, neg_test_iterator)


def main_predict(args):
    iterator = load_data(args.input_file)
    from eden.model import ActiveLearningBinaryClassificationModel
    model = ActiveLearningBinaryClassificationModel()
    model.load(args.model_file)
    predictions = model.decision_function(iterator)
    text = []
    for p in predictions:
        text.append(str(p) + "\n")
    save_output(text=text, output_dir_path=args.output_dir_path, out_file_name='predictions.txt')
    text = []
    for p in predictions:
        if p > 0:
            prediction = 1
        else:
            prediction = -1
        text.append(str(prediction) + "\n")
    save_output(text=text, output_dir_path=args.output_dir_path, out_file_name='classifications.txt')


def main_matrix(args):
    iterator = load_data(args.input_file)
    from eden.model import ActiveLearningBinaryClassificationModel
    model = ActiveLearningBinaryClassificationModel()
    model.load(args.model_file)
    X = model._data_matrix(iterator)
    K = metrics.pairwise.pairwise_kernels(X, metric='linear')
    store_matrix(matrix=K, output_dir_path=args.output_dir_path, out_file_name='Gram_matrix', output_format=args.output_format)


def main_feature(args):
    iterator = load_data(args.input_file)
    from eden.model import ActiveLearningBinaryClassificationModel
    model = ActiveLearningBinaryClassificationModel()
    model.load(args.model_file)
    X = model._data_matrix(iterator)
    store_matrix(matrix=X, output_dir_path=args.output_dir_path, out_file_name='data_matrix', output_format=args.output_format)


def main(args):
    if args.which == 'fit':
        main_fit(args)
    elif args.which == 'estimate':
        main_estimate(args)
    elif args.which == 'predict':
        main_predict(args)
    elif args.which == 'matrix':
        main_matrix(args)
    elif args.which == 'feature':
        main_feature(args)
    else:
        raise Exception('Unknown mode: %s' % args.which)


if __name__ == "__main__":
    class DefaultsRawDescriptionHelpFormatter(argparse.ArgumentDefaultsHelpFormatter, argparse.RawDescriptionHelpFormatter):
        # To join the behaviour of RawDescriptionHelpFormatter with that of ArgumentDefaultsHelpFormatter
        pass

    start_time = time()
    parser = argparse.ArgumentParser(description=DESCRIPTION, epilog=EPILOG, formatter_class=DefaultsRawDescriptionHelpFormatter)
    parser.add_argument('--version', action='version', version='0.1')
    parser.add_argument("-v", "--verbosity",
                        action="count",
                        help="Increase output verbosity")
    parser.add_argument("-x", "--no-logging",
                        dest="no_logging",
                        help="If set, do not log on file.",
                        action="store_true")

    subparsers = parser.add_subparsers(help='commands')
    # fit commands
    fit_parser = subparsers.add_parser('fit', help='Fit commands', formatter_class=DefaultsRawDescriptionHelpFormatter)
    fit_parser.set_defaults(which='fit')
    fit_parser.add_argument("-i", "--input-file",
                            dest="input_file",
                            help="Path to FASTA file containing input sequences.",
                            required=True)
    fit_parser.add_argument("-o", "--output-dir",
                            dest="output_dir_path",
                            help="Path to output directory.",
                            default="out")
    fit_parser.add_argument("-m", "--model-file",
                            dest="model_file",
                            help="Model file name. Note: it will be located in the output directory.",
                            default="model")
    fit_parser.add_argument("--negative-ratio",
                            dest="negative_ratio",
                            type=int,
                            help="Relative size ration for the randomly permuted negative instances w.r.t. the positive instances.",
                            default=2)
    fit_parser.add_argument("--shuffle-order",
                            dest="shuffle_order",
                            type=int,
                            help="Order of the k-mer for the random shuffling procedure.",
                            default=2)
    fit_parser.add_argument("-e", "--n-iter",
                            dest="n_iter",
                            type=int,
                            help="Number of randomly generated hyper parameter configurations tried during the discriminative model optimization. A value of 1 implies using the estimator default values.",
                            default=1)
    fit_parser.add_argument("--n-active-learning-iterations",
                            dest="n_active_learning_iterations",
                            type=int,
                            help="Number of iterations in the active lerning cycle. A value of 0 means to avoid active learning.",
                            default=0)
    fit_parser.add_argument("--size-positive",
                            dest="size_positive",
                            type=int,
                            help="Number of positive instances that have to be sampled in the active lerning cycle. A value of -1 means to use all instances, i.e. not to use active learning for the positive instances.",
                            default=-1)
    fit_parser.add_argument("--size-negative",
                            dest="size_negative",
                            type=int,
                            help="Number of negative instances that have to be sampled in the active lerning cycle. A value of -1 means to use all instances, i.e. not to use active learning for the negative instances.",
                            default=-1)
    fit_parser.add_argument("--lower-bound-threshold-positive",
                            dest="lower_bound_threshold_positive",
                            type=int,
                            help="Value of the score threshold to determine when to accept positive instances: positive instances with a score higher than the specified value will be accepted as candidates.",
                            default=-1)
    fit_parser.add_argument("--lower-bound-threshold-negative",
                            dest="lower_bound_threshold_negative",
                            type=int,
                            help="Value of the score threshold to determine when to accept negative instances: negative instances with a score higher than the specified value will be accepted as candidates.",
                            default=-1)
    fit_parser.add_argument("--upper-bound-threshold-positive",
                            dest="upper_bound_threshold_positive",
                            type=int,
                            help="Value of the score threshold to determine when to accept positive instances: positive instances with a score lower than the specified value will be accepted as candidates.",
                            default=1)
    fit_parser.add_argument("--upper-bound-threshold-negative",
                            dest="upper_bound_threshold_negative",
                            type=int,
                            help="Value of the score threshold to determine when to accept negative instances: negative instances with a score lower than the specified value will be accepted as candidates.",
                            default=1)
    fit_parser.add_argument("--fit-vectorizer",
                            dest="fit_vectorizer",
                            help="If set, activate the fitting procedure for the vectorizer on positive instances only.",
                            action="store_true")
    fit_parser.add_argument("--max-total-time",
                            dest="max_total_time",
                            type=int,
                            help="Maximal number of seconds for the duration of the optimization phase. After that the procedure is forcefully stopped. A value of -1 means no time limit.",
                            default=-1)
    fit_parser.add_argument("--two-steps-optimization",
                            dest="two_steps_optimization",
                            help="If set, activate a refinement procedure anfter n_iter/2 steps that samples only among the parameters that have previously improved the results.",
                            action="store_true")
    fit_parser.add_argument("--scoring", choices=['accuracy', 'roc_auc', 'average_precision', 'f1', 'f1_micro', 'f1_macro', 'f1_weighted', 'f1_samples', 'log_loss', 'precision', 'recall'],
                            help="The scoring strategy for evaluating in cross validation the quality of a hyper parameter combination.",
                            default='roc_auc')
    fit_parser.add_argument("--cv",
                            type=int,
                            help="Cross validation size.",
                            default=10)
    fit_parser.add_argument("-B", "--nbits",
                            type=int,
                            help="Number of bits used to express the graph kernel features. A value of 20 corresponds to 2**20=1 million possible features.",
                            default=20)
    fit_parser.add_argument("-j", "--n-jobs",
                            dest="n_jobs",
                            type=int,
                            help="Number of cores to use in multiprocessing.",
                            default=1)
    fit_parser.add_argument("-k", "-block-size",
                            dest="block_size",
                            type=int,
                            help="Number of instances per block for the multiprocessing elaboration.",
                            default=None)
    fit_parser.add_argument("-b", "--n-blocks",
                            dest="n_blocks",
                            type=int,
                            help="Number of blocks in which to divide the input for the multiprocessing elaboration.",
                            default=8)
    fit_parser.add_argument("--pre-processor-n-jobs",
                            dest="pre_processor_n_jobs",
                            type=int,
                            help="Number of cores to use in multiprocessing.",
                            default=1)
    fit_parser.add_argument("--pre-processor-n-blocks",
                            dest="pre_processor_n_blocks",
                            type=int,
                            help="Number of blocks in which to divide the input for the multiprocessing elaboration.",
                            default=8)
    fit_parser.add_argument("--pre-processor-block-size",
                            dest="pre_processor_block_size",
                            type=int,
                            help="Number of instances per block for the multiprocessing elaboration.",
                            default=None)
    fit_parser.add_argument("-r", "--random-state",
                            dest="random_state",
                            type=int,
                            help="Random seed.",
                            default=1)

    # estimate commands
    estimate_parser = subparsers.add_parser('estimate', help='Estimate commands', formatter_class=DefaultsRawDescriptionHelpFormatter)
    estimate_parser.set_defaults(which='estimate')
    estimate_parser.add_argument("-i", "--input-file",
                                 dest="input_file",
                                 help="Path to FASTA file containing input sequences.",
                                 required=True)
    estimate_parser.add_argument("-m", "--model-file",
                                 dest="model_file",
                                 help="Path to a fit model file.",
                                 required=True)
    estimate_parser.add_argument("-o", "--output-dir",
                                 dest="output_dir_path",
                                 help="Path to output directory.",
                                 default="out")

    # base parser
    base_parser = argparse.ArgumentParser(add_help=False)
    base_parser.add_argument("-i", "--input-file",
                             dest="input_file",
                             help="Path to networkx JSON file containing input graphs.",
                             required=True)
    base_parser.add_argument("-m", "--model-file",
                             dest="model_file",
                             help="Path to a fit model file.",
                             default="model")
    base_parser.add_argument("-o", "--output-dir",
                             dest="output_dir_path",
                             help="Path to output directory.",
                             default="out")

    # predict commands
    predict_parser = subparsers.add_parser('predict',
                                           help='Predict commands',
                                           parents=[base_parser],
                                           formatter_class=DefaultsRawDescriptionHelpFormatter)
    predict_parser.set_defaults(which='predict')

    # matrix commands
    matrix_parser = subparsers.add_parser('matrix',
                                          help='Matrix commands',
                                          parents=[base_parser],
                                          formatter_class=DefaultsRawDescriptionHelpFormatter)
    matrix_parser.set_defaults(which='matrix')
    matrix_parser.add_argument("-t", "--output-format",  choices=["text", "numpy", "MatrixMarket", "joblib"],
                               dest="output_format",
                               help="Output file format.",
                               default="MatrixMarket")

    # feature commands
    feature_parser = subparsers.add_parser('feature',
                                           help='Feature commands',
                                           parents=[base_parser],
                                           formatter_class=DefaultsRawDescriptionHelpFormatter)
    feature_parser.set_defaults(which='feature')
    feature_parser.add_argument("-t", "--output-format",  choices=["text", "numpy", "MatrixMarket", "joblib"],
                                dest="output_format",
                                help="Output file format.",
                                default="MatrixMarket")

    args = parser.parse_args()

    if args.no_logging:
        logger = configure_logging(verbosity=args.verbosity)
    else:
        logger = configure_logging(verbosity=args.verbosity, filename='%s.log' % (os.path.basename(__file__)))
    logger.debug('-' * 80)
    logger.debug('Program: %s' % os.path.basename(__file__))
    logger.debug('Called with parameters:\n %s' % serialize_dict(args.__dict__))
    try:
        main(args)
    except Exception:
        import datetime
        curr_time = datetime.datetime.now().strftime("%A, %d. %B %Y %I:%M%p")
        logger.exception("Program run failed on %s" % curr_time)
    finally:
        end_time = time()
        logger.info('Elapsed time: %.1f sec', end_time - start_time)
