#!/usr/bin/env python

DESCRIPTION = """
Explicit Decomposition with Neighborhood (EDeN) utility program.
Model driver. 


Note: the current implementation uses as estimator a regularized linear model
with stochastic  gradient descent (SGD) learning scheme: the gradient of the
loss is estimated each sample at  a time and the model is updated along the way
with a decreasing strength schedule (aka learning rate). """

EPILOG = """
Author: Fabrizio Costa
Copyright: 2015
License: GPL
Maintainer: Fabrizio Costa
Email: costa@informatik.uni-freiburg.de
Status: Production

Cite:  Costa, Fabrizio, and Kurt De Grave, 'Fast neighborhood subgraph pairwise
distance kernel', Proceedings of the 26th International Conference on Machine
Learning. 2010. """

import sys
import os
import random
import re
from time import time, clock
import multiprocessing as mp
import numpy as np
from itertools import tee, chain
from collections import defaultdict

import argparse
import logging
import logging.handlers
from eden.util import configure_logging


from numpy.random import randint
from numpy.random import uniform

from sklearn.linear_model import SGDClassifier
from sklearn import metrics

from eden.model import ActiveLearningBinaryClassificationModel
from eden.graph import Vectorizer
from eden.util import save_output, store_matrix
from eden.converter.graph.node_link_data import node_link_data_to_eden


def load_data(fname):
    iterator = node_link_data_to_eden(fname)
    return iterator


def null_pre_processor(graphs, **args):
    return graphs


def pre_processor_init(n_iter):
    pre_processor = null_pre_processor
    pre_processor_parameters = {}
    return pre_processor, pre_processor_parameters


def vectorizer_init(n_iter):
    vectorizer = Vectorizer()
    vectorizer_parameters = {'complexity': [2, 3, 4]}
    return vectorizer, vectorizer_parameters


def estimator_init(n_iter):
    estimator = SGDClassifier(average=True, class_weight='auto', shuffle=True)
    estimator_parameters = {'n_iter': randint(5, 200, size=n_iter),
                            'penalty': ['l1', 'l2', 'elasticnet'],
                            'l1_ratio': uniform(0.1, 0.9, size=n_iter),
                            'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],
                            'power_t': uniform(0.1, size=n_iter),
                            'alpha': [10 ** x for x in range(-8, 0)],
                            'eta0': [10 ** x for x in range(-4, -1)],
                            'learning_rate': ["invscaling", "constant", "optimal"],
                            'n_jobs': [-1]}
    return estimator, estimator_parameters


def main_fit(args):
    pos_train_iterator = load_data(args.positive_input_file)
    neg_train_iterator = load_data(args.negative_input_file)
    pre_processor, pre_processor_parameters = pre_processor_init(args.n_iter)
    vectorizer, vectorizer_parameters = vectorizer_init(args.n_iter)
    estimator, estimator_parameters = estimator_init(args.n_iter)
    model = ActiveLearningBinaryClassificationModel(pre_processor=pre_processor,
                                                    estimator=estimator,
                                                    vectorizer=vectorizer,
                                                    n_jobs=args.n_jobs,
                                                    n_blocks=args.n_blocks,
                                                    block_size=args.block_size,
                                                    pre_processor_n_jobs=args.pre_processor_n_jobs,
                                                    pre_processor_n_blocks=args.pre_processor_n_blocks,
                                                    random_state=args.random_state)
    # save model
    if not os.path.exists(args.output_dir_path):
        os.mkdir(args.output_dir_path)
    full_out_file_name = os.path.join(args.output_dir_path, args.model_file)

    model.optimize(pos_train_iterator, neg_train_iterator,
                   model_name=full_out_file_name,
                   n_iter=args.n_iter,
                   verbosity=args.verbosity,
                   pre_processor_parameters=pre_processor_parameters,
                   vectorizer_parameters=vectorizer_parameters,
                   estimator_parameters=estimator_parameters)


def main_estimate(args):
    pos_test_iterator = load_data(args.positive_input_file)
    neg_test_iterator = load_data(args.negative_input_file)
    model = ActiveLearningBinaryClassificationModel()
    model.load(args.model_file)
    model.print_model_parameter_configuration()
    apr, rocauc = model.estimate(pos_test_iterator, neg_test_iterator)


def main_predict(args):
    iterator = load_data(args.input_file)
    model = ActiveLearningBinaryClassificationModel()
    model.load(args.model_file)
    predictions = model.decision_function(iterator)
    text = []
    for p in predictions:
        text.append(str(p) + "\n")
    save_output(text=text, output_dir_path=args.output_dir_path, out_file_name='predictions.txt')
    text = []
    for p in predictions:
        if p > 0:
            prediction = 1
        else:
            prediction = -1
        text.append(str(prediction) + "\n")
    save_output(text=text, output_dir_path=args.output_dir_path, out_file_name='classifications.txt')


def main_matrix(args):
    iterator = load_data(args.input_file)
    model = ActiveLearningBinaryClassificationModel()
    model.load(args.model_file)
    X = model._data_matrix(iterator)
    K = metrics.pairwise.pairwise_kernels(X, metric='linear')
    store_matrix(matrix=K, output_dir_path=args.output_dir_path, out_file_name='Gram_matrix', output_format=args.output_format)


def main_feature(args):
    iterator = load_data(args.input_file)
    model = ActiveLearningBinaryClassificationModel()
    model.load(args.model_file)
    X = model._data_matrix(iterator)
    store_matrix(matrix=X, output_dir_path=args.output_dir_path, out_file_name='data_matrix', output_format=args.output_format)


def main(args):
    if args.which == 'fit':
        main_fit(args)
    elif args.which == 'estimate':
        main_estimate(args)
    elif args.which == 'predict':
        main_predict(args)
    elif args.which == 'matrix':
        main_matrix(args)
    elif args.which == 'feature':
        main_feature(args)
    else:
        raise Exception('Unknown mode: %s' % args.which)


if __name__ == "__main__":
    class DefaultsRawDescriptionHelpFormatter(argparse.ArgumentDefaultsHelpFormatter, argparse.RawDescriptionHelpFormatter):
        # To join the behaviour of RawDescriptionHelpFormatter with that of ArgumentDefaultsHelpFormatter
        pass

    start_time = time()
    parser = argparse.ArgumentParser(description=DESCRIPTION, epilog=EPILOG, formatter_class=DefaultsRawDescriptionHelpFormatter)
    parser.add_argument('--version', action='version', version='0.1')
    parser.add_argument("-v", "--verbosity",
                        action="count",
                        help="Increase output verbosity")

    subparsers = parser.add_subparsers(help='commands')
    # fit commands
    fit_parser = subparsers.add_parser('fit', help='Fit commands', formatter_class=DefaultsRawDescriptionHelpFormatter)
    fit_parser.set_defaults(which='fit')
    fit_parser.add_argument("-p", "--positive-input-file",
                            dest="positive_input_file",
                            help="Path to networkx JSON file containing graphs for the positive class.",
                            required=True)
    fit_parser.add_argument("-n", "--negative-input-file",
                            dest="negative_input_file",
                            help="Path to networkx JSON file containing graphs for the negative class.",
                            required=True)
    fit_parser.add_argument("-o", "--output-dir",
                            dest="output_dir_path",
                            help="Path to output directory.",
                            default="out")
    fit_parser.add_argument("-m", "--model-file",
                            dest="model_file",
                            help="Model file name. Note: it will be located in the output directory.",
                            default="model",
                            required=True)
    fit_parser.add_argument("-B", "--nbits",
                            type=int,
                            help="Number of bits used to express the graph kernel features. A value of 20 corresponds to 2**20=1 million possible features.",
                            default=20)
    fit_parser.add_argument("-e", "--n-iter",
                            dest="n_iter",
                            type=int,
                            help="Number of randomly generated hyper parameter configurations tried during the discriminative model optimization. A value of 1 implies using the estimator default values.",
                            default=1)
    fit_parser.add_argument("-j", "--n-jobs",
                            dest="n_jobs",
                            type=int,
                            help="Number of cores to use in multiprocessing.",
                            default=2)
    fit_parser.add_argument("-k", "-block-size",
                            dest="block_size",
                            type=int,
                            help="Number of instances per block for the multiprocessing elaboration.",
                            default=None)
    fit_parser.add_argument("-b", "--n-blocks",
                            dest="n_blocks",
                            type=int,
                            help="Number of blocks in which to divide the input for the multiprocessing elaboration.",
                            default=8)
    fit_parser.add_argument("-J", "--pre-processor-n-jobs",
                            dest="pre_processor_n_jobs",
                            type=int,
                            help="Number of cores to use in multiprocessing.",
                            default=1)
    fit_parser.add_argument("-r", "--random-state",
                            dest="random_state",
                            type=int,
                            help="Random seed.",
                            default=1)
    fit_parser.add_argument("-L", "--pre-processor-n-blocks",
                            dest="pre_processor_n_blocks",
                            type=int,
                            help="Number of blocks in which to divide the input for the multiprocessing elaboration.",
                            default=8)

    # estimate commands
    estimate_parser = subparsers.add_parser('estimate', help='Estimate commands', formatter_class=DefaultsRawDescriptionHelpFormatter)
    estimate_parser.set_defaults(which='estimate')
    estimate_parser.add_argument("-p", "--positive-input-file",
                                 dest="positive_input_file",
                                 help="Path to networkx JSON file containing graphs for the positive class.",
                                 required=True)
    estimate_parser.add_argument("-n", "--negative-input-file",
                                 dest="negative_input_file",
                                 help="Path to networkx JSON file containing graphs for the negative class.",
                                 required=True)
    estimate_parser.add_argument("-m", "--model-file",
                                 dest="model_file",
                                 help="Path to a fit model file.",
                                 required=True)
    estimate_parser.add_argument("-o", "--output-dir",
                                 dest="output_dir_path",
                                 help="Path to output directory.",
                                 default="out")

    # predict commands
    predict_parser = subparsers.add_parser('predict', help='Predict commands', formatter_class=DefaultsRawDescriptionHelpFormatter)
    predict_parser.set_defaults(which='predict')
    predict_parser.add_argument("-i", "--input-file",
                                dest="input_file",
                                help="Path to networkx JSON file containing input graphs.",
                                required=True)
    predict_parser.add_argument("-m", "--model-file",
                                dest="model_file",
                                help="Path to a fit model file.",
                                required=True)
    predict_parser.add_argument("-o", "--output-dir",
                                dest="output_dir_path",
                                help="Path to output directory.",
                                default="out")

    # matrix commands
    matrix_parser = subparsers.add_parser('matrix', help='Matrix commands', formatter_class=DefaultsRawDescriptionHelpFormatter)
    matrix_parser.set_defaults(which='matrix')
    matrix_parser.add_argument("-i", "--input-file",
                               dest="input_file",
                               help="Path to networkx JSON file containing input graphs.",
                               required=True)
    matrix_parser.add_argument("-m", "--model-file",
                               dest="model_file",
                               help="Path to a fit model file.",
                               required=True)
    matrix_parser.add_argument("-o", "--output-dir",
                               dest="output_dir_path",
                               help="Path to output directory.",
                               default="out")
    matrix_parser.add_argument("-t", "--output-format",  choices=["text", "numpy", "MatrixMarket", "joblib"],
                               dest="output_format",
                               help="Output file format.",
                               default="MatrixMarket")

    # feature commands
    feature_parser = subparsers.add_parser('feature', help='Feature commands', formatter_class=DefaultsRawDescriptionHelpFormatter)
    feature_parser.set_defaults(which='feature')
    feature_parser.add_argument("-i", "--input-file",
                                dest="input_file",
                                help="Path to networkx JSON file containing input graphs.",
                                required=True)
    feature_parser.add_argument("-m", "--model-file",
                                dest="model_file",
                                help="Path to a fit model file.",
                                required=True)
    feature_parser.add_argument("-o", "--output-dir",
                                dest="output_dir_path",
                                help="Path to output directory.",
                                default="out")
    feature_parser.add_argument("-t", "--output-format",  choices=["text", "numpy", "MatrixMarket", "joblib"],
                                dest="output_format",
                                help="Output file format.",
                                default="MatrixMarket")

    args = parser.parse_args()

    logger = configure_logging(verbosity=args.verbosity, filename='%s.log' % (os.path.basename(__file__)))

    logger.debug('-' * 80)
    logger.debug('Program: %s' % os.path.basename(__file__))
    logger.debug('Called with parameters: %s' % args.__dict__)
    try:
        main(args)
    except Exception:
        import datetime
        curr_time = datetime.datetime.now().strftime("%A, %d. %B %Y %I:%M%p")
        logger.exception("Program run failed on %s" % curr_time)
    finally:
        end_time = time()
        logger.info('Elapsed time: %.1f sec', end_time - start_time)
