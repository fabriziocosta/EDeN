#!/usr/bin/env python

DESCRIPTION = """
Explicit Decomposition with Neighborhood (EDeN) utility program.
Model driver. 


Note: the current implementation uses as estimator a regularized linear model
with stochastic  gradient descent (SGD) learning scheme: the gradient of the
loss is estimated each sample at  a time and the model is updated along the way
with a decreasing strength schedule (aka learning rate). """

EPILOG = """
Author: Fabrizio Costa
Copyright: 2015
License: GPL
Maintainer: Fabrizio Costa
Email: costa@informatik.uni-freiburg.de
Status: Production

Cite:  Costa, Fabrizio, and Kurt De Grave, 'Fast neighborhood subgraph pairwise
distance kernel', Proceedings of the 26th International Conference on Machine
Learning. 2010. """

import sys
import os
import random
import re
from time import time, clock
import multiprocessing as mp
import numpy as np
from itertools import tee, chain
from collections import defaultdict

import argparse
import logging
import logging.handlers

from numpy.random import randint
from numpy.random import uniform

from sklearn.linear_model import SGDClassifier

from eden.model import ActiveLearningBinaryClassificationModel
from eden.graph import Vectorizer

from eden.util import setup
from eden.util import save_output

from eden.converter.graph.node_link_data import node_link_data_to_eden


def load_data(fname):
    iterator = node_link_data_to_eden(fname)
    return iterator


def null_pre_processor(graphs, **args):
    return graphs


def pre_processor_init(n_iter):
    pre_processor = null_pre_processor
    pre_processor_parameters = {}
    return pre_processor, pre_processor_parameters


def vectorizer_init(n_iter):
    vectorizer = Vectorizer()
    vectorizer_parameters = {'complexity': [2, 3, 4]}
    return vectorizer, vectorizer_parameters


def estimator_init(n_iter):
    estimator = SGDClassifier(average=True, class_weight='auto', shuffle=True)
    estimator_parameters = {'n_iter': randint(5, 200, size=n_iter),
                            'penalty': ['l1', 'l2', 'elasticnet'],
                            'l1_ratio': uniform(0.1, 0.9, size=n_iter),
                            'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],
                            'power_t': uniform(0.1, size=n_iter),
                            'alpha': [10 ** x for x in range(-8, 0)],
                            'eta0': [10 ** x for x in range(-4, -1)],
                            'learning_rate': ["invscaling", "constant", "optimal"],
                            'n_jobs': [-1]}
    return estimator, estimator_parameters


def main_fit(args):
    pos_train_iterator = load_data(args.positive_input_file)
    neg_train_iterator = load_data(args.negative_input_file)
    pre_processor, pre_processor_parameters = pre_processor_init(args.n_iter)
    vectorizer, vectorizer_parameters = vectorizer_init(args.n_iter)
    estimator, estimator_parameters = estimator_init(args.n_iter)
    model = ActiveLearningBinaryClassificationModel(pre_processor=pre_processor,
                                                    estimator=estimator,
                                                    vectorizer=vectorizer,
                                                    n_jobs=args.n_jobs,
                                                    n_blocks=args.n_blocks,
                                                    pre_processor_n_jobs=args.pre_processor_n_jobs,
                                                    pre_processor_n_blocks=args.pre_processor_n_blocks,
                                                    random_state=args.random_state)
    model.optimize(pos_train_iterator, neg_train_iterator,
                   model_name=args.model_file,
                   n_iter=args.n_iter,
                   verbose=args.verbosity,
                   pre_processor_parameters=pre_processor_parameters,
                   vectorizer_parameters=vectorizer_parameters,
                   estimator_parameters=estimator_parameters)


def main_predict(args):
    iterator = load_data(args.input_file)
    model = ActiveLearningBinaryClassificationModel()
    model.load(args.model_file)
    if args.print_estimate:
        model.print_model_parameter_configuration()
        model.estimate(pos_test_graphs, neg_test_graphs)
    predictions = model.decision_function(iterator)
    text = []
    for p in predictions:
        text.append(str(p) + "\n")
    save_output(text=text, output_dir_path=args.output_dir_path, out_file_name='predictions.txt', logger=logger)


def main_matrix(args):
    iterator = load_data(args.input_file)
    pass

def main_feature(args):
    iterator = load_data(args.input_file)
    pass


def main(args):
    if args.which == 'fit':
        main_fit(args)
    elif args.which == 'predict':
        main_predict(args)
    elif args.which == 'matrix':
        main_matrix(args)
    elif args.which == 'feature':
        main_feature(args)
    else:
        raise Exception('Unknown mode: %s' % args.which)


if __name__ == "__main__":
    start_time = time()
    parser = argparse.ArgumentParser(description=DESCRIPTION, epilog=EPILOG, formatter_class=argparse.RawDescriptionHelpFormatter)
    parser.add_argument('--version', action='version', version='0.1')
    parser.add_argument("-v", "--verbosity",
                        action="count",
                        help="Increase output verbosity")

    subparsers = parser.add_subparsers(help='commands')
    # fit commands
    fit_parser = subparsers.add_parser('fit', help='Fit commands')
    fit_parser.set_defaults(which='fit')
    fit_parser.add_argument("-p", "--positive-input-file",
                            dest="positive_input_file",
                            help="Path to networkx JSON file containing graphs for the positive class.",
                            required=True)
    fit_parser.add_argument("-n", "--negative-input-file",
                            dest="negative_input_file",
                            help="Path to networkx JSON file containing graphs for the negative class.",
                            required=True)
    fit_parser.add_argument("-o", "--output-dir",
                            dest="output_dir_path",
                            help="Path to output directory.",
                            default="out")
    fit_parser.add_argument("-m", "--model-file",
                            dest="model_file",
                            help="Path to a fit model file.",
                            default="model",
                            required=True)
    fit_parser.add_argument("-B", "--nbits",
                            type=int,
                            help="Number of bits used to express the graph kernel features. A value of 20 corresponds to 2**20=1 million possible features.",
                            default=20)
    fit_parser.add_argument("-C", "--complexity",
                            type=int,
                            help="Size of the generalization of k-mers for graphs.",
                            default=4)
    fit_parser.add_argument("-e", "--n-iter",
                            dest="n_iter",
                            type=int,
                            help="Number of randomly generated hyper parameter configurations tried during the discriminative model optimization. A value of 1 implies using the estimator default values.",
                            default=1)
    fit_parser.add_argument("-j", "--n-jobs",
                            dest="n_jobs",
                            type=int,
                            help="Number of cores to use in multiprocessing.",
                            default=2)
    fit_parser.add_argument("-b", "--n-blocks",
                            dest="n_blocks",
                            type=int,
                            help="Number of blocks in which to divide the input for the multiprocessing elaboration.",
                            default=8)
    fit_parser.add_argument("-J", "--pre-processor-n-jobs",
                            dest="pre_processor_n_jobs",
                            type=int,
                            help="Number of cores to use in multiprocessing.",
                            default=1)
    fit_parser.add_argument("-r", "--random-state",
                            dest="random_state",
                            type=int,
                            help="Random seed.",
                            default=1)
    fit_parser.add_argument("-L", "--pre-processor-n-blocks",
                            dest="pre_processor_n_blocks",
                            type=int,
                            help="Number of blocks in which to divide the input for the multiprocessing elaboration.",
                            default=8)

    # predict commands
    predict_parser = subparsers.add_parser('predict', help='Predict commands')
    predict_parser.set_defaults(which='predict')
    predict_parser.add_argument("-i", "--input-file",
                                dest="input_file",
                                help="Path to networkx JSON file containing input graphs.",
                                required=True)
    predict_parser.add_argument("-m", "--model-file",
                                dest="model_file",
                                help="Path to a fit model file.",
                                required=True)
    predict_parser.add_argument("-o", "--output-dir",
                                dest="output_dir_path",
                                help="Path to output directory.",
                                default="out")
    predict_parser.add_argument("-p", "--print_estimate",
                                dest="print-estimate",
                                help="Print predictive performance estimate.",
                                action="store_true")

    # matrix commands
    predict_parser = subparsers.add_parser('matrix', help='Matrix commands')
    predict_parser.set_defaults(which='matrix')
    predict_parser.add_argument("-i", "--input-file",
                                dest="input_file",
                                help="Path to networkx JSON file containing input graphs.",
                                required=True)
    predict_parser.add_argument("-m", "--model-file",
                                dest="model_file",
                                help="Path to a fit model file.",
                                required=True)
    predict_parser.add_argument("-o", "--output-dir",
                                dest="output_dir_path",
                                help="Path to output directory.",
                                default="out")

    # feature commands
    predict_parser = subparsers.add_parser('feature', help='Feature commands')
    predict_parser.set_defaults(which='feature')
    predict_parser.add_argument("-i", "--input-file",
                                dest="input_file",
                                help="Path to networkx JSON file containing input graphs.",
                                required=True)
    predict_parser.add_argument("-m", "--model-file",
                                dest="model_file",
                                help="Path to a fit model file.",
                                required=True)
    predict_parser.add_argument("-o", "--output-dir",
                                dest="output_dir_path",
                                help="Path to output directory.",
                                default="out")

    args = parser.parse_args()

    logger = setup.logger(logger_name=sys.argv[0], filename="log", verbosity=args.verbosity)
    logger.info('-' * 80)
    logger.info('Program: %s' % sys.argv[0])
    logger.info('Parameters: %s' % args.__dict__)
    try:
        main(args)
    except Exception:
        import datetime
        curr_time = datetime.datetime.now().strftime("%A, %d. %B %Y %I:%M%p")
        logger.exception("Program run failed on %s" % curr_time)
    finally:
        end_time = time()
        logger.info('Elapsed time: %.1f sec', end_time - start_time)
