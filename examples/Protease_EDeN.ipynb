{
 "metadata": {
  "name": "",
  "signature": "sha256:27963ea4548e7f544ce9192dc44e7228c30dc99f3fdbc80bb38a3e8c06c100d3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def train_protease_model(fname=None, model_fname=None, neg_size_factor=5, n_jobs=8, n_iter=40, threshold=1, n_active_learning_iterations=4, verbose=2):\n",
      "    \n",
      "    def pre_processor( seqs, **args ):\n",
      "        #insert landmark in the cleavage site after pos 4, in our case this means always in the middle position\n",
      "        from eden.modifier.seq import seq_to_seq, mark_modifier \n",
      "        seqs = seq_to_seq( seqs, modifier = mark_modifier, position = 0.5, mark = '%' )\n",
      "        seqs = seq_to_seq( seqs, modifier = mark_modifier, position = 0.0, mark = '@' )\n",
      "        seqs = seq_to_seq( seqs, modifier = mark_modifier, position = 1.0, mark = '*' )\n",
      "        #convert to graph\n",
      "        from eden.converter.fasta import sequence_to_eden\n",
      "        graphs = sequence_to_eden( seqs )\n",
      "        return graphs\n",
      "\n",
      "    from eden.graph import Vectorizer\n",
      "    vectorizer = Vectorizer()\n",
      "\n",
      "    from sklearn.linear_model import SGDClassifier\n",
      "    estimator = SGDClassifier(average=True, class_weight='auto', shuffle=True, n_jobs=n_jobs)\n",
      "    \n",
      "    #create iterable from files\n",
      "    from eden.converter.fasta import fasta_to_sequence\n",
      "    seqs = fasta_to_sequence( fname )\n",
      "\n",
      "    from itertools import tee\n",
      "    seqs,seqs_,seqs__=tee(seqs,3)\n",
      "\n",
      "    #count positive instances\n",
      "    active_set_size=sum(1 for x in seqs__)\n",
      "    \n",
      "    iterable_pos_train = seqs\n",
      "    from eden.modifier.seq import seq_to_seq, shuffle_modifier\n",
      "    iterable_neg_train = seq_to_seq( seqs_, modifier=shuffle_modifier, times=neg_size_factor, order=2 )\n",
      "\n",
      "    #make predictive model\n",
      "    from eden.model import ActiveLearningBinaryClassificationModel\n",
      "    model = ActiveLearningBinaryClassificationModel( pre_processor=pre_processor, \n",
      "                                                    estimator=estimator, \n",
      "                                                    vectorizer=vectorizer,\n",
      "                                                    n_jobs=n_jobs,\n",
      "                                                    n_blocks=n_jobs)\n",
      "\n",
      "    #optimize hyperparameters and fit model\n",
      "    from numpy.random import randint\n",
      "    from numpy.random import uniform\n",
      "\n",
      "    pre_processor_parameters={}\n",
      "\n",
      "    vectorizer_parameters={'r':[2,3], 'd':[0,1,2,3,4,5]}\n",
      "\n",
      "    estimator_parameters={'n_iter':randint(5, 100, size=n_iter),\n",
      "                          'penalty':['l1','l2','elasticnet'],\n",
      "                          'l1_ratio':uniform(0.1,0.9, size=n_iter), \n",
      "                          'loss':['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
      "                          'power_t':uniform(0.1, size=n_iter),\n",
      "                          'alpha': [10**x for x in range(-8,0)],\n",
      "                          'eta0': [10**x for x in range(-4,-1)],\n",
      "                          'learning_rate': [\"invscaling\", \"constant\", \"optimal\"]}\n",
      "\n",
      "    model.optimize(iterable_pos_train, iterable_neg_train,\n",
      "                   model_name=model_fname, \n",
      "                   n_active_learning_iterations=n_active_learning_iterations,\n",
      "                   size_positive=-1,\n",
      "                   size_negative=active_set_size,\n",
      "                   lower_bound_threshold_positive=-threshold,\n",
      "                   upper_bound_threshold_positive=threshold,\n",
      "                   lower_bound_threshold_negative=-threshold,\n",
      "                   upper_bound_threshold_negative=threshold,                                              \n",
      "                   n_iter=n_iter, cv=3, verbose=verbose,\n",
      "                   pre_processor_parameters=pre_processor_parameters, \n",
      "                   vectorizer_parameters=vectorizer_parameters, \n",
      "                   estimator_parameters=estimator_parameters)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def test_protease_model(fname=None, model_fname=None):\n",
      "    from eden.model import ActiveLearningBinaryClassificationModel\n",
      "\n",
      "    model = ActiveLearningBinaryClassificationModel()\n",
      "    model.load(model_fname)\n",
      "\n",
      "    from eden.converter.fasta import fasta_to_sequence\n",
      "    seqs = fasta_to_sequence( fname )\n",
      "    from itertools import tee\n",
      "    seqs,seqs_=tee(seqs)\n",
      "    predictions= model.decision_function( seqs_ )\n",
      "    from itertools import izip\n",
      "    return izip(predictions,seqs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Models Training"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dirname='proteasis'\n",
      "file_names = !ls $dirname\n",
      "names = [name.split('.')[0] for name in file_names]\n",
      "print(names)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time\n",
      "import datetime\n",
      "\n",
      "for name in names[:1]:\n",
      "    start=time.time()\n",
      "    print '-'*80\n",
      "    print 'Processing: %s'%name\n",
      "    fname=dirname+'/'+name+'.fasta'\n",
      "    model_fname=name+'.model'\n",
      "    train_protease_model(fname=fname, model_fname=model_fname, \n",
      "                         neg_size_factor=10, \n",
      "                         n_jobs=8,\n",
      "                         n_iter=20, \n",
      "                         threshold=1, \n",
      "                         n_active_learning_iterations=2, \n",
      "                         verbose=2)\n",
      "    print 'Elapsed: %s'%(datetime.timedelta(time.time()-start))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}