{
 "metadata": {
  "name": "",
  "signature": "sha256:8d0f57d5c4a116bf95cabea14634d24f17d61a47020e19b12fb399f641de2ddf"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import itertools\n",
      "def join_pre_processes( data, pre_processes, weights):\n",
      "    if hasattr( data, '__iter__' ):\n",
      "        iterable = data\n",
      "    else: #if not then process url or file with fasta_to_fasta\n",
      "        from eden.modifier.fasta import fasta_to_fasta\n",
      "        iterable = fasta_to_fasta( data )\n",
      "    from eden import util\n",
      "    return util.join_pre_processes(iterable, pre_processes=pre_processes, weights=weights)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_process_rnashapes( iterable ):\n",
      "    from eden.converter.fasta import fasta_to_sequence\n",
      "    seqs = fasta_to_sequence(iterable)\n",
      "    \n",
      "    from eden.converter.rna.rnashapes import rnashapes_to_eden\n",
      "    graphs = rnashapes_to_eden( seqs, shape_type = 5, energy_range = 35, max_num = 3 )\n",
      "    return graphs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_process_fasta( iterable ):\n",
      "    from eden.converter.fasta import fasta_to_sequence\n",
      "    seqs = fasta_to_sequence(iterable)\n",
      "    \n",
      "    from eden.converter.fasta import sequence_to_eden\n",
      "    graphs = sequence_to_eden(seqs)\n",
      "    return graphs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_process_structure( iterable ):\n",
      "    from eden.converter.fasta import fasta_to_sequence\n",
      "    seqs = fasta_to_sequence(iterable)\n",
      "\n",
      "    from eden.converter.rna.rnashapes_struct import rnashapes_struct_to_eden\n",
      "    graphs = rnashapes_struct_to_eden(seqs, shape=True, dotbracket=False, energy=False, shape_type=5, energy_range=35, max_num=3)\n",
      "    return graphs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_process_energy( iterable ):\n",
      "    from eden.converter.fasta import fasta_to_sequence\n",
      "    seqs = fasta_to_sequence(iterable)\n",
      "\n",
      "    from eden.converter.rna.rnashapes_struct import rnashapes_struct_to_eden\n",
      "    graphs = rnashapes_struct_to_eden(seqs, energy=True, dotbracket=False, shape=False, shape_type=5, energy_range=35, max_num=3)\n",
      "    return graphs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_process_contraction( iterable ):\n",
      "    from eden.converter.fasta import fasta_to_sequence\n",
      "    seqs = fasta_to_sequence(iterable)\n",
      "\n",
      "    from eden.converter.rna.rnashapes import rnashapes_to_eden\n",
      "    graphs = rnashapes_to_eden( seqs, shape_type=5, energy_range=35, max_num=3 )\n",
      "    \n",
      "    #annotate in node attribute 'type' the incident edges' labels\n",
      "    from eden.modifier.graph import vertex_attributes\n",
      "    graphs = vertex_attributes.incident_edge_label(graphs, level=1, output_attribute='type', separator='.')\n",
      "    \n",
      "    from eden.modifier.graph.structure import contraction, contraction_modifier\n",
      "    label_modifier = contraction_modifier(attribute_in='type', attribute_out='label', reduction='set_categorical')\n",
      "    \n",
      "    #reduce all 'weight' attributes of contracted nodes using a sum to be written in the 'weight' attribute of the resulting graph \n",
      "    weight_modifier = contraction_modifier(attribute_in='weight', attribute_out='weight', reduction='sum')\n",
      "    modifiers = [label_modifier, weight_modifier]\n",
      "    \n",
      "    #contract the graph on the 'type' attribute\n",
      "    graphs = contraction(graphs, contraction_attribute='type', modifiers=modifiers)\n",
      "    \n",
      "    return graphs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_process( data ):\n",
      "    pre_processes = [pre_process_energy, pre_process_rnashapes, pre_process_fasta, pre_process_structure, pre_process_contraction]\n",
      "    weights = [0.4, 0.2, 0.05, 0.3, 0.05]\n",
      "    return join_pre_processes( data, pre_processes, weights)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_process( data ):\n",
      "    pre_processes = [pre_process_energy, pre_process_structure]\n",
      "    weights = [0.2, 0.8]\n",
      "    return join_pre_processes( data, pre_processes, weights)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def describe(X):\n",
      "    print 'Instances: %d ; Features: %d (with an avg of %d features per instance)' % (X.shape[0], X.shape[1],  X.getnnz()/X.shape[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def model(uri, pre_process):\n",
      "\n",
      "    from eden.graph import Vectorizer\n",
      "    vectorizer = Vectorizer( complexity=2 )\n",
      "\n",
      "    graphs = pre_process( uri )\n",
      "    X1 = vectorizer.transform( graphs )\n",
      "    describe(X1)\n",
      "    \n",
      "    from eden.modifier.fasta import fasta_to_fasta, shuffle_modifier\n",
      "    graphs = pre_process( fasta_to_fasta( uri , modifier=shuffle_modifier, times=2, order=2) )\n",
      "    X2 = vectorizer.transform( graphs )\n",
      "    describe(X2)\n",
      "    \n",
      "    from eden.util import fit_estimator\n",
      "    estimator = fit_estimator( positive_data_matrix=X1, negative_data_matrix=X2, cv=5 )\n",
      "    \n",
      "    return estimator, vectorizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def list_model(uri, pre_process):\n",
      "\n",
      "    from eden.graph import ListVectorizer\n",
      "    vectorizer = ListVectorizer( complexity=2 )\n",
      "\n",
      "    graphs_list, weights = pre_process( uri )\n",
      "    X1 = vectorizer.transform( graphs_list, weights=weights )\n",
      "    describe(X1)\n",
      "    \n",
      "    from eden.modifier.fasta import fasta_to_fasta, shuffle_modifier\n",
      "    graphs_list, weights = pre_process( fasta_to_fasta( uri , modifier=shuffle_modifier, times=2, order=2) )\n",
      "    X2 = vectorizer.transform( graphs_list, weights=weights )\n",
      "    describe(X2)\n",
      "    \n",
      "    from eden.util import fit_estimator\n",
      "    estimator = fit_estimator( positive_data_matrix=X1, negative_data_matrix=X2, cv=5 )\n",
      "    \n",
      "    return estimator, vectorizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def rfam_uri(family_id):\n",
      "    return 'http://rfam.xfam.org/family/%s/alignment?acc=%s&format=fastau&download=0'%(family_id,family_id)\n",
      "def rfam_uri(family_id):\n",
      "    return '%s.fa'%(family_id)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rfam_id = 'RF00871' #microRNA mir-689\n",
      "rfam_id = 'RF00005' #tRNA\n",
      "rfam_id = 'RF02275' #Hammerhead_HH9"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "estimator, vectorizer = model(rfam_uri( rfam_id ), pre_process_rnashapes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Instances: 33 ; Features: 1048577 (with an avg of 725 features per instance)\n",
        "Instances: 66 ; Features: 1048577 (with an avg of 913 features per instance)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Classifier:\n",
        "SGDClassifier(alpha=0.000443870113755, average=True, class_weight='auto',\n",
        "       epsilon=0.1, eta0=0.38461087073, fit_intercept=True, l1_ratio=0.15,\n",
        "       learning_rate='invscaling', loss='hinge', n_iter=50, n_jobs=-1,\n",
        "       penalty='l2', power_t=0.670271039147, random_state=None,\n",
        "       shuffle=True, verbose=0, warm_start=False)\n",
        "--------------------------------------------------------------------------------\n",
        "Predictive performance:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "            accuracy: 1.000 +- 0.000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "           precision: 1.000 +- 0.000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "              recall: 1.000 +- 0.000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                  f1: 1.000 +- 0.000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   average_precision: 1.000 +- 0.000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             roc_auc: 1.000 +- 0.000\n",
        "--------------------------------------------------------------------------------\n",
        "CPU times: user 10.3 s, sys: 1.59 s, total: 11.9 s\n",
        "Wall time: 29.7 s\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "estimator_str, vectorizer_str = list_model(rfam_uri( rfam_id ), pre_process)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Instances: 33 ; Features: 1048577 (with an avg of 74 features per instance)\n",
        "Instances: 66 ; Features: 1048577 (with an avg of 72 features per instance)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Classifier:\n",
        "SGDClassifier(alpha=3.40714927494e-05, average=True, class_weight='auto',\n",
        "       epsilon=0.1, eta0=0.673011249259, fit_intercept=True, l1_ratio=0.15,\n",
        "       learning_rate='constant', loss='hinge', n_iter=75, n_jobs=-1,\n",
        "       penalty='elasticnet', power_t=0.304361210113, random_state=None,\n",
        "       shuffle=True, verbose=0, warm_start=False)\n",
        "--------------------------------------------------------------------------------\n",
        "Predictive performance:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "            accuracy: 0.949 +- 0.046\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "           precision: 0.896 +- 0.095\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "              recall: 0.971 +- 0.057\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                  f1: 0.930 +- 0.064\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   average_precision: 0.984 +- 0.014\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             roc_auc: 0.991 +- 0.008\n",
        "--------------------------------------------------------------------------------\n",
        "CPU times: user 1.83 s, sys: 687 ms, total: 2.52 s\n",
        "Wall time: 14.2 s\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extract_motives(uri, motif_support_threshold = 2, min_subarray_size=5, max_subarray_size=18, estimator = estimator, vectorizer = vectorizer):\n",
      "    \n",
      "    #annotate graphs with node importance \n",
      "    graphs = pre_process_rnashapes( uri )\n",
      "    graphs = vectorizer.annotate( graphs, estimator )\n",
      "\n",
      "    #use node importance and 'position' attribute to identify max_subarrays of a specific size\n",
      "    #use compute_max_subarrays to return an iterator over motives \n",
      "    from eden.util.iterated_maximum_subarray import compute_max_subarrays\n",
      "\n",
      "    motives = set()\n",
      "    for graph in graphs:\n",
      "        subarrays = compute_max_subarrays(graph=graph, min_subarray_size=min_subarray_size, max_subarray_size=max_subarray_size)\n",
      "        for subarray in subarrays:\n",
      "            motives.add(subarray['subarray_string'])\n",
      "\n",
      "    #count occurrences of motives in original dataset to determine support of each motif\n",
      "    from collections import defaultdict\n",
      "\n",
      "    from eden.modifier.fasta import fasta_to_fasta, one_line_modifier\n",
      "    iterable = fasta_to_fasta( uri, modifier=one_line_modifier, sequence_only=True)\n",
      "\n",
      "    motif_counter = defaultdict(int)\n",
      "    for seq in iterable:\n",
      "        for motif in motives:\n",
      "            if seq.find(motif) != -1:\n",
      "                motif_counter[motif] += 1\n",
      "    \n",
      "    #select only motives with support higher than a user defined threshold\n",
      "    selcted_motives = [motif for motif in motif_counter if motif_counter[motif] >= motif_support_threshold]   \n",
      "\n",
      "    #remove motives that are specializations of smaller motifs\n",
      "    blacklist=set()\n",
      "    for motif1 in selcted_motives:\n",
      "        for motif2 in selcted_motives:\n",
      "            if motif1 != motif2 and motif1 in motif2:\n",
      "                blacklist.add(motif2)\n",
      "    selcted_motives=list(set(selcted_motives).difference(blacklist))\n",
      "\n",
      "    print 'Selected %d motives'%len(selcted_motives)\n",
      "    #build a regex expression that matches the occurrence of at least one of the motives\n",
      "    regex=''\n",
      "    for m in sorted(selcted_motives): regex += '|' + m\n",
      "    regex = regex[1:]\n",
      "    return regex"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "regex = extract_motives(rfam_uri( rfam_id ), motif_support_threshold = 10, min_subarray_size=5, max_subarray_size=15, estimator = estimator, vectorizer = vectorizer)\n",
      "print \"regex: \", regex"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Selected 4 motives\n",
        "regex:  AGCUCCA|CCGUUACCUGCA|CCUGCAG|UCCAAAAAGAGC\n",
        "CPU times: user 3.2 s, sys: 259 ms, total: 3.46 s\n",
        "Wall time: 4.11 s\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def motives_discriminative_performance_evaluation(data, regex):\n",
      "    #compute statistics when using the motives as indicators for the target family on the original data \n",
      "    #and on a randomly permuted dataset\n",
      "    \n",
      "    from eden.modifier.fasta import fasta_to_fasta, keep_modifier, shuffle_modifier\n",
      "    iterable = fasta_to_fasta( data , modifier=keep_modifier, regex=regex )\n",
      "    true_positive_count = sum(1 for x in iterable)\n",
      "    iterable = fasta_to_fasta( data )\n",
      "    positive_count = sum(1 for x in iterable)\n",
      "    iterable = fasta_to_fasta( data , modifier=shuffle_modifier, times=10, order=2)\n",
      "    it1,it2 = itertools.tee(iterable)\n",
      "    negative_count = sum(1 for x in it1)\n",
      "    iterable = fasta_to_fasta( it2 , modifier=keep_modifier, regex=regex )\n",
      "    false_positive_count = sum(1 for x in iterable)\n",
      "    false_negative_count =  positive_count - true_positive_count\n",
      "    true_negative_count = negative_count - false_negative_count\n",
      "\n",
      "    recall = true_positive_count/float(true_positive_count + false_negative_count)\n",
      "    precision = true_positive_count/float(true_positive_count + false_positive_count)\n",
      "    f1 = 2 * precision * recall / (precision + recall)\n",
      "\n",
      "    print 'pos:%d neg:%d TP:%d FP:%d TN:%d FN:%d' % (positive_count, negative_count, true_positive_count, false_positive_count, true_negative_count, false_negative_count)\n",
      "    print 'precision:%0.3f recall:%0.3f f1:%0.3f' % (precision, recall, f1)\n",
      "    print 'dataset reduction: from %d to %d = %0.3f' % (negative_count, false_positive_count, false_positive_count/float(negative_count))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "motives_discriminative_performance_evaluation(rfam_uri( rfam_id ), regex)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "pos:66 neg:660 TP:66 FP:8 TN:660 FN:0\n",
        "precision:0.892 recall:1.000 f1:0.943\n",
        "dataset reduction: from 660 to 8 = 0.012\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def lenght_stats(uri, lower_percentile=25, upper_percentile=75):\n",
      "    #extract statistics on the average lenght of the sequences in the given Rfam family\n",
      "    #use this information to determine the size of the window when scanning the genome\n",
      "    import numpy\n",
      "    from eden.modifier.fasta import fasta_to_fasta, one_line_modifier\n",
      "\n",
      "    iterable = fasta_to_fasta( uri, modifier=one_line_modifier, sequence_only=True)\n",
      "    len_seqs = [len(seq) for seq in iterable]\n",
      "    lower_quantile = int(numpy.percentile(len_seqs, lower_percentile))\n",
      "    upper_quantile = int(numpy.percentile(len_seqs, upper_percentile))\n",
      "\n",
      "    num_seqs = len(len_seqs)\n",
      "\n",
      "    print 'Rfam family %s has %d sequences' % (rfam_id, num_seqs)\n",
      "    print 'more than %d%% of the sequences have lenght smaller than: %d ' % (upper_percentile, upper_quantile)\n",
      "    print 'less then %d%% of the sequences have lenght smaller than: %d ' % (lower_percentile, lower_quantile)\n",
      "    \n",
      "    return lower_quantile, upper_quantile"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lower_quantile, upper_quantile = lenght_stats(rfam_uri( rfam_id ), lower_percentile=15, upper_percentile=85)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Rfam family RF02275 has 33 sequences\n",
        "more than 85% of the sequences have lenght smaller than: 78 \n",
        "less then 15% of the sequences have lenght smaller than: 67 \n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def out_of_core_list_filter( iterable, estimator=None, vectorizer=None, pre_process=None, threshold=1 ):\n",
      "    #define a filter that uses the predictive model\n",
      "    import itertools\n",
      "    iterable_headers, iterable_seqs = itertools.tee( iterable )\n",
      "    \n",
      "    #1. extract oneline fasta\n",
      "    from eden.modifier.fasta import fasta_to_fasta, one_line_modifier\n",
      "    header_seqs = fasta_to_fasta( iterable_headers, modifier=one_line_modifier, one_line=True )\n",
      "\n",
      "    #2. extract graphs\n",
      "    graphs_list, weights = pre_process( iterable_seqs )\n",
      "    predictions = vectorizer.predict(graphs_list, estimator=estimator, weights=weights)\n",
      "\n",
      "    #1+2\n",
      "    for header_seq, prediction in itertools.izip(header_seqs, predictions):\n",
      "        if prediction >= float(threshold):\n",
      "            lines = header_seq.split('\\t')\n",
      "            header = lines[0] + ' SCORE: %.3f '%prediction\n",
      "            seq = lines[1]\n",
      "            yield header\n",
      "            yield seq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def out_of_core_filter( iterable, estimator=None, vectorizer=None, pre_process=None, threshold=1 ):\n",
      "    #define a filter that uses the predictive model\n",
      "    import itertools\n",
      "    iterable_headers, iterable_seqs = itertools.tee( iterable )\n",
      "    \n",
      "    #1. extract oneline fasta\n",
      "    from eden.modifier.fasta import fasta_to_fasta, one_line_modifier\n",
      "    header_seqs = fasta_to_fasta( iterable_headers, modifier=one_line_modifier, one_line=True )\n",
      "\n",
      "    #2. extract graphs\n",
      "    graphs = pre_process( iterable_seqs )\n",
      "    predictions = vectorizer.predict(graphs, estimator=estimator)\n",
      "\n",
      "    #1+2\n",
      "    for header_seq, prediction in itertools.izip(header_seqs, predictions):\n",
      "        if prediction >= float(threshold):\n",
      "            lines = header_seq.split('\\t')\n",
      "            header = lines[0] + ' SCORE: %.3f '%prediction\n",
      "            seq = lines[1]\n",
      "            yield header\n",
      "            yield seq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#parameters choice\n",
      "uri = 'ecoli.fa'\n",
      "min_lenght = lower_quantile\n",
      "max_lenght = upper_quantile\n",
      "threshold_1 = 0.0\n",
      "threshold_2 = 0.0\n",
      "\n",
      "\n",
      "#compose all modifiers and filters\n",
      "from eden.modifier.fasta import fasta_to_fasta, one_line_modifier, replace_modifier, split_regex_modifier, split_modifier, keep_modifier\n",
      "\n",
      "#replace Ts with Us\n",
      "iterable = fasta_to_fasta(uri, modifier=replace_modifier, regex='T', replacement='U')\n",
      "\n",
      "#split out sequences that are not stretches of Ns  \n",
      "#iterable = fasta_to_fasta(iterable, modifier=split_regex_modifier, regex=\"([^N]+)\" )\n",
      "\n",
      "#filter out small sequences, i.e. smaller than lower_quantile\n",
      "#iterable = fasta_to_fasta(iterable, modifier=keep_modifier, regex=\"(.{%d,})\"%min_lenght )\n",
      "\n",
      "#split large sequences into overlapping windows of size comparable with the Rfam average seq lenght\n",
      "iterable = fasta_to_fasta( iterable, modifier=split_modifier, window=max_lenght, step=5 )\n",
      "\n",
      "#keep only the sequences that are matched by the regex\n",
      "iterable = fasta_to_fasta(iterable, modifier=keep_modifier, regex=regex )\n",
      "\n",
      "#filter sequences using predictive model on structures\n",
      "iterable = out_of_core_list_filter( iterable, threshold=threshold_1, pre_process=pre_process, estimator=estimator_str, vectorizer=vectorizer_str )\n",
      "\n",
      "#filter sequences using predictive model on seq+structure\n",
      "iterable = out_of_core_filter( iterable, threshold=threshold_2, pre_process=pre_process_rnashapes, estimator=estimator, vectorizer=vectorizer )\n",
      "\n",
      "#extract one line\n",
      "iterable = fasta_to_fasta( iterable, modifier=one_line_modifier, one_line=True )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#run the filter on the genome and save results\n",
      "\n",
      "from datetime import datetime\n",
      "import sys\n",
      "\n",
      "results = []\n",
      "\n",
      "f = open('result','a')\n",
      "print >> f, '-'*80\n",
      "print >> f, rfam_id\n",
      "print >> f, datetime.now() \n",
      "\n",
      "#display and save results    \n",
      "from itertools import islice\n",
      "for line in islice(iterable,10):\n",
      "    print line\n",
      "    sys.stdout.flush()\n",
      "    print >> f, line\n",
      "    f.flush()\n",
      "    results.append(line)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#run the filter on the genome and save results\n",
      "\n",
      "from datetime import datetime\n",
      "import sys\n",
      "\n",
      "results = []\n",
      "\n",
      "f = open('result','a')\n",
      "print >> f, '-'*80\n",
      "print >> f, rfam_id\n",
      "print >> f, datetime.now() \n",
      "\n",
      "#display and save results    \n",
      "for line in iterable:\n",
      "    print line\n",
      "    sys.stdout.flush()\n",
      "    print >> f, line\n",
      "    f.flush()\n",
      "    results.append(line)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from ipy_table import * \n",
      "\n",
      "matr=[('ID','Pos','Conf1','Conf2','Seq')]\n",
      "\n",
      "th0=1.8\n",
      "th1=th2=0\n",
      "counter=1\n",
      "for line in results:\n",
      "    lines=line.split()\n",
      "    seq,sc1,sc2,pos = lines[-1], float(lines[-2]),float(lines[-4]),lines[-10]\n",
      "    if sc1 + sc2 > th0 and sc2 > th2 and sc1 > th1:\n",
      "        matr += [(counter, pos, sc1,sc2, seq)]\n",
      "        counter += 1\n",
      "\n",
      "make_table(matr)\n",
      "apply_theme('basic')\n",
      "set_global_style(float_format = '%0.3f')\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#reference tRNA\n",
      "fname='trna_ecoli'\n",
      "def parse(fname):\n",
      "    with open(fname) as f:\n",
      "        for line in f:\n",
      "            text = ' '.join([line.strip(), f.next().strip(), f.next().strip(), f.next().strip()])\n",
      "            lines=text.split()\n",
      "            yield (int(lines[6].replace(\",\", \"\")),lines[0], lines[5])\n",
      "\n",
      "from ipy_table import * \n",
      "\n",
      "mat=[('ID','Name','Pos')]\n",
      "\n",
      "counter=1            \n",
      "for t in sorted(parse(fname)):\n",
      "    pos,name,strand = t\n",
      "    name=name.replace(\"T\",\"U\")\n",
      "    if '+' in strand:\n",
      "        mat += [(counter, name, pos)]\n",
      "        counter += 1\n",
      "        \n",
      "make_table(mat)\n",
      "apply_theme('basic')\n",
      "set_global_style(float_format = '%0.3f')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#validate results\n",
      "tolerance = 50\n",
      "offset = 2000\n",
      "name_set = set()\n",
      "for counter_r, pos_r, sc1_r,sc2_r, seq_r in matr[1:]:\n",
      "    for counter, name, pos in mat[1:]:\n",
      "        if int(pos_r) - offset > int(pos) - tolerance and int(pos_r) - offset < int(pos) + tolerance: \n",
      "            print name,pos, pos_r, counter_r\n",
      "            name_set.add(name)\n",
      "print len(name_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def fasta_results(mat):\n",
      "    for counter, pos, sc1,sc2, seq in mat:\n",
      "        yield '>Ecoli:%s'%pos\n",
      "        yield seq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_process(data):\n",
      "    from eden.converter.rna.rnashapes import rnashapes_to_eden\n",
      "    graphs = rnashapes_to_eden(data, shape_type=5, energy_range=35, max_num=3)\n",
      "    return graphs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "#parameters for visualization\n",
      "from eden.util.display import draw_graph\n",
      "size = 14\n",
      "node_size = 200\n",
      "font_size = 9\n",
      "opts={'size':size, 'node_border':False, 'node_size':node_size, 'font_size':font_size, 'vertex_alpha':0.6}\n",
      "\n",
      "for graph in itertools.islice(pre_process(fasta_results(matr)),29,31):\n",
      "    draw_graph(graph, **opts)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}