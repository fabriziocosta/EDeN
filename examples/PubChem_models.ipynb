{
 "metadata": {
  "name": "",
  "signature": "sha256:8a3cca1454435d7c46400c22bfcee5c73a021e94958efbe0ed0d90a6ae7d78f8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import requests\n",
      "\n",
      "def get_compounds(fname, size, listkey):\n",
      "    PROLOG='https://pubchem.ncbi.nlm.nih.gov/rest/pug/'\n",
      "    with open(fname,'w') as file_handle:\n",
      "        stepsize=50\n",
      "        index_start=0\n",
      "        for chunk, index_end in enumerate(range(0,size+stepsize,stepsize)):\n",
      "            if index_end is not 0 :\n",
      "                print 'Chunk %s) Processing compounds %s to %s (of a total of %s)' % (chunk, index_start, index_end-1, size)\n",
      "                RESTQ = PROLOG + 'compound/listkey/' + str(listkey) + '/SDF?&listkey_start=' + str(index_start) + '&listkey_count=' + str(stepsize)\n",
      "                reply=requests.get(RESTQ)\n",
      "                file_handle.write(reply.text)\n",
      "            index_start = index_end\n",
      "        print 'compounds available in file: ', fname\n",
      "\n",
      "\n",
      "def get_assay(assay_id):\n",
      "    PROLOG='https://pubchem.ncbi.nlm.nih.gov/rest/pug/'\n",
      "    AID=str(assay_id)\n",
      "    #active\n",
      "    RESTQ = PROLOG + 'assay/aid/' + AID + '/cids/JSON?cids_type=active&list_return=listkey'\n",
      "    reply=requests.get(RESTQ)\n",
      "    #extract the listkey\n",
      "    active_listkey = reply.json()['IdentifierList']['ListKey']\n",
      "    active_size = reply.json()['IdentifierList']['Size'] \n",
      "    active_fname = 'AID'+AID+'_active.sdf'\n",
      "    get_compounds(fname=active_fname, size=active_size, listkey=active_listkey)\n",
      "\n",
      "    #inactive\n",
      "    RESTQ = PROLOG + 'assay/aid/' + AID + '/cids/JSON?cids_type=inactive&list_return=listkey'\n",
      "    reply=requests.get(RESTQ)\n",
      "    #extract the listkey\n",
      "    inactive_listkey = reply.json()['IdentifierList']['ListKey']\n",
      "    inactive_size = reply.json()['IdentifierList']['Size']\n",
      "    inactive_fname = 'AID'+AID+'_inactive.sdf'\n",
      "    get_compounds(fname=inactive_fname, size=inactive_size, listkey=inactive_listkey)\n",
      "\n",
      "    return (active_fname,inactive_fname)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import datetime, time\n",
      "def train_obabel_model(pos_fname, neg_fname, model_fname=None, n_iter=40, active_set_size=1000, n_active_learning_iterations=3, threshold=1, train_test_split=0.7, verbose=False):\n",
      "    def pre_processor( data, **args):\n",
      "        return data\n",
      "    \n",
      "    from eden.graph import Vectorizer\n",
      "    vectorizer = Vectorizer()\n",
      "\n",
      "    from sklearn.linear_model import SGDClassifier\n",
      "    estimator = SGDClassifier(average=True, class_weight='auto', shuffle=True)\n",
      "\n",
      "    #create iterable from files\n",
      "    from eden.converter.molecule import obabel\n",
      "    iterable_pos=obabel.obabel_to_eden(pos_fname)\n",
      "    iterable_neg=obabel.obabel_to_eden(neg_fname)\n",
      "    \n",
      "    from itertools import tee\n",
      "    iterable_pos, iterable_pos_ = tee(iterable_pos)\n",
      "    iterable_neg, iterable_neg_ = tee(iterable_neg)\n",
      "    \n",
      "    import time\n",
      "    start = time.time()\n",
      "    print('# positives: %d  # negatives: %d (%.1f sec %s)'%(sum(1 for x in iterable_pos_), sum(1 for x in iterable_neg_), time.time() - start, str(datetime.timedelta(seconds=(time.time() - start)))))\n",
      "    \n",
      "    #split train/test\n",
      "    from eden.util import random_bipartition_iter\n",
      "    iterable_pos_train, iterable_pos_test = random_bipartition_iter(iterable_pos, relative_size=train_test_split)\n",
      "    iterable_neg_train, iterable_neg_test = random_bipartition_iter(iterable_neg, relative_size=train_test_split)\n",
      "\n",
      "\n",
      "\n",
      "    #make predictive model\n",
      "    from eden.model import ActiveLearningBinaryClassificationModel\n",
      "    model = ActiveLearningBinaryClassificationModel( pre_processor, estimator=estimator, vectorizer=vectorizer )\n",
      "\n",
      "    #optimize hyperparameters and fit model\n",
      "    from numpy.random import randint\n",
      "    from numpy.random import uniform\n",
      "\n",
      "    pre_processor_parameters={} \n",
      "\n",
      "    vectorizer_parameters={'complexity':[4]}\n",
      "\n",
      "    estimator_parameters={'n_iter':randint(5, 100, size=n_iter),\n",
      "                          'penalty':['l1','l2','elasticnet'],\n",
      "                          'l1_ratio':uniform(0.1,0.9, size=n_iter), \n",
      "                          'loss':['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
      "                          'power_t':uniform(0.1, size=n_iter),\n",
      "                          'alpha': [10**x for x in range(-8,-2)],\n",
      "                          'eta0': [10**x for x in range(-4,-1)],\n",
      "                          'learning_rate': [\"invscaling\", \"constant\", \"optimal\"]}\n",
      "\n",
      "    model.optimize(iterable_pos_train, iterable_neg_train, \n",
      "                   model_name=model_fname,\n",
      "                   n_active_learning_iterations=n_active_learning_iterations,\n",
      "                   size_positive=-1,\n",
      "                   size_negative=active_set_size,\n",
      "                   n_iter=n_iter, cv=3, verbose=verbose,\n",
      "                   pre_processor_parameters=pre_processor_parameters, \n",
      "                   vectorizer_parameters=vectorizer_parameters, \n",
      "                   estimator_parameters=estimator_parameters)\n",
      "  \n",
      "    #estimate predictive performance\n",
      "    model.estimate( iterable_pos_test, iterable_neg_test, cv=5 )\n",
      "    return model\n",
      "    \n",
      "    \n",
      "def test_obabel_model(fname, model_fname=None):\n",
      "    from eden.model import ActiveLearningBinaryClassificationModel\n",
      "\n",
      "    model = ActiveLearningBinaryClassificationModel()\n",
      "    model.load(model_fname)\n",
      "\n",
      "    #create iterable from files\n",
      "    from eden.converter.molecule import obabel\n",
      "    iterable=obabel.obabel_to_eden(fname)\n",
      "    \n",
      "    predictions= model.decision_function( iterable )\n",
      "        \n",
      "    return predictions"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "AID=488918\n",
      "AID=738\n",
      "AID=743150\n",
      "AID=2401"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "READ_FROM_FILE=False\n",
      "READ_FROM_FILE=True\n",
      "\n",
      "if READ_FROM_FILE:\n",
      "    active_fname='AID%s_active.sdf'%AID\n",
      "    inactive_fname='AID%s_inactive.sdf'%AID\n",
      "else:\n",
      "    active_fname, inactive_fname = get_assay(AID)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 7 \u00b5s, sys: 6 \u00b5s, total: 13 \u00b5s\n",
        "Wall time: 11 \u00b5s\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "model_fname='AID%s.model'%AID\n",
      "model = train_obabel_model(active_fname, inactive_fname, model_fname=model_fname, \n",
      "                           n_iter=40, \n",
      "                           active_set_size=500, \n",
      "                           n_active_learning_iterations=4, \n",
      "                           threshold=1, \n",
      "                           train_test_split=0.8, \n",
      "                           verbose=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from eden.converter.molecule import obabel\n",
      "graphs=obabel.obabel_to_eden(active_fname,file_type = 'sdf')\n",
      "from itertools import islice\n",
      "graphs = islice(graphs, 3)\n",
      "from eden.util.display import draw_graph\n",
      "for graph in graphs:  draw_graph(graph, size=12, node_size=400, node_border=1, vertex_label='hlabel')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Old"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from eden.graph import Vectorizer\n",
      "vectorizer=Vectorizer(complexity=5, nbits=14)\n",
      "from eden.converter.molecule import obabel\n",
      "print 'Working on positive instances in %s and negative instances in %s' % (active_fname, inactive_fname)\n",
      "active_graphs=obabel.obabel_to_eden(active_fname)\n",
      "inactive_graphs=obabel.obabel_to_eden(inactive_fname)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndexError",
       "evalue": "list index out of range",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-6-c5ee2878185e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0meden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplexity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0meden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmolecule\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mobabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'Working on positive instances in %s and negative instances in %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mactive_fname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minactive_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mactive_graphs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobabel_to_eden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactive_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/costa/Desktop/BTSync/Projects/EDeN/EDeN/eden/converter/molecule/obabel.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mopenbabel\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpybel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnetworkx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadwrite\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/costa/Desktop/BTSync/Projects/EDeN/EDeN/examples/build/bdist.macosx-10.9-intel/egg/pybel.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
        "\u001b[0;32m/Users/costa/Desktop/BTSync/Projects/EDeN/EDeN/examples/build/bdist.macosx-10.9-intel/egg/pybel.py\u001b[0m in \u001b[0;36m_getpluginnames\u001b[0;34m(ptype)\u001b[0m\n",
        "\u001b[0;31mIndexError\u001b[0m: list index out of range"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "from eden import vectorize\n",
      "active_X = vectorize(active_graphs,vectorizer=vectorizer)\n",
      "inactive_X = vectorize(inactive_graphs,vectorizer=vectorizer)\n",
      "from scipy.sparse import vstack\n",
      "import numpy as np\n",
      "X=vstack( [active_X,inactive_X] )\n",
      "yp=[1]*active_X.shape[0]\n",
      "yn=[-1]*inactive_X.shape[0]\n",
      "y=np.array(yp+yn)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "from sklearn import cross_validation\n",
      "\n",
      "#induce a predictive model\n",
      "predictor = SGDClassifier(class_weight = 'auto', shuffle = True, average=True)\n",
      "scores = cross_validation.cross_val_score(predictor, X, y,cv=10, scoring='roc_auc')\n",
      "print('AUC ROC: %.4f +- %.4f' % (np.mean(scores),np.std(scores)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "AUC ROC: 0.8974 +- 0.0670\n",
        "CPU times: user 593 ms, sys: 121 ms, total: 714 ms\n",
        "Wall time: 711 ms\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "from sklearn.decomposition import TruncatedSVD\n",
      "svd = TruncatedSVD(n_components=500, random_state=42)\n",
      "Xd=svd.fit_transform(X) \n",
      "print(svd.explained_variance_ratio_.sum()) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.57483039478\n",
        "CPU times: user 13.8 s, sys: 453 ms, total: 14.2 s\n",
        "Wall time: 11.3 s\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "from sklearn import cross_validation\n",
      "\n",
      "#induce a predictive model\n",
      "predictor = SGDClassifier(class_weight = 'auto', shuffle = True, average=True)\n",
      "scores = cross_validation.cross_val_score(predictor, Xd, y,cv=10, scoring='roc_auc')\n",
      "print('AUC ROC: %.4f +- %.4f' % (np.mean(scores),np.std(scores)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "AUC ROC: 0.8929 +- 0.0631\n",
        "CPU times: user 167 ms, sys: 19.3 ms, total: 186 ms\n",
        "Wall time: 185 ms\n"
       ]
      }
     ],
     "prompt_number": 9
    }
   ],
   "metadata": {}
  }
 ]
}