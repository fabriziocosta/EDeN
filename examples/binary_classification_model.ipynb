{
 "metadata": {
  "name": "",
  "signature": "sha256:86e72ba1c60e86841c92184516752adff2b1e69523abdeb35e10f01982d706fb"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def rfam_uri(family_id):\n",
      "    return 'http://rfam.xfam.org/family/%s/alignment?acc=%s&format=fastau&download=0'%(family_id,family_id)\n",
      "\n",
      "def rfam_uri(family_id):\n",
      "    return '%s.fa'%(family_id)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rfam_id = 'RF02275' #Hammerhead_HH9\n",
      "rfam_id = 'RF00871' #microRNA mir-689\n",
      "rfam_id = 'RF00005' #tRNA"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_processor( data, **args):\n",
      "    from eden.converter.rna.rnafold import rnafold_to_eden\n",
      "    graphs = rnafold_to_eden( data, **args )\n",
      "    return graphs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_processor( data, **args):\n",
      "    from eden.converter.rna.rnashapes import rnashapes_to_eden\n",
      "    graphs = rnashapes_to_eden( data, **args )\n",
      "    return graphs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from eden.graph import Vectorizer\n",
      "vectorizer = Vectorizer()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import SGDClassifier, Perceptron, PassiveAggressiveClassifier\n",
      "estimator = PassiveAggressiveClassifier(shuffle=True)\n",
      "estimator = Perceptron(class_weight='auto', shuffle=True)\n",
      "estimator = SGDClassifier(average=True, class_weight='auto', shuffle=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#data setup\n",
      "model_fname='eden_model_%s'%rfam_id\n",
      "size=50\n",
      "times=20\n",
      "train_test_split=0.5\n",
      "n_iter=40"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#BinaryClassificationModel"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create iterable from files\n",
      "from eden.converter.fasta import fasta_to_sequence\n",
      "seqs = fasta_to_sequence( rfam_uri( rfam_id ) )\n",
      "from itertools import tee\n",
      "seqs,seqs_=tee(seqs)\n",
      "iterable_pos = seqs\n",
      "from eden.modifier.seq import seq_to_seq, shuffle_modifier\n",
      "iterable_neg = seq_to_seq( seqs_, modifier=shuffle_modifier, times=2, order=2 )\n",
      "\n",
      "#consier only first 'size' elements\n",
      "from itertools import islice\n",
      "iterable_pos = islice(iterable_pos,size)\n",
      "iterable_neg = islice(iterable_neg,size*times)\n",
      "\n",
      "#split train/test\n",
      "from eden.util import random_bipartition_iter\n",
      "iterable_pos_train, iterable_pos_test = random_bipartition_iter(iterable_pos, relative_size=train_test_split)\n",
      "iterable_neg_train, iterable_neg_test = random_bipartition_iter(iterable_neg, relative_size=train_test_split)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#make predictive model\n",
      "from eden.model import ActiveLearningBinaryClassificationModel\n",
      "model = ActiveLearningBinaryClassificationModel( pre_processor, estimator=estimator, vectorizer=vectorizer )\n",
      "\n",
      "#optimize hyperparameters and fit model\n",
      "from numpy.random import randint\n",
      "from numpy.random import uniform\n",
      "pre_processor_parameters={'max_num':[3], \n",
      "                          'shape_type':[5], \n",
      "                          'energy_range':[30]}\n",
      "\n",
      "vectorizer_parameters={'complexity':[2]}\n",
      "\n",
      "estimator_parameters={'n_iter':randint(5, 100, size=n_iter),\n",
      "                      'penalty':['l1','l2','elasticnet'],\n",
      "                      'l1_ratio':uniform(0.1,0.9, size=n_iter), \n",
      "                      'loss':['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
      "                      'power_t':uniform(0.1, size=n_iter),\n",
      "                      'alpha': [10**x for x in range(-8,0)],\n",
      "                      'eta0': [10**x for x in range(-4,-1)],\n",
      "                      'learning_rate': [\"invscaling\", \"constant\", \"optimal\"]}\n",
      "\n",
      "model.optimize(iterable_pos_train, iterable_neg_train, \n",
      "               model_name=model_fname,\n",
      "               max_total_time=60*5, n_iter=n_iter, \n",
      "               cv=5, n_jobs=1, verbose=2,\n",
      "               score_func=lambda avg_score,std_score : avg_score - std_score * 10,\n",
      "               scoring='average_precision',\n",
      "               pre_processor_parameters=pre_processor_parameters, \n",
      "               vectorizer_parameters=vectorizer_parameters, \n",
      "               estimator_parameters=estimator_parameters)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "--------------------------------------------------------------------------------\n",
        "Parameters range:\n",
        "Pre_processor:\n",
        "{'energy_range': [30], 'max_num': [3], 'shape_type': [5]}\n",
        "Vectorizer:\n",
        "{'complexity': [2]}\n",
        "Estimator:\n",
        "{'alpha': [1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1],\n",
        " 'eta0': [0.0001, 0.001, 0.01],\n",
        " 'l1_ratio': array([ 0.59499445,  0.66955939,  0.37506744,  0.74820112,  0.4888375 ,\n",
        "        0.86826183,  0.33928572,  0.60554625,  0.57774011,  0.77645638,\n",
        "        0.63333487,  0.77619576,  0.55166057,  0.76829541,  0.13532632,\n",
        "        0.88828063,  0.74199482,  0.20674794,  0.86471099,  0.19719424,\n",
        "        0.50800665,  0.74268394,  0.69893819,  0.2899149 ,  0.15659177,\n",
        "        0.77760289,  0.29949714,  0.25085825,  0.43436554,  0.12930179,\n",
        "        0.60385151,  0.78737605,  0.50277584,  0.54139505,  0.17351431,\n",
        "        0.58647952,  0.52038228,  0.16252097,  0.22351019,  0.89486813]),\n",
        " 'learning_rate': ['invscaling', 'constant', 'optimal'],\n",
        " 'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
        " 'n_iter': array([75, 98,  7, 74, 50, 74, 81, 47, 14, 22, 90, 88, 35, 66, 11, 51, 22,\n",
        "       33, 22, 64, 70, 88, 25, 73, 92, 96, 19, 23, 46, 10, 25, 86, 74,  8,\n",
        "       20, 14, 25, 72, 46, 38]),\n",
        " 'penalty': ['l1', 'l2', 'elasticnet'],\n",
        " 'power_t': array([ 0.72438429,  0.67901957,  0.28947432,  0.59684311,  0.47487063,\n",
        "        0.65314173,  0.95152007,  0.52235851,  0.969632  ,  0.60593168,\n",
        "        0.3063295 ,  0.88567213,  0.98892559,  0.83605881,  0.13044198,\n",
        "        0.54467802,  0.14997715,  0.45169389,  0.66559741,  0.26184516,\n",
        "        0.31048355,  0.18609489,  0.48505706,  0.96920223,  0.49955205,\n",
        "        0.67368538,  0.73049006,  0.14967778,  0.64430279,  0.7549984 ,\n",
        "        0.18163416,  0.13510631,  0.7200329 ,  0.22667314,  0.86133776,\n",
        "        0.18167306,  0.89858126,  0.90177289,  0.1342367 ,  0.48522082])}\n",
        "--------------------------------------------------------------------------------\n",
        "--------------------------------------------------------------------------------"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Parameters range:\n",
        "Pre_processor:\n",
        "{'energy_range': [30], 'max_num': [3], 'shape_type': [5]}\n",
        "Vectorizer:\n",
        "{'complexity': [2]}\n",
        "Estimator:\n",
        "{'alpha': [1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1],\n",
        " 'eta0': [0.0001, 0.001, 0.01],\n",
        " 'l1_ratio': array([ 0.59499445,  0.66955939,  0.37506744,  0.74820112,  0.4888375 ,\n",
        "        0.86826183,  0.33928572,  0.60554625,  0.57774011,  0.77645638,\n",
        "        0.63333487,  0.77619576,  0.55166057,  0.76829541,  0.13532632,\n",
        "        0.88828063,  0.74199482,  0.20674794,  0.86471099,  0.19719424,\n",
        "        0.50800665,  0.74268394,  0.69893819,  0.2899149 ,  0.15659177,\n",
        "        0.77760289,  0.29949714,  0.25085825,  0.43436554,  0.12930179,\n",
        "        0.60385151,  0.78737605,  0.50277584,  0.54139505,  0.17351431,\n",
        "        0.58647952,  0.52038228,  0.16252097,  0.22351019,  0.89486813]),\n",
        " 'learning_rate': ['invscaling', 'constant', 'optimal'],\n",
        " 'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
        " 'n_iter': array([75, 98,  7, 74, 50, 74, 81, 47, 14, 22, 90, 88, 35, 66, 11, 51, 22,\n",
        "       33, 22, 64, 70, 88, 25, 73, 92, 96, 19, 23, 46, 10, 25, 86, 74,  8,\n",
        "       20, 14, 25, 72, 46, 38]),\n",
        " 'penalty': ['l1', 'l2', 'elasticnet'],\n",
        " 'power_t': array([ 0.72438429,  0.67901957,  0.28947432,  0.59684311,  0.47487063,\n",
        "        0.65314173,  0.95152007,  0.52235851,  0.969632  ,  0.60593168,\n",
        "        0.3063295 ,  0.88567213,  0.98892559,  0.83605881,  0.13044198,\n",
        "        0.54467802,  0.14997715,  0.45169389,  0.66559741,  0.26184516,\n",
        "        0.31048355,  0.18609489,  0.48505706,  0.96920223,  0.49955205,\n",
        "        0.67368538,  0.73049006,  0.14967778,  0.64430279,  0.7549984 ,\n",
        "        0.18163416,  0.13510631,  0.7200329 ,  0.22667314,  0.86133776,\n",
        "        0.18167306,  0.89858126,  0.90177289,  0.1342367 ,  0.48522082])}\n",
        "--------------------------------------------------------------------------------\n",
        "Reached max time: 0:05:05.430948"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "CPU times: user 4min 47s, sys: 6.62 s, total: 4min 53s\n",
        "Wall time: 5min 5s\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#estimate predictive performance\n",
      "model.print_model_parameter_configuration()\n",
      "model.estimate( iterable_pos_test, iterable_neg_test )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "--------------------------------------------------------------------------------\n",
        "Current parameters:\n",
        "Pre_processor:\n",
        "{}\n",
        "Vectorizer:\n",
        "{}\n",
        "Estimator:\n",
        "{}\n",
        "--------------------------------------------------------------------------------\n",
        "Classifier:\n",
        "None\n",
        "--------------------------------------------------------------------------------\n"
       ]
      },
      {
       "ename": "AttributeError",
       "evalue": "'NoneType' object has no attribute 'set_params'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-13-19d002af90d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu'#estimate predictive performance\\nmodel.print_model_parameter_configuration()\\nmodel.estimate( iterable_pos_test, iterable_neg_test )'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m/Library/Python/2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2160\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2162\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2163\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Library/Python/2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
        "\u001b[0;32m/Library/Python/2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Library/Python/2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m             \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
        "\u001b[0;32m/Users/costa/Desktop/BTSync/Projects/EDeN/EDeN/eden/model.pyc\u001b[0m in \u001b[0;36mestimate\u001b[0;34m(self, iterable_pos, iterable_neg, n_jobs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'-'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_matrices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable_neg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'Instances: %d ; Features: %d with an avg of %d features per instance'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'-'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/costa/Desktop/BTSync/Projects/EDeN/EDeN/eden/model.pyc\u001b[0m in \u001b[0;36m_data_matrices\u001b[0;34m(self, iterable_pos, iterable_neg, fit_vectorizer, n_jobs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_data_matrices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable_neg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_vectorizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_pos\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_neg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Not iterable'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorizer_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0miterator_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_processor_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfit_vectorizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'set_params'"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Models can be reloaded from disk"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from eden.model import ActiveLearningBinaryClassificationModel\n",
      "\n",
      "model2 = ActiveLearningBinaryClassificationModel()\n",
      "model2.load(model_fname)\n",
      "\n",
      "from eden.converter.fasta import fasta_to_sequence\n",
      "seqs = fasta_to_sequence( rfam_uri( rfam_id ) )\n",
      "from itertools import tee\n",
      "seqs,seqs_=tee(seqs)\n",
      "iterable_pos = seqs\n",
      "\n",
      "#consier only first 'size' elements\n",
      "from itertools import islice\n",
      "iterable_pos = islice(iterable_pos,size)\n",
      "\n",
      "predictions= model2.decision_function( iterable_pos )\n",
      "for n,i in enumerate(sorted(predictions)): print n,i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#ActiveLearningBinaryClassificationModel"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create iterable from files\n",
      "from eden.converter.fasta import fasta_to_sequence\n",
      "seqs = fasta_to_sequence( rfam_uri( rfam_id ) )\n",
      "from itertools import tee\n",
      "seqs,seqs_=tee(seqs)\n",
      "iterable_pos = seqs\n",
      "from eden.modifier.seq import seq_to_seq, shuffle_modifier\n",
      "iterable_neg = seq_to_seq( seqs_, modifier=shuffle_modifier, times=10, order=2 )\n",
      "\n",
      "#consier only first 'size' elements\n",
      "from itertools import islice\n",
      "iterable_pos = islice(iterable_pos,size)\n",
      "iterable_neg = islice(iterable_neg,size*times)\n",
      "\n",
      "#split train/test\n",
      "from eden.util import random_bipartition_iter\n",
      "iterable_pos_train, iterable_pos_test = random_bipartition_iter(iterable_pos, relative_size=train_test_split)\n",
      "iterable_neg_train, iterable_neg_test = random_bipartition_iter(iterable_neg, relative_size=train_test_split)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#make predictive model\n",
      "from eden.model import ActiveLearningBinaryClassificationModel\n",
      "model = ActiveLearningBinaryClassificationModel( pre_processor, estimator=estimator, vectorizer=vectorizer )\n",
      "\n",
      "#optimize hyperparameters and fit model\n",
      "from numpy.random import randint\n",
      "from numpy.random import uniform\n",
      "pre_processor_parameters={'max_num':[3], \n",
      "                          'shape_type':[5], \n",
      "                          'energy_range':[30]}\n",
      "\n",
      "vectorizer_parameters={'complexity':[2]}\n",
      "\n",
      "estimator_parameters={'n_iter':randint(5, 100, size=n_iter),\n",
      "                      'penalty':['l1','l2','elasticnet'],\n",
      "                      'l1_ratio':uniform(0.1,0.9, size=n_iter), \n",
      "                      'loss':['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
      "                      'power_t':uniform(0.1, size=n_iter),\n",
      "                      'alpha': [10**x for x in range(-8,0)],\n",
      "                      'eta0': [10**x for x in range(-4,-1)],\n",
      "                      'learning_rate': [\"invscaling\", \"constant\", \"optimal\"]}\n",
      "active_set_size=size\n",
      "model_fname='eden_model_active_%s'%rfam_id\n",
      "model.optimize(iterable_pos_train, iterable_neg_train, \n",
      "               model_name=model_fname,\n",
      "               score_func=lambda avg_score,std_score : avg_score - std_score * 10,\n",
      "               scoring='average_precision',\n",
      "               n_active_learning_iterations=6,\n",
      "               max_total_time=60*5, n_iter=n_iter, \n",
      "               size_positive=-1,\n",
      "               size_negative=active_set_size,\n",
      "               cv=5, n_jobs=1, verbose=2,\n",
      "               pre_processor_parameters=pre_processor_parameters, \n",
      "               vectorizer_parameters=vectorizer_parameters, \n",
      "               estimator_parameters=estimator_parameters)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#estimate predictive performance\n",
      "model.estimate( iterable_pos_test, iterable_neg_test )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from eden.model import ActiveLearningBinaryClassificationModel\n",
      "\n",
      "model2 = ActiveLearningBinaryClassificationModel()\n",
      "model2.load(model_fname)\n",
      "\n",
      "from eden.converter.fasta import fasta_to_sequence\n",
      "seqs = fasta_to_sequence( rfam_uri( rfam_id ) )\n",
      "from itertools import tee\n",
      "seqs,seqs_=tee(seqs)\n",
      "iterable_pos = seqs\n",
      "\n",
      "#consier only first 'size' elements\n",
      "from itertools import islice\n",
      "iterable_pos = islice(iterable_pos,size)\n",
      "\n",
      "predictions= model2.decision_function( iterable_pos )\n",
      "for n,i in enumerate(sorted(predictions)): print n,i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}