{
 "metadata": {
  "name": "",
  "signature": "sha256:d099b921e646df91014b9c4ef7339998f9a05e97438c8f3309eb432d73bce383"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def train_protease_model(fname=None, model_fname=None, neg_size_factor=5, n_iter=40, threshold=1, n_active_learning_iterations=4, verbose=0):\n",
      "    \n",
      "    def pre_processor( seqs, **args ):\n",
      "        from urllib import urlretrieve\n",
      "        urlretrieve (\"http://www.bioinf.uni-freiburg.de/~costa/BLOSUM62_5D_encoding_dict.p\", \"BLOSUM62_5D_encoding_dict.p\")\n",
      "        import pickle\n",
      "        aa_encoding_dict5D = pickle.load( open( \"BLOSUM62_5D_encoding_dict.p\", \"rb\" ) )\n",
      "\n",
      "        #add encoding for landmarks\n",
      "        landmark_encodings = {'%':[10,0,0,0,0], '#':[0,10,0,0,0], '$':[0,0,10,0,0]}\n",
      "        aa_encoding_dict5D.update(landmark_encodings)\n",
      "\n",
      "        #insert landmark in the cleavage site after pos 4, in our case this means always in the middle position\n",
      "        from eden.modifier.seq import seq_to_seq, mark_modifier \n",
      "        seqs = seq_to_seq( seqs, modifier = mark_modifier, position = 0.5, mark = '%' )\n",
      "        seqs = seq_to_seq( seqs, modifier = mark_modifier, position = 0.0, mark = '@' )\n",
      "        seqs = seq_to_seq( seqs, modifier = mark_modifier, position = 1.0, mark = '*' )\n",
      "        \n",
      "        #convert to graph\n",
      "        from eden.converter.fasta import sequence_to_eden\n",
      "        graphs = sequence_to_eden( seqs )\n",
      "        \n",
      "        #relabel aa with vector encoding\n",
      "        from eden.modifier.graph.vertex_attributes import translate \n",
      "        graphs = translate(graphs, label_map = aa_encoding_dict5D, default = [0,0,0,0,0])\n",
      "        return graphs\n",
      "\n",
      "    from eden.graph import Vectorizer\n",
      "    vectorizer = Vectorizer(discretization_size = 5, discretization_dimension = 10)\n",
      "\n",
      "    from sklearn.linear_model import SGDClassifier\n",
      "    estimator = SGDClassifier(class_weight='auto', shuffle=True)\n",
      "    \n",
      "    #create iterable from files\n",
      "    from eden.converter.fasta import fasta_to_sequence\n",
      "    seqs = fasta_to_sequence( fname )\n",
      "\n",
      "    from itertools import tee\n",
      "    seqs,seqs_,seqs__=tee(seqs,3)\n",
      "\n",
      "    #count positive instances\n",
      "    active_set_size=sum(1 for x in seqs__)\n",
      "    \n",
      "    iterable_pos_train = seqs\n",
      "    from eden.modifier.seq import seq_to_seq, shuffle_modifier\n",
      "    iterable_neg_train = seq_to_seq( seqs_, modifier=shuffle_modifier, times=neg_size_factor, order=2 )\n",
      "\n",
      "    #make predictive model\n",
      "    from eden.model import ActiveLearningBinaryClassificationModel\n",
      "    model = ActiveLearningBinaryClassificationModel( pre_processor, estimator=estimator, vectorizer=vectorizer )\n",
      "\n",
      "    #optimize hyperparameters and fit model\n",
      "    from numpy.random import randint\n",
      "    from numpy.random import uniform\n",
      "\n",
      "    pre_processor_parameters={}\n",
      "\n",
      "    vectorizer_parameters={'r':[2,3], 'd':[0,1,2,3,4,5]}\n",
      "\n",
      "    estimator_parameters={'n_iter':randint(5, 100, size=n_iter),\n",
      "                          'penalty':['l1','l2','elasticnet'],\n",
      "                          'l1_ratio':uniform(0.1,0.9, size=n_iter), \n",
      "                          'loss':['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
      "                          'power_t':uniform(0.1, size=n_iter),\n",
      "                          'alpha': [10**x for x in range(-8,0)],\n",
      "                          'eta0': [10**x for x in range(-4,-1)],\n",
      "                          'learning_rate': [\"invscaling\", \"constant\", \"optimal\"]}\n",
      "\n",
      "    model.optimize(iterable_pos_train, iterable_neg_train,\n",
      "                   model_name=model_fname, \n",
      "                   fit_vectorizer=True, \n",
      "                   n_active_learning_iterations=n_active_learning_iterations,\n",
      "                   size_positive=-1,\n",
      "                   size_negative=active_set_size,\n",
      "                   lower_bound_threshold_positive=-threshold,\n",
      "                   upper_bound_threshold_positive=threshold,\n",
      "                   lower_bound_threshold_negative=-threshold,\n",
      "                   upper_bound_threshold_negative=threshold,                                              \n",
      "                   n_iter=n_iter, cv=3, n_jobs=1, verbose=verbose,\n",
      "                   pre_processor_parameters=pre_processor_parameters, \n",
      "                   vectorizer_parameters=vectorizer_parameters, \n",
      "                   estimator_parameters=estimator_parameters)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def test_protease_model(fname=None, model_fname=None):\n",
      "    from eden.model import ActiveLearningBinaryClassificationModel\n",
      "\n",
      "    model = ActiveLearningBinaryClassificationModel()\n",
      "    model.load(model_fname)\n",
      "    model.print_model_parameter_configuration()\n",
      "\n",
      "    from eden.converter.fasta import fasta_to_sequence\n",
      "    seqs = fasta_to_sequence( fname )\n",
      "    from itertools import tee\n",
      "    seqs,seqs_=tee(seqs)\n",
      "    predictions= model.decision_function( seqs_ )\n",
      "    from itertools import izip\n",
      "    return izip(predictions,seqs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Models Training"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dirname='proteasis'\n",
      "file_names = !ls $dirname\n",
      "names = [name.split('.')[0] for name in file_names]\n",
      "print(names)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['CAPN1', 'CAPN2', 'CASP1', 'CASP3', 'CASP7', 'CMA1', 'CTSB', 'CTSD', 'CTSE', 'CTSG', 'CTSK', 'CTSL1', 'CTSS', 'ELANE', 'F2', 'FURIN', 'GZMA', 'GZMB', 'GZMM', 'HPN', 'HTRA2', 'KLK4', 'MEP1A', 'MEP1B', 'MME', 'MMP12', 'MMP13', 'MMP14', 'MMP2', 'MMP3', 'MMP7', 'MMP8', 'MMP9', 'PCSK2', 'PCSK4', 'PCSK5', 'PCSK6', 'PCSK7', 'PGA3', 'PLG', 'ST14', 'TMPRSS11E', 'TMPRSS6', 'TMPRSS7']\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time\n",
      "import datetime\n",
      "\n",
      "for name in names[:1]:\n",
      "    start=time.time()\n",
      "    print '-'*80\n",
      "    print 'Processing: %s'%name\n",
      "    fname=dirname+'/'+name+'.fasta'\n",
      "    model_fname=name+'.model'\n",
      "    train_protease_model(fname=fname, model_fname=model_fname, \n",
      "                         neg_size_factor=1, \n",
      "                         n_iter=5, \n",
      "                         threshold=1, \n",
      "                         n_active_learning_iterations=0, \n",
      "                         verbose=2)\n",
      "    print 'Elapsed: %s'%(datetime.timedelta(time.time()-start))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "--------------------------------------------------------------------------------\n",
        "Processing: CAPN1\n",
        "Parameters range:\n",
        "Pre_processor:\n",
        "{}\n",
        "Vectorizer:\n",
        "{'d': [0, 1, 2, 3, 4, 5], 'r': [2, 3]}\n",
        "Estimator:\n",
        "{'alpha': [1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1],\n",
        " 'eta0': [0.0001, 0.001, 0.01],\n",
        " 'l1_ratio': array([ 0.5474335 ,  0.60667593,  0.4153248 ,  0.49277302,  0.64409631,\n",
        "        0.77237196,  0.77171785,  0.38415414,  0.78833625,  0.54844647,\n",
        "        0.21536801,  0.30214059,  0.33733474,  0.544227  ,  0.26517718,\n",
        "        0.15284173,  0.31145226,  0.50383642,  0.44777645,  0.61211657]),\n",
        " 'learning_rate': ['invscaling', 'constant', 'optimal'],\n",
        " 'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
        " 'n_iter': array([44, 80, 46, 12, 71, 25,  9, 66, 51, 57, 33, 96, 30, 88, 53, 80, 86,\n",
        "       40, 82, 94]),\n",
        " 'penalty': ['l1', 'l2', 'elasticnet'],\n",
        " 'power_t': array([ 0.4147571 ,  0.97237925,  0.78486383,  0.57556457,  0.49558708,\n",
        "        0.92605936,  0.2773206 ,  0.10363552,  0.12665089,  0.98586408,\n",
        "        0.31220602,  0.70754183,  0.15899541,  0.80663461,  0.19417043,\n",
        "        0.95166334,  0.77907576,  0.58827708,  0.12184984,  0.9611387 ])}\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Iteration: 1/20 (at 12.5 sec; 0:00:12.477455)\n",
        "Best score (roc_auc): 0.526337 (0.531894 +- 0.005557)\n",
        "Instances: 364 ; Features: 1048577 with an avg of 165 features per instance\n",
        "class: 1 count:182 (0.50)\tclass: -1 count:182 (0.50)\t\n",
        "Current parameters:\n",
        "Pre_processor:\n",
        "{}\n",
        "Vectorizer:\n",
        "{'d': 0, 'r': 2}\n",
        "Estimator:\n",
        "{'alpha': 0.01,\n",
        " 'eta0': 0.001,\n",
        " 'l1_ratio': 0.54422699877039526,\n",
        " 'learning_rate': 'optimal',\n",
        " 'loss': 'modified_huber',\n",
        " 'n_iter': 86,\n",
        " 'penalty': 'l1',\n",
        " 'power_t': 0.92605936322110038}\n",
        "Saved current best model in CAPN1.model\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Iteration: 2/20 (at 39.6 sec; 0:00:39.634031)\n",
        "Best score (roc_auc): 0.765261 (0.802369 +- 0.037109)\n",
        "Instances: 364 ; Features: 1048577 with an avg of 1310 features per instance\n",
        "class: 1 count:182 (0.50)\tclass: -1 count:182 (0.50)\t\n",
        "Current parameters:\n",
        "Pre_processor:\n",
        "{}\n",
        "Vectorizer:\n",
        "{'d': 4, 'r': 3}\n",
        "Estimator:\n",
        "{'alpha': 0.0001,\n",
        " 'eta0': 0.01,\n",
        " 'l1_ratio': 0.54844646999694557,\n",
        " 'learning_rate': 'invscaling',\n",
        " 'loss': 'modified_huber',\n",
        " 'n_iter': 40,\n",
        " 'penalty': 'elasticnet',\n",
        " 'power_t': 0.57556457047850251}\n",
        "Saved current best model in CAPN1.model\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Iteration: 3/20 (at 63.1 sec; 0:01:03.105076)\n",
        "Best score (roc_auc): 0.914650 (0.917518 +- 0.002868)\n",
        "Instances: 364 ; Features: 1048577 with an avg of 1090 features per instance\n",
        "class: 1 count:182 (0.50)\tclass: -1 count:182 (0.50)\t\n",
        "Current parameters:\n",
        "Pre_processor:\n",
        "{}\n",
        "Vectorizer:\n",
        "{'d': 3, 'r': 3}\n",
        "Estimator:\n",
        "{'alpha': 0.001,\n",
        " 'eta0': 0.001,\n",
        " 'l1_ratio': 0.54422699877039526,\n",
        " 'learning_rate': 'constant',\n",
        " 'loss': 'perceptron',\n",
        " 'n_iter': 66,\n",
        " 'penalty': 'l2',\n",
        " 'power_t': 0.41475709932056437}\n",
        "Saved current best model in CAPN1.model\n",
        "\n",
        "Failed iteration: 8/20 (at 180.7 sec; 0:03:00.673471)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Inappropriate argument value (of correct type).\n",
        "Floating-point under-/overflow occurred at epoch #5. Scaling input data with StandardScaler or MinMaxScaler might help.\n",
        "Failed with the following setting:\n",
        "Current parameters:\n",
        "Pre_processor:\n",
        "{}\n",
        "Vectorizer:\n",
        "{'d': 4, 'r': 2}\n",
        "Estimator:\n",
        "{'alpha': 0.0001,\n",
        " 'eta0': 0.0001,\n",
        " 'l1_ratio': 0.38415414366400202,\n",
        " 'learning_rate': 'optimal',\n",
        " 'loss': 'squared_hinge',\n",
        " 'n_iter': 25,\n",
        " 'penalty': 'l2',\n",
        " 'power_t': 0.78486383008323424}\n",
        "...continuing\n",
        "\n",
        "Failed iteration: 15/20 (at 321.1 sec; 0:05:21.112252)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Inappropriate argument value (of correct type).\n",
        "Floating-point under-/overflow occurred at epoch #2. Scaling input data with StandardScaler or MinMaxScaler might help.\n",
        "Failed with the following setting:\n",
        "Current parameters:\n",
        "Pre_processor:\n",
        "{}\n",
        "Vectorizer:\n",
        "{'d': 2, 'r': 3}\n",
        "Estimator:\n",
        "{'alpha': 1e-08,\n",
        " 'eta0': 0.001,\n",
        " 'l1_ratio': 0.54422699877039526,\n",
        " 'learning_rate': 'optimal',\n",
        " 'loss': 'squared_hinge',\n",
        " 'n_iter': 46,\n",
        " 'penalty': 'l1',\n",
        " 'power_t': 0.41475709932056437}\n",
        "...continuing\n",
        "Elapsed: 446 days, 6:14:26.512299"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "for name in names[:1]:\n",
      "    print '-'*80\n",
      "    print 'Processing: %s'%name\n",
      "    fname=dirname+'/'+name+'.fasta'\n",
      "    model_fname=name+'.model'\n",
      "    test_protease_model(fname=fname, model_fname=model_fname)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "--------------------------------------------------------------------------------\n",
        "Processing: CAPN1\n",
        "Current parameters:\n",
        "Pre_processor:\n",
        "{}\n",
        "Vectorizer:\n",
        "{'d': 3, 'r': 3}\n",
        "Estimator:\n",
        "{'alpha': 0.001,\n",
        " 'eta0': 0.001,\n",
        " 'l1_ratio': 0.54422699877039526,\n",
        " 'learning_rate': 'constant',\n",
        " 'loss': 'perceptron',\n",
        " 'n_iter': 66,\n",
        " 'penalty': 'l2',\n",
        " 'power_t': 0.41475709932056437}\n",
        "CPU times: user 11 s, sys: 84.7 ms, total: 11.1 s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Wall time: 11.1 s\n"
       ]
      }
     ],
     "prompt_number": 8
    }
   ],
   "metadata": {}
  }
 ]
}