{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from eden.converter.molecule import obabel\n",
    "import logging\n",
    "import requests\n",
    "\n",
    "def get_compounds(fname, size, listkey):\n",
    "    PROLOG='https://pubchem.ncbi.nlm.nih.gov/rest/pug/'\n",
    "    with open(fname,'w') as file_handle:\n",
    "        stepsize=50\n",
    "        index_start=0\n",
    "        for chunk, index_end in enumerate(range(0,size+stepsize,stepsize)):\n",
    "            if index_end is not 0 :\n",
    "                print 'Chunk %s) Processing compounds %s to %s (of a total of %s)' % (chunk, index_start, index_end-1, size)\n",
    "                RESTQ = PROLOG + 'compound/listkey/' + str(listkey) + '/SDF?&listkey_start=' + str(index_start) + '&listkey_count=' + str(stepsize)\n",
    "                reply=requests.get(RESTQ)\n",
    "                file_handle.write(reply.text)\n",
    "            index_start = index_end\n",
    "        print 'compounds available in file: ', fname\n",
    "\n",
    "\n",
    "def get_assay(assay_id):\n",
    "    PROLOG='https://pubchem.ncbi.nlm.nih.gov/rest/pug/'\n",
    "    AID=str(assay_id)\n",
    "    #active\n",
    "    RESTQ = PROLOG + 'assay/aid/' + AID + '/cids/JSON?cids_type=active&list_return=listkey'\n",
    "    reply=requests.get(RESTQ)\n",
    "    #extract the listkey\n",
    "    active_listkey = reply.json()['IdentifierList']['ListKey']\n",
    "    active_size = reply.json()['IdentifierList']['Size'] \n",
    "    active_fname = 'AID'+AID+'_active.sdf'\n",
    "    get_compounds(fname=active_fname, size=active_size, listkey=active_listkey)\n",
    "\n",
    "    #inactive\n",
    "    RESTQ = PROLOG + 'assay/aid/' + AID + '/cids/JSON?cids_type=inactive&list_return=listkey'\n",
    "    reply=requests.get(RESTQ)\n",
    "    #extract the listkey\n",
    "    inactive_listkey = reply.json()['IdentifierList']['ListKey']\n",
    "    inactive_size = reply.json()['IdentifierList']['Size']\n",
    "    inactive_fname = 'AID'+AID+'_inactive.sdf'\n",
    "    get_compounds(fname=inactive_fname, size=inactive_size, listkey=inactive_listkey)\n",
    "\n",
    "    return (active_fname,inactive_fname)logging.basicConfig(filename=\"example.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime, time\n",
    "def train_obabel_model(pos_fname, neg_fname, model_fname=None, n_iter=40, active_set_size=1000, n_active_learning_iterations=3, threshold=1, train_test_split=0.7, verbose=False):\n",
    "    \n",
    "    \n",
    "    def pre_processor( data, **args):\n",
    "        return data\n",
    "    \n",
    "    from eden.graph import Vectorizer\n",
    "    vectorizer = Vectorizer()\n",
    "\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "    estimator = SGDClassifier(average=True, class_weight='auto', shuffle=True)\n",
    "\n",
    "    #create iterable from files\n",
    "    from eden.converter.molecule import obabel\n",
    "    iterable_pos=obabel.obabel_to_eden(pos_fname)\n",
    "    iterable_neg=obabel.obabel_to_eden(neg_fname)\n",
    "    \n",
    "    from itertools import tee\n",
    "    iterable_pos, iterable_pos_ = tee(iterable_pos)\n",
    "    iterable_neg, iterable_neg_ = tee(iterable_neg)\n",
    "    \n",
    "    import time\n",
    "    start = time.time()\n",
    "    print('# positives: %d  # negatives: %d (%.1f sec %s)'%(sum(1 for x in iterable_pos_), sum(1 for x in iterable_neg_), time.time() - start, str(datetime.timedelta(seconds=(time.time() - start)))))\n",
    "    \n",
    "    #split train/test\n",
    "    from eden.util import random_bipartition_iter\n",
    "    iterable_pos_train, iterable_pos_test = random_bipartition_iter(iterable_pos, relative_size=train_test_split)\n",
    "    iterable_neg_train, iterable_neg_test = random_bipartition_iter(iterable_neg, relative_size=train_test_split)\n",
    "\n",
    "\n",
    "\n",
    "    #make predictive model\n",
    "    from eden.model import ActiveLearningBinaryClassificationModel\n",
    "    # model = ActiveLearningBinaryClassificationModel( pre_processor, estimator=estimator, vectorizer=vectorizer )\n",
    "    model = ActiveLearningBinaryClassificationModel(pre_processor,\n",
    "                                                estimator=estimator,\n",
    "                                                vectorizer=vectorizer,\n",
    "                                                n_jobs = 1,\n",
    "                                                n_blocks = 1,\n",
    "                                                fit_vectorizer=True)\n",
    " \n",
    "    from numpy.random import randint\n",
    "    from numpy.random import uniform\n",
    "\n",
    "    pre_processor_parameters={'model_type':'default'} \n",
    "    \n",
    "    # The training time for this model is much smaller, so we can use various iterations of the\n",
    "    # vectorizer\n",
    "    vectorizer_parameters={'complexity':[2,3,4,5,6]}\n",
    "\n",
    "    estimator_parameters={'n_iter':randint(5, 100, size=n_iter),\n",
    "                          'penalty':['l1','l2','elasticnet'],\n",
    "                          'l1_ratio':uniform(0.1,0.9, size=n_iter), \n",
    "                          'loss':['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "                          'power_t':uniform(0.1, size=n_iter),\n",
    "                          'alpha': [10**x for x in range(-8,-2)],\n",
    "                          'eta0': [10**x for x in range(-4,-1)],\n",
    "                          'learning_rate': [\"invscaling\", \"constant\", \"optimal\"]}\n",
    "\n",
    "    model.optimize(iterable_pos_train, iterable_neg_train, \n",
    "                   model_name=model_fname,\n",
    "                   n_active_learning_iterations=n_active_learning_iterations,\n",
    "                   size_positive=-1,\n",
    "                   size_negative=active_set_size,\n",
    "                   n_iter=n_iter, cv=3,\n",
    "                   pre_processor_parameters=pre_processor_parameters, \n",
    "                   vectorizer_parameters=vectorizer_parameters, \n",
    "                   estimator_parameters=estimator_parameters)\n",
    "    \n",
    "    #estimate predictive performance\n",
    "    model.estimate( iterable_pos_test, iterable_neg_test)\n",
    "    return model\n",
    "    \n",
    "    \n",
    "def test_obabel_model(fname, model_fname=None):\n",
    "    from eden.model import ActiveLearningBinaryClassificationModel\n",
    "\n",
    "    model = ActiveLearningBinaryClassificationModel()\n",
    "    model.load(model_fname)\n",
    "\n",
    "    #create iterable from files\n",
    "    from eden.converter.molecule import obabel\n",
    "    iterable=obabel.obabel_to_eden(fname)\n",
    "    \n",
    "    predictions= model.decision_function( iterable )\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.get_assay>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AID=720577\n",
    "#AID=2801\n",
    "get_assay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1) Processing compounds 0 to 49 (of a total of 80)\n",
      "Chunk 2) Processing compounds 50 to 99 (of a total of 80)\n",
      "compounds available in file:  AID720577_active.sdf\n",
      "Chunk 1) Processing compounds 0 to 49 (of a total of 146)\n",
      "Chunk 2) Processing compounds 50 to 99 (of a total of 146)\n",
      "Chunk 3) Processing compounds 100 to 149 (of a total of 146)\n",
      "compounds available in file:  AID720577_inactive.sdf\n",
      "CPU times: user 281 ms, sys: 22.9 ms, total: 304 ms\n",
      "Wall time: 41.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#READ_FROM_FILE=False\n",
    "READ_FROM_FILE=False\n",
    "\n",
    "if READ_FROM_FILE:\n",
    "    active_fname='data/AID%s_active.sdf'%AID\n",
    "    inactive_fname='data/AID%s_inactive.sdf'%AID\n",
    "else:\n",
    "    active_fname, inactive_fname = get_assay(AID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root.eden.model:\n",
      "\n",
      "\tIteration: 1/20 (after 4.2 sec; 0:00:04.199919)\n",
      "Best score (roc_auc): 0.415 (0.524 +- 0.109)\n",
      "\n",
      "Data:\n",
      "Instances: 158 ; Features: 1048577 with an avg of 160 features per instance\n",
      "class: 1 count:56 (0.35)\tclass: -1 count:102 (0.65)\t\n",
      "\n",
      "\tModel parameters:\n",
      "\n",
      "Pre_processor:\n",
      "     model_type: d\n",
      "\n",
      "Vectorizer:\n",
      "     complexity: 2\n",
      "\n",
      "Estimator:\n",
      "         n_iter: 90\n",
      "           eta0: 0.001\n",
      "           loss: modified_huber\n",
      "       l1_ratio: 0.696418251641\n",
      "  learning_rate: optimal\n",
      "        penalty: l1\n",
      "        power_t: 0.739454986921\n",
      "          alpha: 0.0001\n",
      "INFO:root.eden.model:\n",
      "\n",
      "\tIteration: 2/20 (after 7.5 sec; 0:00:07.499097)\n",
      "Best score (roc_auc): 0.434 (0.554 +- 0.120)\n",
      "\n",
      "Data:\n",
      "Instances: 158 ; Features: 1048577 with an avg of 160 features per instance\n",
      "class: 1 count:56 (0.35)\tclass: -1 count:102 (0.65)\t\n",
      "\n",
      "\tModel parameters:\n",
      "\n",
      "Pre_processor:\n",
      "     model_type: t\n",
      "\n",
      "Vectorizer:\n",
      "     complexity: 2\n",
      "\n",
      "Estimator:\n",
      "         n_iter: 46\n",
      "           eta0: 0.001\n",
      "           loss: squared_hinge\n",
      "       l1_ratio: 0.627743682694\n",
      "  learning_rate: optimal\n",
      "        penalty: elasticnet\n",
      "        power_t: 0.446143399888\n",
      "          alpha: 0.0001\n",
      "INFO:root.eden.model:\n",
      "\n",
      "\tIteration: 4/20 (after 18.3 sec; 0:00:18.261067)\n",
      "Best score (roc_auc): 0.490 (0.558 +- 0.068)\n",
      "\n",
      "Data:\n",
      "Instances: 158 ; Features: 1048577 with an avg of 160 features per instance\n",
      "class: 1 count:56 (0.35)\tclass: -1 count:102 (0.65)\t\n",
      "\n",
      "\tModel parameters:\n",
      "\n",
      "Pre_processor:\n",
      "     model_type: u\n",
      "\n",
      "Vectorizer:\n",
      "     complexity: 2\n",
      "\n",
      "Estimator:\n",
      "         n_iter: 27\n",
      "           eta0: 0.0001\n",
      "           loss: hinge\n",
      "       l1_ratio: 0.387152047652\n",
      "  learning_rate: constant\n",
      "        penalty: l1\n",
      "        power_t: 0.370037421973\n",
      "          alpha: 1e-07\n",
      "INFO:root.eden.model:\n",
      "\n",
      "\tIteration: 6/20 (after 36.2 sec; 0:00:36.185352)\n",
      "Best score (roc_auc): 0.538 (0.591 +- 0.053)\n",
      "\n",
      "Data:\n",
      "Instances: 158 ; Features: 1048577 with an avg of 598 features per instance\n",
      "class: 1 count:56 (0.35)\tclass: -1 count:102 (0.65)\t\n",
      "\n",
      "\tModel parameters:\n",
      "\n",
      "Pre_processor:\n",
      "     model_type: l\n",
      "\n",
      "Vectorizer:\n",
      "     complexity: 4\n",
      "\n",
      "Estimator:\n",
      "         n_iter: 82\n",
      "           eta0: 0.001\n",
      "           loss: modified_huber\n",
      "       l1_ratio: 0.282022456106\n",
      "  learning_rate: invscaling\n",
      "        penalty: l1\n",
      "        power_t: 0.581854853796\n",
      "          alpha: 0.001\n",
      "INFO:root.eden.model:\n",
      "\n",
      "\tIteration: 15/20 (after 93.1 sec; 0:01:33.089422)\n",
      "Best score (roc_auc): 0.554 (0.606 +- 0.052)\n",
      "\n",
      "Data:\n",
      "Instances: 158 ; Features: 1048577 with an avg of 598 features per instance\n",
      "class: 1 count:56 (0.35)\tclass: -1 count:102 (0.65)\t\n",
      "\n",
      "\tModel parameters:\n",
      "\n",
      "Pre_processor:\n",
      "     model_type: u\n",
      "\n",
      "Vectorizer:\n",
      "     complexity: 4\n",
      "\n",
      "Estimator:\n",
      "         n_iter: 46\n",
      "           eta0: 0.0001\n",
      "           loss: hinge\n",
      "       l1_ratio: 0.627743682694\n",
      "  learning_rate: optimal\n",
      "        penalty: l1\n",
      "        power_t: 0.370037421973\n",
      "          alpha: 0.0001\n",
      "INFO:root.eden.model:Saved current best model in models/AID720577.default_model\n",
      "INFO:root.eden.model:\n",
      "Classifier:\n",
      "SGDClassifier(alpha=0.0001, average=True, class_weight='auto', epsilon=0.1,\n",
      "       eta0=0.0001, fit_intercept=True, l1_ratio=0.62774368269373615,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=46, n_jobs=1,\n",
      "       penalty='l1', power_t=0.37003742197259182, random_state=None,\n",
      "       shuffle=True, verbose=0, warm_start=False)\n",
      "\n",
      "Data:\n",
      "Instances: 68 ; Features: 1048577 with an avg of 559 features per instance\n",
      "\n",
      "Predictive performace estimate:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.62      0.80      0.70        44\n",
      "          1       0.25      0.12      0.17        24\n",
      "\n",
      "avg / total       0.49      0.56      0.51        68\n",
      "\n",
      "APR: 0.326\n",
      "ROC: 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# positives: 80  # negatives: 146 (0.6 sec 0:00:00.579724)\n",
      "CPU times: user 1min 56s, sys: 2.33 s, total: 1min 58s\n",
      "Wall time: 1min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_fname='models/AID%s.default_model'%AID\n",
    "fitted_model = train_obabel_model(active_fname, inactive_fname, model_fname=model_fname, \n",
    "                           n_iter=20, \n",
    "                           active_set_size=0, \n",
    "                           n_active_learning_iterations=0, \n",
    "                           threshold=1, \n",
    "                           train_test_split=0.7, \n",
    "                           verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print fitted_model.get_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from eden.converter.molecule import obabel\n",
    "graphs=obabel.obabel_to_eden(active_fname,file_type = 'sdf')\n",
    "from itertools import islice\n",
    "graphs = islice(graphs, 3)\n",
    "from eden.util.display import draw_graph\n",
    "for graph in graphs:  draw_graph(graph, size=12, node_size=400, node_border=1, vertex_label='hlabel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on positive instances in AID2401_active.sdf and negative instances in AID2401_inactive.sdf\n"
     ]
    }
   ],
   "source": [
    "from eden.graph import Vectorizer\n",
    "vectorizer=Vectorizer(complexity=5, nbits=14)\n",
    "from eden.converter.molecule import obabel\n",
    "print 'Working on positive instances in %s and negative instances in %s' % (active_fname, inactive_fname)\n",
    "active_graphs=obabel.obabel_to_eden(active_fname)\n",
    "inactive_graphs=obabel.obabel_to_eden(inactive_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:\n",
      "SGDClassifier(alpha=0.000244367424549, average=True, class_weight='auto',\n",
      "       epsilon=0.1, eta0=0.391312945136, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='constant', loss='hinge', n_iter=29, n_jobs=-1,\n",
      "       penalty='l2', power_t=0.163214708985, random_state=None,\n",
      "       shuffle=True, verbose=0, warm_start=False)\n",
      "--------------------------------------------------------------------------------\n",
      "Predictive performance:\n",
      "            accuracy: 0.844 +- 0.051\n",
      "           precision: 0.726 +- 0.133\n",
      "              recall: 0.591 +- 0.119\n",
      "                  f1: 0.642 +- 0.102\n",
      "   average_precision: 0.722 +- 0.143\n",
      "             roc_auc: 0.867 +- 0.072\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.000244367424549, average=True, class_weight='auto',\n",
       "       epsilon=0.1, eta0=0.391312945136, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='constant', loss='hinge', n_iter=29, n_jobs=-1,\n",
       "       penalty='l2', power_t=0.163214708985, random_state=None,\n",
       "       shuffle=True, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from eden.util import fit\n",
    "fit(active_graphs,inactive_graphs, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.13 s, sys: 875 ms, total: 9 s\n",
      "Wall time: 26.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from eden import vectorize\n",
    "active_X = vectorize(active_graphs,vectorizer)\n",
    "inactive_X = vectorize(inactive_graphs,vectorizer)\n",
    "from scipy.sparse import vstack\n",
    "import numpy as np\n",
    "X=vstack( [active_X,inactive_X] )\n",
    "yp=[1]*active_X.shape[0]\n",
    "yn=[-1]*inactive_X.shape[0]\n",
    "y=np.array(yp+yn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC ROC: 0.8647 +- 0.0742\n",
      "CPU times: user 719 ms, sys: 148 ms, total: 867 ms\n",
      "Wall time: 866 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import cross_validation\n",
    "\n",
    "#induce a predictive model\n",
    "predictor = SGDClassifier(class_weight = 'auto', shuffle = True, average=True)\n",
    "scores = cross_validation.cross_val_score(predictor, X, y,cv=10, scoring='roc_auc')\n",
    "print('AUC ROC: %.4f +- %.4f' % (np.mean(scores),np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.534820064485\n",
      "CPU times: user 15.9 s, sys: 443 ms, total: 16.3 s\n",
      "Wall time: 13.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=500, random_state=42)\n",
    "Xd=svd.fit_transform(X) \n",
    "print(svd.explained_variance_ratio_.sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC ROC: 0.8606 +- 0.0690\n",
      "CPU times: user 202 ms, sys: 24.2 ms, total: 226 ms\n",
      "Wall time: 226 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import cross_validation\n",
    "\n",
    "#induce a predictive model\n",
    "predictor = SGDClassifier(class_weight = 'auto', shuffle = True, average=True)\n",
    "scores = cross_validation.cross_val_score(predictor, Xd, y,cv=10, scoring='roc_auc')\n",
    "print('AUC ROC: %.4f +- %.4f' % (np.mean(scores),np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
