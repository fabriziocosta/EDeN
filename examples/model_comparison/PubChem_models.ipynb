{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from eden.converter.molecule import obabel\n",
    "import logging\n",
    "logging.basicConfig(filename=\"example.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_compounds(fname, size, listkey):\n",
    "    PROLOG='https://pubchem.ncbi.nlm.nih.gov/rest/pug/'\n",
    "    with open(fname,'w') as file_handle:\n",
    "        stepsize=50\n",
    "        index_start=0\n",
    "        for chunk, index_end in enumerate(range(0,size+stepsize,stepsize)):\n",
    "            if index_end is not 0 :\n",
    "                print 'Chunk %s) Processing compounds %s to %s (of a total of %s)' % (chunk, index_start, index_end-1, size)\n",
    "                RESTQ = PROLOG + 'compound/listkey/' + str(listkey) + '/SDF?&listkey_start=' + str(index_start) + '&listkey_count=' + str(stepsize)\n",
    "                reply=requests.get(RESTQ)\n",
    "                file_handle.write(reply.text)\n",
    "            index_start = index_end\n",
    "        print 'compounds available in file: ', fname\n",
    "\n",
    "\n",
    "def get_assay(assay_id):\n",
    "    PROLOG='https://pubchem.ncbi.nlm.nih.gov/rest/pug/'\n",
    "    AID=str(assay_id)\n",
    "    #active\n",
    "    RESTQ = PROLOG + 'assay/aid/' + AID + '/cids/JSON?cids_type=active&list_return=listkey'\n",
    "    reply=requests.get(RESTQ)\n",
    "    #extract the listkey\n",
    "    active_listkey = reply.json()['IdentifierList']['ListKey']\n",
    "    active_size = reply.json()['IdentifierList']['Size'] \n",
    "    active_fname = 'data/AID'+AID+'_active.sdf'\n",
    "    get_compounds(fname=active_fname, size=active_size, listkey=active_listkey)\n",
    "\n",
    "    #inactive\n",
    "    RESTQ = PROLOG + 'assay/aid/' + AID + '/cids/JSON?cids_type=inactive&list_return=listkey'\n",
    "    reply=requests.get(RESTQ)\n",
    "    #extract the listkey\n",
    "    inactive_listkey = reply.json()['IdentifierList']['ListKey']\n",
    "    inactive_size = reply.json()['IdentifierList']['Size']\n",
    "    inactive_fname = 'data/AID'+AID+'_inactive.sdf'\n",
    "    get_compounds(fname=inactive_fname, size=inactive_size, listkey=inactive_listkey)\n",
    "\n",
    "    return (active_fname,inactive_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime, time\n",
    "def train_obabel_model(pos_fname, neg_fname, model_fname=None, n_iter=40, active_set_size=1000, n_active_learning_iterations=3, threshold=1, train_test_split=0.7, verbose=False):\n",
    "    \n",
    "    \n",
    "    def pre_processor( data, **args):\n",
    "        return data\n",
    "    \n",
    "    from eden.graph import Vectorizer\n",
    "    vectorizer = Vectorizer()\n",
    "\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "    estimator = SGDClassifier(average=True, class_weight='auto', shuffle=True)\n",
    "\n",
    "    #create iterable from files\n",
    "    from eden.converter.molecule import obabel\n",
    "    iterable_pos=obabel.obabel_to_eden(pos_fname)\n",
    "    iterable_neg=obabel.obabel_to_eden(neg_fname)\n",
    "    \n",
    "    from itertools import tee\n",
    "    iterable_pos, iterable_pos_ = tee(iterable_pos)\n",
    "    iterable_neg, iterable_neg_ = tee(iterable_neg)\n",
    "    \n",
    "    import time\n",
    "    start = time.time()\n",
    "    print('# positives: %d  # negatives: %d (%.1f sec %s)'%(sum(1 for x in iterable_pos_), sum(1 for x in iterable_neg_), time.time() - start, str(datetime.timedelta(seconds=(time.time() - start)))))\n",
    "    \n",
    "    #split train/test\n",
    "    from eden.util import random_bipartition_iter\n",
    "    iterable_pos_train, iterable_pos_test = random_bipartition_iter(iterable_pos, relative_size=train_test_split)\n",
    "    iterable_neg_train, iterable_neg_test = random_bipartition_iter(iterable_neg, relative_size=train_test_split)\n",
    "\n",
    "\n",
    "\n",
    "    #make predictive model\n",
    "    from eden.model import ActiveLearningBinaryClassificationModel\n",
    "    # model = ActiveLearningBinaryClassificationModel( pre_processor, estimator=estimator, vectorizer=vectorizer )\n",
    "    model = ActiveLearningBinaryClassificationModel(pre_processor,\n",
    "                                                estimator=estimator,\n",
    "                                                vectorizer=vectorizer,\n",
    "                                                n_jobs = 2,\n",
    "                                                n_blocks = 10,\n",
    "                                                fit_vectorizer=True)\n",
    " \n",
    "    from numpy.random import randint\n",
    "    from numpy.random import uniform\n",
    "\n",
    "    pre_processor_parameters={'model_type':'default'} \n",
    "    \n",
    "    # The training time for this model is much smaller, so we can use various iterations of the\n",
    "    # vectorizer\n",
    "    vectorizer_parameters={'complexity':[2,3,4,5,6]}\n",
    "\n",
    "    estimator_parameters={'n_iter':randint(5, 100, size=n_iter),\n",
    "                          'penalty':['l1','l2','elasticnet'],\n",
    "                          'l1_ratio':uniform(0.1,0.9, size=n_iter), \n",
    "                          'loss':['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "                          'power_t':uniform(0.1, size=n_iter),\n",
    "                          'alpha': [10**x for x in range(-8,-2)],\n",
    "                          'eta0': [10**x for x in range(-4,-1)],\n",
    "                          'learning_rate': [\"invscaling\", \"constant\", \"optimal\"]}\n",
    "\n",
    "    model.optimize(iterable_pos_train, iterable_neg_train, \n",
    "                   model_name=model_fname,\n",
    "                   n_active_learning_iterations=n_active_learning_iterations,\n",
    "                   size_positive=-1,\n",
    "                   size_negative=active_set_size,\n",
    "                   n_iter=n_iter, cv=3,\n",
    "                   pre_processor_parameters=pre_processor_parameters, \n",
    "                   vectorizer_parameters=vectorizer_parameters, \n",
    "                   estimator_parameters=estimator_parameters)\n",
    "    \n",
    "    #estimate predictive performance\n",
    "    model.estimate( iterable_pos_test, iterable_neg_test)\n",
    "    return model\n",
    "    \n",
    "    \n",
    "def test_obabel_model(fname, model_fname=None):\n",
    "    from eden.model import ActiveLearningBinaryClassificationModel\n",
    "\n",
    "    model = ActiveLearningBinaryClassificationModel()\n",
    "    model.load(model_fname)\n",
    "\n",
    "    #create iterable from files\n",
    "    from eden.converter.molecule import obabel\n",
    "    iterable=obabel.obabel_to_eden(fname)\n",
    "    \n",
    "    predictions= model.decision_function( iterable )\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AID=720577\n",
    "#AID=2801"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1) Processing compounds 0 to 49 (of a total of 80)\n",
      "Chunk 2) Processing compounds 50 to 99 (of a total of 80)\n",
      "compounds available in file:  data/AID720577_active.sdf\n",
      "Chunk 1) Processing compounds 0 to 49 (of a total of 146)\n",
      "Chunk 2) Processing compounds 50 to 99 (of a total of 146)\n",
      "Chunk 3) Processing compounds 100 to 149 (of a total of 146)\n",
      "compounds available in file:  data/AID720577_inactive.sdf\n",
      "CPU times: user 230 ms, sys: 17 ms, total: 247 ms\n",
      "Wall time: 35.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#READ_FROM_FILE=False\n",
    "READ_FROM_FILE=False\n",
    "\n",
    "if READ_FROM_FILE:\n",
    "    active_fname='data/AID%s_active.sdf'%AID\n",
    "    inactive_fname='data/AID%s_inactive.sdf'%AID\n",
    "else:\n",
    "    active_fname, inactive_fname = get_assay(AID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root.eden.model:\n",
      "\n",
      "\tIteration: 1/20 (after 3.8 sec; 0:00:03.777023)\n",
      "Best score (roc_auc): 0.423 (0.574 +- 0.151)\n",
      "\n",
      "Data:\n",
      "Instances: 158 ; Features: 1048577 with an avg of 160 features per instance\n",
      "class: 1 count:56 (0.35)\tclass: -1 count:102 (0.65)\t\n",
      "\n",
      "\tModel parameters:\n",
      "\n",
      "Pre_processor:\n",
      "     model_type: d\n",
      "\n",
      "Vectorizer:\n",
      "     complexity: 2\n",
      "\n",
      "Estimator:\n",
      "         n_iter: 44\n",
      "           eta0: 0.001\n",
      "           loss: modified_huber\n",
      "       l1_ratio: 0.38216035311\n",
      "  learning_rate: optimal\n",
      "        penalty: l1\n",
      "        power_t: 0.342280171631\n",
      "          alpha: 0.0001\n",
      "INFO:root.eden.model:\n",
      "\n",
      "\tIteration: 3/20 (after 15.4 sec; 0:00:15.407195)\n",
      "Best score (roc_auc): 0.458 (0.505 +- 0.047)\n",
      "\n",
      "Data:\n",
      "Instances: 158 ; Features: 1048577 with an avg of 600 features per instance\n",
      "class: 1 count:56 (0.35)\tclass: -1 count:102 (0.65)\t\n",
      "\n",
      "\tModel parameters:\n",
      "\n",
      "Pre_processor:\n",
      "     model_type: a\n",
      "\n",
      "Vectorizer:\n",
      "     complexity: 4\n",
      "\n",
      "Estimator:\n",
      "         n_iter: 35\n",
      "           eta0: 0.0001\n",
      "           loss: modified_huber\n",
      "       l1_ratio: 0.2519667605\n",
      "  learning_rate: invscaling\n",
      "        penalty: l1\n",
      "        power_t: 0.587848191615\n",
      "          alpha: 0.001\n",
      "INFO:root.eden.model:\n",
      "\n",
      "\tIteration: 7/20 (after 44.9 sec; 0:00:44.897048)\n",
      "Best score (roc_auc): 0.477 (0.566 +- 0.088)\n",
      "\n",
      "Data:\n",
      "Instances: 158 ; Features: 1048577 with an avg of 349 features per instance\n",
      "class: 1 count:56 (0.35)\tclass: -1 count:102 (0.65)\t\n",
      "\n",
      "\tModel parameters:\n",
      "\n",
      "Pre_processor:\n",
      "     model_type: a\n",
      "\n",
      "Vectorizer:\n",
      "     complexity: 3\n",
      "\n",
      "Estimator:\n",
      "         n_iter: 35\n",
      "           eta0: 0.001\n",
      "           loss: modified_huber\n",
      "       l1_ratio: 0.543009075452\n",
      "  learning_rate: optimal\n",
      "        penalty: l1\n",
      "        power_t: 0.786804743427\n",
      "          alpha: 0.0001\n",
      "INFO:root.eden.model:\n",
      "\n",
      "\tIteration: 12/20 (after 88.0 sec; 0:01:28.008488)\n",
      "Best score (roc_auc): 0.495 (0.552 +- 0.058)\n",
      "\n",
      "Data:\n",
      "Instances: 158 ; Features: 1048577 with an avg of 349 features per instance\n",
      "class: 1 count:56 (0.35)\tclass: -1 count:102 (0.65)\t\n",
      "\n",
      "\tModel parameters:\n",
      "\n",
      "Pre_processor:\n",
      "     model_type: a\n",
      "\n",
      "Vectorizer:\n",
      "     complexity: 3\n",
      "\n",
      "Estimator:\n",
      "         n_iter: 35\n",
      "           eta0: 0.0001\n",
      "           loss: modified_huber\n",
      "       l1_ratio: 0.2519667605\n",
      "  learning_rate: invscaling\n",
      "        penalty: l1\n",
      "        power_t: 0.786804743427\n",
      "          alpha: 0.0001\n",
      "INFO:root.eden.model:\n",
      "\n",
      "\tIteration: 16/20 (after 109.3 sec; 0:01:49.259753)\n",
      "Best score (roc_auc): 0.535 (0.577 +- 0.041)\n",
      "\n",
      "Data:\n",
      "Instances: 158 ; Features: 1048577 with an avg of 349 features per instance\n",
      "class: 1 count:56 (0.35)\tclass: -1 count:102 (0.65)\t\n",
      "\n",
      "\tModel parameters:\n",
      "\n",
      "Pre_processor:\n",
      "     model_type: a\n",
      "\n",
      "Vectorizer:\n",
      "     complexity: 3\n",
      "\n",
      "Estimator:\n",
      "         n_iter: 35\n",
      "           eta0: 0.0001\n",
      "           loss: modified_huber\n",
      "       l1_ratio: 0.2519667605\n",
      "  learning_rate: invscaling\n",
      "        penalty: l1\n",
      "        power_t: 0.786804743427\n",
      "          alpha: 0.0001\n",
      "INFO:root.eden.model:Saved current best model in models/AID720577.default_model\n",
      "INFO:root.eden.model:\n",
      "Classifier:\n",
      "SGDClassifier(alpha=0.0001, average=True, class_weight='auto', epsilon=0.1,\n",
      "       eta0=0.0001, fit_intercept=True, l1_ratio=0.25196676049993394,\n",
      "       learning_rate='invscaling', loss='modified_huber', n_iter=35,\n",
      "       n_jobs=1, penalty='l1', power_t=0.78680474342733164,\n",
      "       random_state=None, shuffle=True, verbose=0, warm_start=False)\n",
      "\n",
      "Data:\n",
      "Instances: 68 ; Features: 1048577 with an avg of 326 features per instance\n",
      "\n",
      "Predictive performace estimate:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.70      1.00      0.82        44\n",
      "          1       1.00      0.21      0.34        24\n",
      "\n",
      "avg / total       0.80      0.72      0.65        68\n",
      "\n",
      "APR: 0.741\n",
      "ROC: 0.812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# positives: 80  # negatives: 146 (0.5 sec 0:00:00.506782)\n",
      "CPU times: user 2min 14s, sys: 531 ms, total: 2min 14s\n",
      "Wall time: 2min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_fname='models/AID%s.default_model'%AID\n",
    "fitted_model = train_obabel_model(active_fname, inactive_fname, model_fname=model_fname, \n",
    "                           n_iter=20, \n",
    "                           active_set_size=0, \n",
    "                           n_active_learning_iterations=0, \n",
    "                           threshold=1, \n",
    "                           train_test_split=0.7, \n",
    "                           verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tModel parameters:\n",
      "\n",
      "Pre_processor:\n",
      "     model_type: a\n",
      "\n",
      "Vectorizer:\n",
      "     complexity: 3\n",
      "\n",
      "Estimator:\n",
      "         n_iter: 35\n",
      "           eta0: 0.0001\n",
      "           loss: modified_huber\n",
      "       l1_ratio: 0.2519667605\n",
      "  learning_rate: invscaling\n",
      "        penalty: l1\n",
      "        power_t: 0.786804743427\n",
      "          alpha: 0.0001\n"
     ]
    }
   ],
   "source": [
    "print fitted_model.get_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "('requires pygraphviz ', 'http://networkx.lanl.gov/pygraphviz ', '(not available for Python3)')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-39aede763602>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgraphs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mislice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0meden\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdraw_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mgraph\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[0mdraw_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_border\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvertex_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'hlabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/liconj/proj/thesis/EDeN/eden/util/display.pyc\u001b[0m in \u001b[0;36mdraw_graph\u001b[1;34m(graph, vertex_label, secondary_vertex_label, edge_label, secondary_edge_label, vertex_color, vertex_alpha, size, size_x_to_y_ratio, node_size, font_size, layout, prog, node_border, colormap, invert_colormap, verbose, file_name)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlayout\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'graphviz'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraphviz_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mlayout\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'circular'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcircular_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/liconj/.local/lib/python2.7/site-packages/networkx/drawing/nx_agraph.pyc\u001b[0m in \u001b[0;36mgraphviz_layout\u001b[1;34m(G, prog, root, args)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m     \"\"\"\n\u001b[1;32m--> 229\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mpygraphviz_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpygraphviz_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'neato'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/liconj/.local/lib/python2.7/site-packages/networkx/drawing/nx_agraph.pyc\u001b[0m in \u001b[0;36mpygraphviz_layout\u001b[1;34m(G, prog, root, args)\u001b[0m\n\u001b[0;32m    258\u001b[0m         raise ImportError('requires pygraphviz ',\n\u001b[0;32m    259\u001b[0m                           \u001b[1;34m'http://networkx.lanl.gov/pygraphviz '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m                           '(not available for Python3)')\n\u001b[0m\u001b[0;32m    261\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mroot\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;34m\"-Groot=%s\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: ('requires pygraphviz ', 'http://networkx.lanl.gov/pygraphviz ', '(not available for Python3)')"
     ]
    }
   ],
   "source": [
    "from eden.converter.molecule import obabel\n",
    "graphs=obabel.obabel_to_eden(active_fname,file_type = 'sdf')\n",
    "from itertools import islice\n",
    "graphs = islice(graphs, 3)\n",
    "from eden.util.display import draw_graph\n",
    "for graph in graphs:  draw_graph(graph, size=12, node_size=400, node_border=1, vertex_label='hlabel')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
