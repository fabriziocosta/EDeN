{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from eden.converter.molecule import obabel\n",
    "import networkx as nx\n",
    "import pybel\n",
    "import requests\n",
    "import os.path\n",
    "from itertools import tee\n",
    "from numpy.random import randint\n",
    "from numpy.random import uniform\n",
    "from eden.graph import Vectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import datetime, time\n",
    "from eden.util import random_bipartition_iter\n",
    "from eden.model import ActiveLearningBinaryClassificationModel\n",
    "\n",
    "from eden.util import configure_logging\n",
    "import logging\n",
    "configure_logging(logging.getLogger(),verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where the data sets are defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AID = 602325\n",
    "#AID=2401\n",
    "DATA_DIR = '/home/liconj/proj/thesis/EDeN/examples/model_comparison/data'\n",
    "active_fname=DATA_DIR + '/AID%s_active.sdf'%AID\n",
    "inactive_fname=DATA_DIR + '/AID%s_inactive.sdf'%AID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for training and testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_fname = DATA_DIR + '/AID%s.model3d'%AID\n",
    "model_type = \"3d\"\n",
    "n_conf = 10\n",
    "n_iter = 10\n",
    "active_set_size = 5\n",
    "n_active_learning_iterations = 0\n",
    "threshold = 1\n",
    "train_test_split = 0.8\n",
    "\n",
    "pre_processor_parameters={'k':randint(1, 10,size=n_iter),\n",
    "                          'threshold':randint(3, 10, size=n_iter),\n",
    "                          'n_conf':[n_conf]}\n",
    "\n",
    "def pre_processor(data, model_type=\"3d\", **kwargs):\n",
    "    # model_type = kwargs.get('mode', 'default')\n",
    "    if model_type == \"default\":\n",
    "        iterable = obabel.obabel_to_eden(data, **kwargs)\n",
    "    elif model_type == \"3d\":\n",
    "        iterable = obabel.obabel_to_eden3d(data, **kwargs)\n",
    "    return iterable\n",
    "\n",
    "\n",
    "\n",
    "vectorizer = Vectorizer()\n",
    "estimator = SGDClassifier(class_weight='auto', shuffle=True)\n",
    "\n",
    "# Make predictive model\n",
    "model = ActiveLearningBinaryClassificationModel(pre_processor,\n",
    "                                                estimator=estimator,\n",
    "                                                vectorizer=vectorizer,\n",
    "                                                n_jobs = 1,\n",
    "                                                n_blocks = 2,\n",
    "                                                fit_vectorizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# positives: 80  # negatives: 146 (0.1 sec 0:00:00.057244)\n"
     ]
    }
   ],
   "source": [
    "########\n",
    "# Create iterables from files\n",
    "########\n",
    "\n",
    "iterable_pos = obabel.make_iterable('AID720577_active.sdf', 'sdf')\n",
    "iterable_neg = obabel.make_iterable('AID720577_inactive.sdf', 'sdf')\n",
    "iterable_pos, iterable_pos_ = tee(iterable_pos)\n",
    "iterable_neg, iterable_neg_ = tee(iterable_neg)\n",
    "\n",
    "start = time.time()\n",
    "print('# positives: %d  # negatives: %d (%.1f sec %s)'%(sum(1 for x in iterable_pos_), sum(1 for x in iterable_neg_), time.time() - start, str(datetime.timedelta(seconds=(time.time() - start)))))\n",
    "\n",
    "\n",
    "iterable_pos, iterable_pos_ = tee(iterable_pos)\n",
    "iterable_neg, iterable_neg_ = tee(iterable_neg)\n",
    "\n",
    "# Split train/test\n",
    "iterable_pos_train, iterable_pos_test = random_bipartition_iter(iterable_pos, relative_size=train_test_split)\n",
    "iterable_neg_train, iterable_neg_test = random_bipartition_iter(iterable_neg, relative_size=train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC ROC: 0.9955 +- 0.0097\n"
     ]
    }
   ],
   "source": [
    "########\n",
    "# Create iterables with the pre_processor\n",
    "########\n",
    "\n",
    "pos_graphs = pre_processor(iterable_pos_train, \"3d\")\n",
    "neg_graphs = pre_processor(iterable_neg_train, \"3d\")\n",
    "\n",
    "########\n",
    "# Fit vectorizer\n",
    "########\n",
    "from eden.graph import Vectorizer\n",
    "vectorizer = Vectorizer(complexity=1, n=3)\n",
    "\n",
    "Xp = vectorizer.fit_transform(pos_graphs)\n",
    "Xn= vectorizer.fit_transform(neg_graphs)\n",
    "\n",
    "import numpy as np\n",
    "yp = [1] * Xp.shape[0]\n",
    "yn = [-1] * Xn.shape[0]\n",
    "y = np.array(yp + yn)\n",
    "from scipy.sparse import vstack\n",
    "X = vstack([Xp,Xn], format=\"csr\")\n",
    "\n",
    "#induce a predictive model\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "predictor = SGDClassifier(average=True, class_weight='auto', shuffle=True, n_jobs=-1)\n",
    "\n",
    "from sklearn import cross_validation\n",
    "scores = cross_validation.cross_val_score(predictor, X, y, cv=10, scoring='roc_auc')\n",
    "\n",
    "import numpy as np\n",
    "print('AUC ROC: %.4f +- %.4f' % (np.mean(scores),np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\tParameters range:\n",
      "\n",
      "Pre_processor:\n",
      "         k: [2 4 8 7 5 4 2 1 8 7]\n",
      "    n_conf: [10]\n",
      " threshold: [6 5 8 7 5 3 4 7 4 3]\n",
      "\n",
      "Vectorizer:\n",
      "complexity: [1]\n",
      "         n: 3\n",
      "\n",
      "Estimator:\n",
      "     alpha: [1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001]\n",
      "      eta0: [0.0001, 0.001, 0.01]\n",
      "  l1_ratio: [ 0.14382132  0.89052985  0.88810926  0.81740331  0.4980864   0.73702012\n",
      "  0.87434349  0.7683658   0.72780085  0.54732058]\n",
      "learning_rate: ['invscaling', 'constant', 'optimal']\n",
      "      loss: ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron']\n",
      "    n_iter: [58 56 13 48 17 20 29 99 73 64]\n",
      "   penalty: ['l1', 'l2', 'elasticnet']\n",
      "   power_t: [ 0.79322316  0.74672044  0.21021533  0.92491762  0.14952556  0.64267232\n",
      "  0.29765783  0.83633371  0.11844824  0.94797485]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-36ac14894a69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu'# Optimize hyperparameters and fit model\\n# Since this model is fitted much more slowly, use a single vectorizer\\n#vectorizer_parameters={\\'complexity\\':[2,3,4],\\n#                       \\'discretization_size\\':randint(2, 3,size=n_iter),\\n#                       \\'discretization_dimension\\':randint(2, 3,size=n_iter)}\\n\\n\\n\\n\\nestimator_parameters={\\'n_iter\\':randint(5, 100, size=n_iter),\\n                      \\'penalty\\':[\\'l1\\',\\'l2\\',\\'elasticnet\\'],\\n                      \\'l1_ratio\\':uniform(0.1,0.9, size=n_iter),\\n                      \\'loss\\':[\\'hinge\\', \\'log\\', \\'modified_huber\\', \\'squared_hinge\\', \\'perceptron\\'],\\n                      \\'power_t\\':uniform(0.1, size=n_iter),\\n                      \\'alpha\\': [10**x for x in range(-8,-2)],\\n                      \\'eta0\\': [10**x for x in range(-4,-1)],\\n                      \\'learning_rate\\': [\"invscaling\", \"constant\", \"optimal\"]}\\n\\nmodel.optimize(iterable_pos_train, iterable_neg_train,\\n               model_name=model_fname,\\n               n_active_learning_iterations=0,\\n               size_positive=-1,\\n               size_negative=active_set_size,\\n               n_iter=n_iter, cv=3,\\n               pre_processor_parameters=pre_processor_parameters,\\n               vectorizer_parameters=vectorizer_parameters,\\n               estimator_parameters=estimator_parameters)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/liconj/.local/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2262\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2263\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2264\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2265\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/liconj/.local/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32m/home/liconj/.local/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/liconj/.local/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1164\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1165\u001b[0m             \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1166\u001b[1;33m             \u001b[1;32mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1167\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m/home/liconj/proj/thesis/EDeN/eden/model.pyc\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, iterable_pos, iterable_neg, model_name, n_active_learning_iterations, size_positive, size_negative, lower_bound_threshold_positive, upper_bound_threshold_positive, lower_bound_threshold_negative, upper_bound_threshold_negative, n_iter, n_inner_iter_estimator, max_total_time, pre_processor_parameters, vectorizer_parameters, estimator_parameters, cv, scoring, score_func, two_steps_optimization)\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[0mmean_len_vectorizer_parameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m                 \u001b[0mmean_len_vectorizer_parameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectorizer_parameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvectorizer_parameters\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmean_len_pre_processor_parameters\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mmean_len_pre_processor_parameters\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmean_len_vectorizer_parameters\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mmean_len_vectorizer_parameters\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m                 \u001b[0mdata_matrix_is_stable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Optimize hyperparameters and fit model\n",
    "# Since this model is fitted much more slowly, use a single vectorizer\n",
    "#vectorizer_parameters={'complexity':[2,3,4],\n",
    "#                       'discretization_size':randint(2, 3,size=n_iter),\n",
    "#                       'discretization_dimension':randint(2, 3,size=n_iter)}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "estimator_parameters={'n_iter':randint(5, 100, size=n_iter),\n",
    "                      'penalty':['l1','l2','elasticnet'],\n",
    "                      'l1_ratio':uniform(0.1,0.9, size=n_iter),\n",
    "                      'loss':['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "                      'power_t':uniform(0.1, size=n_iter),\n",
    "                      'alpha': [10**x for x in range(-8,-2)],\n",
    "                      'eta0': [10**x for x in range(-4,-1)],\n",
    "                      'learning_rate': [\"invscaling\", \"constant\", \"optimal\"]}\n",
    "\n",
    "model.optimize(iterable_pos_train, iterable_neg_train,\n",
    "               model_name=model_fname,\n",
    "               n_active_learning_iterations=0,\n",
    "               size_positive=-1,\n",
    "               size_negative=active_set_size,\n",
    "               n_iter=n_iter, cv=3,\n",
    "               pre_processor_parameters=pre_processor_parameters,\n",
    "               vectorizer_parameters=vectorizer_parameters,\n",
    "               estimator_parameters=estimator_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Estimate predictive performance\n",
    "model.estimate( iterable_pos_test, iterable_neg_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_obabel_model(fname, model_type = \"default\", model_fname=None):\n",
    "    from eden.model import ActiveLearningBinaryClassificationModel\n",
    "\n",
    "    model = ActiveLearningBinaryClassificationModel()\n",
    "    model.load(model_fname)\n",
    "\n",
    "    #create iterable from files\n",
    "    from eden.converter.molecule import obabel\n",
    "    if model_type == \"default\":\n",
    "        iterable=obabel.obabel_to_eden(fname)\n",
    "    elif model_type == \"3d\":\n",
    "        iterable=obabel.obabel_to_eden3d(fname)\n",
    "\n",
    "    predictions= model.decision_function( iterable )\n",
    "\n",
    "    return predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
