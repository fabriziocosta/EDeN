{
 "metadata": {
  "name": "",
  "signature": "sha256:0d6beb2b378634fdcbe1d77ca5fe5d2599a1ee4169b643bf2943611fa8fa082f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "auxiliary functions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import itertools\n",
      "def join_pre_processes( data, pre_processes, weights):\n",
      "    if hasattr( data, '__iter__' ):\n",
      "        iterable = data\n",
      "    else: #if not then process url or file with fasta_to_fasta\n",
      "        from eden.modifier.fasta import fasta_to_fasta\n",
      "        iterable = fasta_to_fasta( data )\n",
      "    from eden import util\n",
      "    return util.join_pre_processes(iterable, pre_processes=pre_processes, weights=weights)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def out_of_core_predict(data, estimator = None, vectorizer = None):\n",
      "    from eden.graph import OutOfCoreListPredictor\n",
      "    estimator\n",
      "    vectorizer\n",
      "    out_of_core_predictor = OutOfCoreListPredictor( estimator = estimator, vectorizer = vectorizer )\n",
      "\n",
      "    #extract oneline fasta\n",
      "    from eden.modifier.fasta import fasta_to_fasta, remove_modifier\n",
      "    seqs = fasta_to_fasta( data, modifier = remove_modifier, remove_char = '-' )\n",
      "    from eden.modifier.fasta import fasta_to_fasta, one_line_modifier\n",
      "    fasta_seqs = fasta_to_fasta( seqs, modifier = one_line_modifier, one_line = True, one_line_separator = '\\t' )\n",
      "\n",
      "    #extract graphs\n",
      "    graphs_list, weights = pre_process( data )\n",
      "\n",
      "    #sort and store prediction-fasta pairs\n",
      "    import itertools as it \n",
      "    results = sorted([(line, prediction) for line, prediction in it.izip(fasta_seqs, out_of_core_predictor.predict(graphs_list, weights = weights))], key=lambda val: val[1] , reverse=True)\n",
      "\n",
      "    return results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Domain specific conversion"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#data sources\n",
      "posf  = 'http://share.gruenings.eu/schilling/mmp2-training-final_noMinus.fasta'\n",
      "negf  = 'http://share.gruenings.eu/schilling/human-shuffled.fasta'\n",
      "testf = 'http://share.gruenings.eu/schilling//Mmp2-CTSL-VALIDATE-final_noMinue.fasta'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from urllib import urlretrieve\n",
      "import pickle\n",
      "urlretrieve (\"http://www.bioinf.uni-freiburg.de/~costa/BLOSUM62_5D_encoding_dict.p\", \"BLOSUM62_5D_encoding_dict.p\")\n",
      "aa_encoding_dict5D = pickle.load( open( \"BLOSUM62_5D_encoding_dict.p\", \"rb\" ) )\n",
      "\n",
      "#add encoding for landmarks\n",
      "landmark_encodings = {'%':[10,0,0,0,0], '#':[0,10,0,0,0], '$':[0,0,10,0,0]}\n",
      "aa_encoding_dict5D.update(landmark_encodings)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_jobs = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_process_aa_categorical( iterable ):\n",
      "    #skip fasta entries that contain the '-' symbol\n",
      "    from eden.modifier.fasta import fasta_to_fasta\n",
      "    seqs = fasta_to_fasta( iterable )\n",
      "    \n",
      "    #insert landmark in the cleavage site after pos 4, in our case this means always in the middle position\n",
      "    from eden.modifier.fasta import fasta_to_fasta, insert_landmark_modifier\n",
      "    seqs = fasta_to_fasta( seqs, modifier = insert_landmark_modifier, landmark_relative_position = 0.5, landmark_char = '%' )\n",
      "    seqs = fasta_to_fasta( seqs, modifier = insert_landmark_modifier, landmark_relative_position = 0, landmark_char = '#' )\n",
      "    seqs = fasta_to_fasta( seqs, modifier = insert_landmark_modifier, landmark_relative_position = 1, landmark_char = '$' )\n",
      "\n",
      "    #convert to graph\n",
      "    from eden.converter.fasta import fasta_to_eden\n",
      "    graphs = fasta_to_eden( seqs )\n",
      "    \n",
      "    return graphs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_process_aa_smoothed( iterable ):\n",
      "    #skip fasta entries that contain the '-' symbol\n",
      "    from eden.modifier.fasta import fasta_to_fasta\n",
      "    seqs = fasta_to_fasta( iterable )\n",
      "    \n",
      "    #insert landmark in the cleavage site after pos 4, in our case this means always in the middle position\n",
      "    from eden.modifier.fasta import fasta_to_fasta, insert_landmark_modifier\n",
      "    seqs = fasta_to_fasta( seqs, modifier = insert_landmark_modifier, landmark_relative_position = 0.5, landmark_char = '%' )\n",
      "    seqs = fasta_to_fasta( seqs, modifier = insert_landmark_modifier, landmark_relative_position = 0, landmark_char = '#' )\n",
      "    seqs = fasta_to_fasta( seqs, modifier = insert_landmark_modifier, landmark_relative_position = 1, landmark_char = '$' )\n",
      "\n",
      "    #convert to graph\n",
      "    from eden.converter.fasta import fasta_to_eden\n",
      "    graphs = fasta_to_eden( seqs )\n",
      "    \n",
      "    #relabel aa with vector encoding\n",
      "    from eden.modifier.graph.vertex_attributes import translate \n",
      "    graphs = translate(graphs, label_map = aa_encoding_dict5D, default = [0,0,0,0,0])\n",
      "    \n",
      "    return graphs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_process( data ):\n",
      "    weights = [0.7, 0.3]\n",
      "    pre_processes = [pre_process_aa_categorical, pre_process_aa_smoothed]\n",
      "    return join_pre_processes( data, pre_processes, weights)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def describe(X):\n",
      "    print 'Instances: %d ; Features: %d (with an avg of %d features per instance)' % (X.shape[0], X.shape[1],  X.getnnz()/X.shape[0])\n",
      "    \n",
      "def list_model(uri, pre_process):\n",
      "\n",
      "    from eden.graph import ListVectorizer\n",
      "    vectorizer = ListVectorizer( r=2, d = 5, min_r = 0, discretization_size = 5, discretization_dimension = 10)\n",
      "    n_jobs = -1\n",
      "\n",
      "    graphs_list, weights = pre_process( uri )\n",
      "    vectorizer.fit( graphs_list, n_jobs = n_jobs )\n",
      "    X1 = vectorizer.transform( graphs_list, weights=weights, n_jobs=n_jobs )\n",
      "    describe(X1)\n",
      "    \n",
      "    from eden.modifier.fasta import fasta_to_fasta, shuffle_modifier\n",
      "    graphs_list, weights = pre_process( fasta_to_fasta( uri , modifier=shuffle_modifier, times=2, order=2) )\n",
      "    X2 = vectorizer.transform( graphs_list, weights=weights, n_jobs=n_jobs )\n",
      "    describe(X2)\n",
      "    \n",
      "    from eden.util import fit_estimator\n",
      "    estimator = fit_estimator( positive_data_matrix=X1, negative_data_matrix=X2, cv=5 )\n",
      "    \n",
      "    return estimator, vectorizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "estimator, vectorizer = list_model(posf, pre_process)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "results = out_of_core_predict(testf, estimator = estimator, vectorizer = vectorizer)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from ipy_table import * \n",
      "\n",
      "mat=[('ID','Conf')]\n",
      "mat += results\n",
      "make_table(mat)\n",
      "apply_theme('basic')\n",
      "set_global_style(float_format = '%0.3f')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "results_neg = out_of_core_predict(negf, estimator = estimator, vectorizer = vectorizer)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#extract top-k difficult sequences\n",
      "negative_to_positive_ratio = 10\n",
      "num_pos = X1.shape[0]\n",
      "num = int( num_pos * negative_to_positive_ratio )\n",
      "print 'Selecting top %d most difficult to discriminate instances'%num\n",
      "from itertools import chain\n",
      "selected_seqs = list(chain.from_iterable(line.split('\\t') for line, prediction in results_neg[:num]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "graphs_list, weights = pre_process( selected_seqs )\n",
      "X3 = vectorizer.transform( graphs_list, weights = weights, n_jobs = n_jobs )\n",
      "print 'Instances: %d ; Features: %d with an avg of %d features per instance' % (X3.shape[0], X3.shape[1],  X3.getnnz()/X3.shape[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "X,y = make_data_matrix(X1,X3)\n",
      "estimator2 = estimate_predictive_performance(X,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "results2 = out_of_core_predict(testf, estimator = estimator2, vectorizer = vectorizer)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from ipy_table import * \n",
      "\n",
      "mat=[('ID','Conf')]\n",
      "mat += results2\n",
      "make_table(mat)\n",
      "apply_theme('basic')\n",
      "set_global_style(float_format = '%0.3f')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}