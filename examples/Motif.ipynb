{
 "metadata": {
  "name": "",
  "signature": "sha256:f64b5012d75d7b973e214e264b1731eab8fbaed7d2223e948b2602bec3b505dd"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Aim\n",
      "\n",
      "Given a large set of sequences or graphs with ordered vertices find small vertex ordered subsequences that are most discriminative for the set.\n",
      "\n",
      "Steps:\n",
      "- devise a negative set\n",
      "- learn a discriminative model\n",
      "- annotate importance on vertices\n",
      "- extract max subarrays \n",
      "- cluster them \n",
      " - use fast EDeN string kernel \n",
      " - LSHForest\n",
      " - custom incremental cluster"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#code for making artificial dataset\n",
      "import random\n",
      "def random_string(length,alphabet_list):\n",
      "    rand_str = ''.join(random.choice(alphabet_list) for i in range(length))\n",
      "    return rand_str\n",
      "\n",
      "def perturb(seed,alphabet_list,p=0.5):\n",
      "    seq=''\n",
      "    for c in seed:\n",
      "        if random.random() < p: c = random.choice(alphabet_list)\n",
      "        seq += c\n",
      "    return seq\n",
      "\n",
      "def make_artificial_dataset(alphabet='ACGU', motives=None, motif_length=6, sequence_length=100, n_sequences=1000, n_motives=2, p=0.2):\n",
      "    alphabet_list=[c for c in alphabet]\n",
      "    \n",
      "    if motives is None:\n",
      "        motives=[]\n",
      "        for i in range(n_motives):\n",
      "            motives.append(random_string(motif_length,alphabet_list))\n",
      "    else:\n",
      "        motif_length = len(motives[0])\n",
      "        n_motives = len(motives)\n",
      "        \n",
      "    flanking_length = (sequence_length - motif_length ) / 2\n",
      "    n_seq_per_motif = n_sequences / n_motives\n",
      "\n",
      "    counter=0\n",
      "    seqs=[]\n",
      "    for i in range(n_seq_per_motif):\n",
      "        for j in range(n_motives):\n",
      "            left_flanking = random_string(flanking_length,alphabet_list)\n",
      "            right_flanking = random_string(flanking_length,alphabet_list)\n",
      "            noisy_motif = perturb(motives[j],alphabet_list,p)\n",
      "            seq = left_flanking + noisy_motif + right_flanking\n",
      "            seqs.append(('>ID%d'%counter,seq))\n",
      "            counter += 1\n",
      "    return motives, seqs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def vectorize_sequences(seqs, vectorizer=None, negative_ratio=2):\n",
      "    #duplicate iterator\n",
      "    from itertools import tee\n",
      "    seqs,seqs_=tee(seqs)\n",
      "    #make graphs for pos\n",
      "    from eden.converter.fasta import sequence_to_eden\n",
      "    iterable_pos = sequence_to_eden(seqs)\n",
      "    #shuffle seqs to obtain negatives\n",
      "    from eden.modifier.seq import seq_to_seq, shuffle_modifier\n",
      "    seqs_neg = seq_to_seq( seqs_, modifier=shuffle_modifier, times=negative_ratio, order=2 )\n",
      "    #make graphs for negs\n",
      "    from eden.converter.fasta import sequence_to_eden\n",
      "    iterable_neg = sequence_to_eden(seqs_neg)\n",
      "    #build data matrix\n",
      "    from eden import vectorize\n",
      "    X_pos = vectorize(iterable_pos, vectorizer=vectorizer)\n",
      "    X_neg = vectorize(iterable_neg, vectorizer=vectorizer)\n",
      "    import numpy as np\n",
      "    from scipy.sparse import vstack\n",
      "    yp = [1] * X_pos.shape[0]\n",
      "    yn = [-1] * X_neg.shape[0]\n",
      "    y = np.array(yp + yn)\n",
      "    X = vstack([X_pos, X_neg], format=\"csr\")\n",
      "    return X,y\n",
      "    \n",
      "def fit_predictive_model(seqs, vectorizer=None, negative_ratio=2):\n",
      "    X,y = vectorize_sequences(seqs, vectorizer=vectorizer, negative_ratio=negative_ratio)\n",
      "    #fit predictive model\n",
      "    from sklearn.linear_model import SGDClassifier\n",
      "    estimator = SGDClassifier(average=True, class_weight='auto', shuffle=True, n_jobs=-1)\n",
      "    estimator.fit(X,y)\n",
      "    return estimator"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def serial_graph_motif(seqs, vectorizer=None, estimator=None, min_subarray_size=5, max_subarray_size=18):\n",
      "    #make graphs \n",
      "    from eden.converter.fasta import sequence_to_eden\n",
      "    iterable = sequence_to_eden(seqs)\n",
      "    #use node importance and 'position' attribute to identify max_subarrays of a specific size\n",
      "    graphs = vectorizer.annotate( iterable, estimator=estimator )\n",
      "    #use compute_max_subarrays to return an iterator over motives \n",
      "    from eden.util.iterated_maximum_subarray import compute_max_subarrays\n",
      "    motives=[]\n",
      "    for graph in graphs:\n",
      "        subarrays = compute_max_subarrays(graph=graph, min_subarray_size=min_subarray_size, max_subarray_size=max_subarray_size)\n",
      "        for subarray in subarrays:\n",
      "            motives.append(subarray['subarray_string'])\n",
      "    return motives\n",
      "\n",
      "def multiprocess_graph_motif(seqs, vectorizer=None, estimator=None, min_subarray_size=5, max_subarray_size=18, n_blocks=5, n_processes=8):\n",
      "    import multiprocessing as mp\n",
      "    size = len(seqs)\n",
      "    block_size=size/n_blocks\n",
      "    pool = mp.Pool(processes=n_processes)\n",
      "    results = [pool.apply_async(serial_graph_motif, args=(seqs[s*block_size:(s+1)*block_size],vectorizer, estimator, min_subarray_size, max_subarray_size)) for s in range(n_blocks-1)]\n",
      "    output = [p.get() for p in results]\n",
      "    import itertools \n",
      "    chain = itertools.chain(*output)\n",
      "    return list(chain)\n",
      "\n",
      "def graph_motif(seqs, vectorizer=None, estimator=None, min_subarray_size=5, max_subarray_size=18, multiprocess=True, n_blocks=5, n_processes=8):\n",
      "    if multiprocess:\n",
      "        return multiprocess_graph_motif(seqs,vectorizer=vectorizer,estimator=estimator, min_subarray_size=min_subarray_size, max_subarray_size=max_subarray_size, n_blocks=n_blocks, n_processes=n_processes)\n",
      "    else:\n",
      "        return serial_graph_motif(seqs, vectorizer=vectorizer, estimator=estimator, min_subarray_size=min_subarray_size, max_subarray_size=max_subarray_size)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "def greedy_density_cluster(density_order, indices):\n",
      "    num=len(indices)\n",
      "    instance_id_to_cluster_id_map=np.zeros((num,),'int64')\n",
      "    #init: the densest neighbourhood constitutes the first cluster\n",
      "    id = density_order[0]\n",
      "    neighbors = indices[id]\n",
      "    instance_id_to_cluster_id_map[neighbors] = id\n",
      "    for id in density_order:\n",
      "        #work only on instances that have not alrady been assigned to clusters\n",
      "        if instance_id_to_cluster_id_map[id] == 0:\n",
      "            neighbors = indices[id]\n",
      "            neighbor_cluster_ids = instance_id_to_cluster_id_map[neighbors]\n",
      "            neighbor_cluster_id_hist = np.bincount(neighbor_cluster_ids) #NOTE:replace with dict\n",
      "            cluster_id = np.argmax(neighbor_cluster_id_hist)\n",
      "            #count the max num occurrences of the cluster_id associated to each neighbor\n",
      "            cluster_count=neighbor_cluster_id_hist[cluster_id]\n",
      "            #print id, neighbors,neighbor_cluster_ids , neighbor_cluster_id_hist, cluster_id, cluster_count\n",
      "            #if we are allocating instance 0 then give it the id num = max_id+1\n",
      "            if id == 0: id = num\n",
      "            #if most of the instances are not assigned and have 0 as representative then create a new cluster\n",
      "            if cluster_id == 0: cluster_id = id\n",
      "            #give to all non-yet-cluster-associated (i.e. with clust_id=0) neighbors the cluster_id of max_count\n",
      "            #or if this corresponds to 0 then give as cluster id the id of the instance\n",
      "            mask=np.array([True if x == 0 else False for x in neighbor_cluster_ids])\n",
      "            instance_id_to_cluster_id_map[neighbors[mask]] = cluster_id    \n",
      "    return instance_id_to_cluster_id_map\n",
      "\n",
      "\n",
      "def kneighbors_greedy_density_clustering(X, n_neighbors=10, nn_algo='NearestNeighbors'):\n",
      "    if nn_algo == 'NearestNeighbors':\n",
      "        from sklearn.neighbors import NearestNeighbors\n",
      "        nn = NearestNeighbors()\n",
      "    elif nn_algo == 'LSHForest':\n",
      "        from sklearn.neighbors import LSHForest\n",
      "        nn = LSHForest()\n",
      "    else:\n",
      "        raise Exception('Unknown algorithm: %s' % nn_algo)\n",
      "    nn.fit(X)\n",
      "    distances, indices = nn.kneighbors(X, n_neighbors=n_neighbors)\n",
      "    avg_distance=[sum(distance) for distance in distances ]\n",
      "    density_order=np.argsort(avg_distance)\n",
      "    predictions = greedy_density_cluster(density_order, indices)\n",
      "    return predictions\n",
      "\n",
      "\n",
      "def cluster(seqs, complexity=3, n_neighbors=10, algo='greedy_density', nn_algo='NearestNeighbors', n_clusters=4, eps=0.3, min_samples=3):\n",
      "    from eden.path import Vectorizer\n",
      "    seq_vectorizer = Vectorizer( complexity = complexity, nbits=14)\n",
      "    from eden import vectorize\n",
      "    X = vectorize(seqs, vectorizer=seq_vectorizer)\n",
      "    if algo == 'greedy_density':\n",
      "        predictions = kneighbors_greedy_density_clustering(X,n_neighbors=n_neighbors, nn_algo=nn_algo)\n",
      "    elif algo == 'MiniBatchKMeans':\n",
      "        from sklearn.cluster import MiniBatchKMeans \n",
      "        cl = MiniBatchKMeans(n_clusters=n_clusters)\n",
      "        predictions = cl.fit_predict(X)\n",
      "    elif algo == 'DBSCAN':\n",
      "        from sklearn.cluster import DBSCAN\n",
      "        db = DBSCAN(eps=eps, min_samples=min_samples)\n",
      "        db.fit(X)\n",
      "        predictions = db.labels_\n",
      "    else:\n",
      "        raise Exception('Unknown algorithm: %s'%algo) \n",
      "    #collect instance ids per cluster id\n",
      "    from collections import defaultdict\n",
      "    clusters = defaultdict(list)\n",
      "    for i in range(len(predictions)):\n",
      "        clusters[predictions[i]]+=[i]\n",
      "    return clusters\n",
      "\n",
      "\n",
      "def graph_motif_cluster(seqs, size=100, complexity=3, negative_ratio=2, n_neighbors=10, algo='greedy_density', nn_algo='NearestNeighbors', n_clusters=4, eps=0.3, min_samples=3, min_subarray_size=9, max_subarray_size=15, verbosity=0):    \n",
      "    #init vectorizer\n",
      "    from eden.graph import Vectorizer\n",
      "    vectorizer = Vectorizer( complexity=complexity )\n",
      "    \n",
      "    from time import time\n",
      "    import random\n",
      "    start=time()\n",
      "    training_seqs = random.sample(seqs, size)\n",
      "    estimator = fit_predictive_model(training_seqs, vectorizer=vectorizer, negative_ratio=negative_ratio)\n",
      "    end=time()\n",
      "    if verbosity>0: print 'model induction: %d secs'%(end-start)\n",
      "    \n",
      "    start=time()\n",
      "    motives = graph_motif(seqs, vectorizer=vectorizer, estimator=estimator, min_subarray_size=min_subarray_size, max_subarray_size=max_subarray_size, multiprocess=True)\n",
      "    motif_list = list(motives)\n",
      "    end=time()\n",
      "    if verbosity>0: print '%d motives extraction: %d secs'%(len(motif_list), end-start)\n",
      "    \n",
      "    start=time()\n",
      "    clusters = cluster(motif_list, complexity=complexity, n_neighbors=n_neighbors, algo=algo, nn_algo=nn_algo, n_clusters=n_clusters, eps=eps, min_samples=min_samples)\n",
      "    end=time()\n",
      "    if verbosity>0: print 'clustering for %d clusters: %d secs'%(len(clusters), end-start)\n",
      "    \n",
      "    return clusters,motif_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def consensus(seqs):\n",
      "    from collections import Counter\n",
      "    cons=''\n",
      "    length =int(np.average([len(seq) for seq in seqs]))\n",
      "    for i in range(length):\n",
      "        col = []\n",
      "        for j in range(len(seqs)):\n",
      "            if len(seqs[j]) >= i:\n",
      "                col.append(seqs[j][i:i+1])\n",
      "        cons += Counter(col).most_common(1)[0][0]\n",
      "    return cons\n",
      "\n",
      "def extract_and_cluster_motives(seqs, min_motif_count=2, min_cluster_size=5, **args):\n",
      "    from collections import defaultdict\n",
      "    clustered_motives=defaultdict(list)             \n",
      "    clusters,motif_list = graph_motif_cluster(seqs,**args)\n",
      "    for cluster_id in clusters:\n",
      "        if cluster_id != -1:\n",
      "            if len(clusters[cluster_id]) > min_cluster_size:\n",
      "                clustered_seqs = []\n",
      "                for seq_ids in clusters[cluster_id]:\n",
      "                    clustered_seqs.append(motif_list[seq_ids])\n",
      "                cons = consensus(clustered_seqs)\n",
      "                for s in clustered_seqs: \n",
      "                    clustered_motives[cons].append(s)\n",
      "                    \n",
      "    #extract x motif count within a cluster\n",
      "    motives_db=defaultdict(list)   \n",
      "    #for all clusters\n",
      "    for cons in clustered_motives:\n",
      "        #consider only non identical motives\n",
      "        motif_set = set(clustered_motives[cons])\n",
      "        for motif_i in motif_set:\n",
      "            #count occurrences of motif in cluster\n",
      "            count=0\n",
      "            for motif_j in clustered_motives[cons]:\n",
      "                if motif_i == motif_j:\n",
      "                    count += 1\n",
      "            #create dict with motives and their counts\n",
      "            motives_db[cons].append((count,motif_i))\n",
      "    for cons in motives_db:\n",
      "        motives_db[cons]=sorted(motives_db[cons], reverse=True)\n",
      "    #print motives\n",
      "    for cons in motives_db:\n",
      "        print\n",
      "        print cons\n",
      "        print '-'*15\n",
      "        for count, motif in motives_db[cons]:\n",
      "            if count >= min_motif_count:\n",
      "                print motif, count\n",
      "    return motives_db "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Experimental Setup"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#setup parameters\n",
      "alphabet='ACGU'\n",
      "motives=['AAAAAAAAAA','CCCCCCCCCC','GGGGGGGGGG','UUUUUUUUUU']\n",
      "sequence_length=200\n",
      "n_sequences=1000\n",
      "p=0.3\n",
      "\n",
      "#make dataset\n",
      "motives, seqs = make_artificial_dataset(alphabet=alphabet,motives=motives,sequence_length=sequence_length,n_sequences=n_sequences,p=p)\n",
      "\n",
      "#display\n",
      "print 'Motives and sample of their perturbed variants:'\n",
      "alphabet_list=[c for c in alphabet]\n",
      "for motif in motives: \n",
      "    print\n",
      "    print motif,\n",
      "    for i in range(9):\n",
      "        print perturb(motif,alphabet_list,p=p),\n",
      "#for seq in seqs: print seq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Motives and sample of their perturbed variants:\n",
        "\n",
        "AAAAAAAAAA AAAAACCUAA AACGAAAUAC GCAAAAAAAA AAUAAAGAAA AAAAAAAAAA AAAACACAAA AAAAUAAAAU AAAUAAAAAA AAAGAAAAAA\n",
        "CCCCCCCCCC CCCCCACCCC CCCCUCGCGC CCCCCCCCCC CCCUCCCGCG AUCACCCCCC ACCCCCCCCC CCCCACCCCC CGCCCCCCCC CCCCCCACAC\n",
        "GGGGGGGGGG GGGGGGGGGU CGGGCGGCGG GAGGGCGGCG UAGGGGGGGG AUUGUGGGGC GGGGGGCGGG GGGCGGGGGG ACUGACAGGC GGGGGGGCGG\n",
        "UUUUUUUUUU UUCUUUUUUU UUUUUUUUUU UUUUCUUCUU CUUUUUAUUU UUUAUUCGUC GUGUUUUUUU UGUCUUUUUA UGUUUUUUUG UUUUUUGUUA\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#global parameters for motif and cluster extraction\n",
      "args={'size':100,\n",
      "      'complexity':4,\n",
      "      'negative_ratio':4,\n",
      "      'n_neighbors':5,\n",
      "      'algo':'greedy_density',\n",
      "      'nn_algo':'NearestNeighbors',\n",
      "      'n_clusters':4, \n",
      "      'eps':0.3, \n",
      "      'min_samples':3,\n",
      "      'min_subarray_size':9,\n",
      "      'max_subarray_size':11,\n",
      "      'verbosity':1,\n",
      "      'min_cluster_size':10, \n",
      "      'min_motif_count':2}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "args.update({'algo':'greedy_density','nn_algo':'NearestNeighbors','n_neighbors':5})\n",
      "clustered_motives=extract_and_cluster_motives(seqs, **args)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "model induction: 21 secs\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "293 motives extraction: 43 secs\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "clustering for 45 clusters: 0 secs\n",
        "\n",
        "AAAAAAAAAA\n",
        "---------------\n",
        "AAAAAAAAAAA 5\n",
        "UAAAAAAAAAA 2\n",
        "\n",
        "GGGGGGGGGGG\n",
        "---------------\n",
        "GGGGGGGGGGG 5\n",
        "GGGGGGCGGGG 3\n",
        "UGGGGGGGGGG 2\n",
        "\n",
        "GUUUUUUUUUU\n",
        "---------------\n",
        "\n",
        "GGGUGGGGGGG\n",
        "---------------\n",
        "GGGUGGGGGGC 2\n",
        "\n",
        "GCCCCCCCCCC\n",
        "---------------\n",
        "GCCCCCCCCCC 4\n",
        "GCCCCCCCCCU 2\n",
        "\n",
        "UUUUUUUUUUU\n",
        "---------------\n",
        "\n",
        "AAAAACAAAAA\n",
        "---------------\n",
        "AAAAACAAAAA 3\n",
        "\n",
        "CCCCCCCCCCC\n",
        "---------------\n",
        "CCCCCCCCCCC 6\n",
        "CPU times: user 1.8 s, sys: 610 ms, total: 2.41 s\n",
        "Wall time: 1min 5s\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "args.update({'algo':'greedy_density','nn_algo':'LSHForest','n_neighbors':5})\n",
      "clustered_motives=extract_and_cluster_motives(seqs, **args)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "model induction: 22 secs\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "285 motives extraction: 42 secs\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "clustering for 52 clusters: 1 secs\n",
        "\n",
        "UUUUUUUUUUU\n",
        "---------------\n",
        "UUUUUUUUUUU 6\n",
        "\n",
        "GGGGGGGGGGG\n",
        "---------------\n",
        "GGGGGGGGGGG 5\n",
        "GGGGGGCGGGG 2\n",
        "\n",
        "GGGAGGGGGGG\n",
        "---------------\n",
        "GGGAGGGGGGA 2\n",
        "\n",
        "GCCCCCCCCCC\n",
        "---------------\n",
        "GCCCCCCCCCC 4\n",
        "GCCCCCCCCCA 2\n",
        "CPU times: user 3.12 s, sys: 1.02 s, total: 4.14 s\n",
        "Wall time: 1min 6s\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "args.update({'algo':'MiniBatchKMeans','n_clusters':8})\n",
      "clustered_motives=extract_and_cluster_motives(seqs, **args)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "model induction: 21 secs\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "311 motives extraction: 50 secs\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "clustering for 8 clusters: 0 secs\n",
        "\n",
        "GGGGGGGGGGG\n",
        "---------------\n",
        "GGGGGGGGGGG 8\n",
        "GGGGGGGGGGU 3\n",
        "CGGGGGGUGGG 2\n",
        "\n",
        "GUUUUUUUUUU\n",
        "---------------\n",
        "\n",
        "UUUUUUUUUUU\n",
        "---------------\n",
        "UUUUUUUUUUU 6\n",
        "UUUUUUUUUUG 5\n",
        "AUUUUUUUUUU 3\n",
        "AUUUUUUUUUA 3\n",
        "AUUUUUUGUUU 3\n",
        "GUUUUUUUUUC 2\n",
        "\n",
        "GGGUGGGGGGG\n",
        "---------------\n",
        "\n",
        "AAAAAAAAAAA\n",
        "---------------\n",
        "AAAAAAAAAAA 8\n",
        "GAAAAAAUAAA 3\n",
        "GAAAAAAAAAA 3\n",
        "CAAAAAAAAAA 3\n",
        "AAAAAAAAAAC 3\n",
        "CAAAAAAAAAU 2\n",
        "AAAUAAAAAAA 2\n",
        "AAAAAAAAAAG 2\n",
        "\n",
        "CCCCCCCCCCC\n",
        "---------------\n",
        "CCCCCCCCCCC 7\n",
        "GCCCCCCCCCC 3\n",
        "UCCCCCCCCCA 2\n",
        "GCCCCCCCCCA 2\n",
        "CCCCCCCCCCU 2\n",
        "CCCCCCCCCCG 2\n",
        "CCCCCCACCCC 2\n",
        "CPU times: user 2.15 s, sys: 1.28 s, total: 3.43 s\n",
        "Wall time: 1min 13s\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "args.update({'algo':'DBSCAN','eps':0.3,'min_samples':10})\n",
      "clustered_motives=extract_and_cluster_motives(seqs, **args)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "model induction: 22 secs\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "275 motives extraction: 42 secs\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "clustering for 5 clusters: 0 secs\n",
        "\n",
        "UUUUUUUUUUU\n",
        "---------------\n",
        "UUUUUUUUUUU 7\n",
        "UUUUUUUUUUG 3\n",
        "GUUUUUUUUUU 3\n",
        "CUUUUUUUUUC 3\n",
        "AUUUUUUUUUU 3\n",
        "AUUUUUUUUUA 3\n",
        "GUUUUUUUUUC 2\n",
        "CUUUUUUUUUG 2\n",
        "AUUUUUUUUUG 2\n",
        "AUUUUUUGUUU 2\n",
        "\n",
        "GGGGGGGGGGG\n",
        "---------------\n",
        "GGGGGGGGGGG 9\n",
        "GGGGGGGGGGU 3\n",
        "UGGGGGGGGGG 2\n",
        "GGGGGGGGGGC 2\n",
        "GGGGGGCGGGG 2\n",
        "CGGGGGGGGGU 2\n",
        "CGGGGGGGGGG 2\n",
        "CGGGGGGGGGC 2\n",
        "\n",
        "AAAAAAAAAAA\n",
        "---------------\n",
        "AAAAAAAAAAA 9\n",
        "AAAAAAAAAAC 3\n",
        "AAAUAAAAAAA 2\n",
        "AAAAAAAAAAG 2\n",
        "\n",
        "CCCCCCCCCCC\n",
        "---------------\n",
        "CCCCCCCCCCC 7\n",
        "GCCCCCCCCCC 4\n",
        "AGCCCCCCCCC 3\n",
        "CCGCCCCCCCC 2\n",
        "CCCCCCCCCCG 2\n",
        "CPU times: user 2.34 s, sys: 1.59 s, total: 3.93 s\n",
        "Wall time: 1min 5s\n"
       ]
      }
     ],
     "prompt_number": 12
    }
   ],
   "metadata": {}
  }
 ]
}