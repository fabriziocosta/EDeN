{
 "metadata": {
  "name": "",
  "signature": "sha256:d2d7894fc05d5006b4e758cd1a8d54c69c14e1bee4b263bc6d26521b344b8eb5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Aim\n",
      "\n",
      "Given a large set of sequences or graphs with ordered vertices find small vertex ordered subsequences that are most discriminative for the set.\n",
      "\n",
      "Steps:\n",
      "- devise a negative set\n",
      "- learn a discriminative model\n",
      "- annotate importance on vertices\n",
      "- extract max subarrays \n",
      "- cluster them \n",
      " - use fast EDeN string kernel \n",
      " - LSHForest\n",
      " - custom incremental cluster"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#code for making artificial dataset\n",
      "import random\n",
      "def random_string(length,alphabet_list):\n",
      "    rand_str = ''.join(random.choice(alphabet_list) for i in range(length))\n",
      "    return rand_str\n",
      "\n",
      "def perturb(seed,alphabet_list,p=0.5):\n",
      "    seq=''\n",
      "    for c in seed:\n",
      "        if random.random() < p: c = random.choice(alphabet_list)\n",
      "        seq += c\n",
      "    return seq\n",
      "\n",
      "def make_artificial_dataset(alphabet='ACGU', motives=None, motif_length=6, sequence_length=100, n_sequences=1000, n_motives=2, p=0.2):\n",
      "    alphabet_list=[c for c in alphabet]\n",
      "    \n",
      "    if motives is None:\n",
      "        motives=[]\n",
      "        for i in range(n_motives):\n",
      "            motives.append(random_string(motif_length,alphabet_list))\n",
      "    else:\n",
      "        motif_length = len(motives[0])\n",
      "        n_motives = len(motives)\n",
      "        \n",
      "    flanking_length = (sequence_length - motif_length ) / 2\n",
      "    n_seq_per_motif = n_sequences / n_motives\n",
      "\n",
      "    counter=0\n",
      "    seqs=[]\n",
      "    for i in range(n_seq_per_motif):\n",
      "        for j in range(n_motives):\n",
      "            left_flanking = random_string(flanking_length,alphabet_list)\n",
      "            right_flanking = random_string(flanking_length,alphabet_list)\n",
      "            noisy_motif = perturb(motives[j],alphabet_list,p)\n",
      "            seq = left_flanking + noisy_motif + right_flanking\n",
      "            seqs.append(('>ID%d'%counter,seq))\n",
      "            counter += 1\n",
      "    return motives, seqs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def induce_model(seqs, complexity=4, negative_ratio=2):\n",
      "    #optimized\n",
      "    #duplicate iterator\n",
      "    from itertools import tee\n",
      "    seqs,seqs_=tee(seqs)\n",
      "    #make graphs for pos\n",
      "    from eden.converter.fasta import sequence_to_eden\n",
      "    iterable_pos = sequence_to_eden(seqs)\n",
      "    #shuffle seqs to obtain negatives\n",
      "    from eden.modifier.seq import seq_to_seq, shuffle_modifier\n",
      "    seqs_neg = seq_to_seq( seqs_, modifier=shuffle_modifier, times=negative_ratio, order=2 )\n",
      "    #make graphs for negs\n",
      "    from eden.converter.fasta import sequence_to_eden\n",
      "    iterable_neg = sequence_to_eden(seqs_neg)\n",
      "\n",
      "    #init vectorizer\n",
      "    from eden.graph import Vectorizer\n",
      "    vectorizer = Vectorizer( complexity=complexity )\n",
      "\n",
      "    #make predictive model\n",
      "    from eden.util import fit,estimate\n",
      "    estimator = fit(iterable_pos, iterable_neg, vectorizer, n_jobs=-1,cv=5)\n",
      "    return vectorizer, estimator"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def fit_predictive_model(seqs, complexity=4, negative_ratio=2):\n",
      "    #default hyperparameters\n",
      "    #duplicate iterator\n",
      "    from itertools import tee\n",
      "    seqs,seqs_=tee(seqs)\n",
      "    #make graphs for pos\n",
      "    from eden.converter.fasta import sequence_to_eden\n",
      "    iterable_pos = sequence_to_eden(seqs)\n",
      "    #shuffle seqs to obtain negatives\n",
      "    from eden.modifier.seq import seq_to_seq, shuffle_modifier\n",
      "    seqs_neg = seq_to_seq( seqs_, modifier=shuffle_modifier, times=negative_ratio, order=2 )\n",
      "    #make graphs for negs\n",
      "    from eden.converter.fasta import sequence_to_eden\n",
      "    iterable_neg = sequence_to_eden(seqs_neg)\n",
      "\n",
      "    #init vectorizer\n",
      "    from eden.graph import Vectorizer\n",
      "    vectorizer = Vectorizer( complexity=complexity )\n",
      "    #build data matrix\n",
      "    X_pos = vectorizer.transform(iterable_pos, n_jobs=-1)\n",
      "    X_neg = vectorizer.transform(iterable_neg, n_jobs=-1)\n",
      "    import numpy as np\n",
      "    from scipy.sparse import vstack\n",
      "    yp = [1] * X_pos.shape[0]\n",
      "    yn = [-1] * X_neg.shape[0]\n",
      "    y = np.array(yp + yn)\n",
      "    X = vstack([X_pos, X_neg], format=\"csr\")\n",
      "    #fit predictive model\n",
      "    from sklearn.linear_model import SGDClassifier\n",
      "    estimator = SGDClassifier(average=True, class_weight='auto', shuffle=True, n_jobs=-1)\n",
      "    estimator.fit(X,y)\n",
      "    return vectorizer, estimator"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def serial_graph_motif(seqs, vectorizer=None, estimator=None, min_subarray_size=5, max_subarray_size=18):\n",
      "    #make graphs \n",
      "    from eden.converter.fasta import sequence_to_eden\n",
      "    iterable = sequence_to_eden(seqs)\n",
      "    #use node importance and 'position' attribute to identify max_subarrays of a specific size\n",
      "    graphs = vectorizer.annotate( iterable, estimator=estimator )\n",
      "    #use compute_max_subarrays to return an iterator over motives \n",
      "    from eden.util.iterated_maximum_subarray import compute_max_subarrays\n",
      "    motives=[]\n",
      "    for graph in graphs:\n",
      "        subarrays = compute_max_subarrays(graph=graph, min_subarray_size=min_subarray_size, max_subarray_size=max_subarray_size)\n",
      "        for subarray in subarrays:\n",
      "            motives.append(subarray['subarray_string'])\n",
      "    return motives\n",
      "\n",
      "def multiprocess_graph_motif(seqs, vectorizer=None, estimator=None, min_subarray_size=5, max_subarray_size=18, n_blocks=5, n_processes=8):\n",
      "    import multiprocessing as mp\n",
      "    size = len(seqs)\n",
      "    block_size=size/n_blocks\n",
      "    pool = mp.Pool(processes=n_processes)\n",
      "    results = [pool.apply_async(serial_graph_motif, args=(seqs[s*block_size:(s+1)*block_size],vectorizer, estimator, min_subarray_size, max_subarray_size)) for s in range(n_blocks-1)]\n",
      "    output = [p.get() for p in results]\n",
      "    import itertools \n",
      "    chain = itertools.chain(*output)\n",
      "    return list(chain)\n",
      "\n",
      "def graph_motif(seqs, vectorizer=None, estimator=None, min_subarray_size=5, max_subarray_size=18, multiprocess=True, n_blocks=5, n_processes=8):\n",
      "    if multiprocess:\n",
      "        return multiprocess_graph_motif(seqs,vectorizer=vectorizer,estimator=estimator, min_subarray_size=min_subarray_size, max_subarray_size=max_subarray_size, n_blocks=n_blocks, n_processes=n_processes)\n",
      "    else:\n",
      "        return serial_graph_motif(seqs, vectorizer=vectorizer, estimator=estimator, min_subarray_size=min_subarray_size, max_subarray_size=max_subarray_size)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "def greedy_density_cluster(density_order, indices):\n",
      "    num=len(indices)\n",
      "    instance_id_to_cluster_id_map=np.zeros((num,),'int64')\n",
      "    #init: the densest neighbourhood constitutes the first cluster\n",
      "    id = density_order[0]\n",
      "    neighbors = indices[id]\n",
      "    instance_id_to_cluster_id_map[neighbors] = id\n",
      "    for id in density_order:\n",
      "        #work only on instances that have not alrady been assigned to clusters\n",
      "        if instance_id_to_cluster_id_map[id] == 0:\n",
      "            neighbors = indices[id]\n",
      "            neighbor_cluster_ids = instance_id_to_cluster_id_map[neighbors]\n",
      "            neighbor_cluster_id_hist = np.bincount(neighbor_cluster_ids) #NOTE:replace with dict\n",
      "            cluster_id = np.argmax(neighbor_cluster_id_hist)\n",
      "            #count the max num occurrences of the cluster_id associated to each neighbor\n",
      "            cluster_count=neighbor_cluster_id_hist[cluster_id]\n",
      "            #print id, neighbors,neighbor_cluster_ids , neighbor_cluster_id_hist, cluster_id, cluster_count\n",
      "            #if we are allocating instance 0 then give it the id num = max_id+1\n",
      "            if id == 0: id = num\n",
      "            #if most of the instances are not assigned and have 0 as representative then create a new cluster\n",
      "            if cluster_id == 0: cluster_id = id\n",
      "            #give to all non-yet-cluster-associated (i.e. with clust_id=0) neighbors the cluster_id of max_count\n",
      "            #or if this corresponds to 0 then give as cluster id the id of the instance\n",
      "            mask=np.array([True if x == 0 else False for x in neighbor_cluster_ids])\n",
      "            instance_id_to_cluster_id_map[neighbors[mask]] = cluster_id    \n",
      "    return instance_id_to_cluster_id_map\n",
      "\n",
      "\n",
      "def kneighbors_greedy_density_clustering(X, n_neighbors=10, nn_algo='NearestNeighbors'):\n",
      "    if nn_algo == 'NearestNeighbors':\n",
      "        from sklearn.neighbors import NearestNeighbors\n",
      "        nn = NearestNeighbors()\n",
      "    elif nn_algo == 'LSHForest':\n",
      "        from sklearn.neighbors import LSHForest\n",
      "        nn = LSHForest()\n",
      "    else:\n",
      "        raise Exception('Unknown algorithm: %s' % nn_algo)\n",
      "    nn.fit(X)\n",
      "    distances, indices = nn.kneighbors(X, n_neighbors=n_neighbors)\n",
      "    avg_distance=[sum(distance) for distance in distances ]\n",
      "    density_order=np.argsort(avg_distance)\n",
      "    predictions = greedy_density_cluster(density_order, indices)\n",
      "    return predictions\n",
      "\n",
      "\n",
      "def cluster(seqs, complexity=3, n_neighbors=10, algo='greedy_density', nn_algo='NearestNeighbors', n_clusters=4, eps=0.3, min_samples=3):\n",
      "    from eden.path import Vectorizer\n",
      "    seq_vectorizer = Vectorizer( complexity = complexity)\n",
      "    X = seq_vectorizer.transform(seqs, n_jobs=-1)\n",
      "    if algo == 'greedy_density':\n",
      "        predictions = kneighbors_greedy_density_clustering(X,n_neighbors=n_neighbors, nn_algo=nn_algo)\n",
      "    elif algo == 'MiniBatchKMeans':\n",
      "        from sklearn.cluster import MiniBatchKMeans \n",
      "        cl = MiniBatchKMeans(n_clusters=n_clusters)\n",
      "        predictions = cl.fit_predict(X)\n",
      "    elif algo == 'DBSCAN':\n",
      "        from sklearn.cluster import DBSCAN\n",
      "        db = DBSCAN(eps=eps, min_samples=min_samples)\n",
      "        db.fit(X)\n",
      "        predictions = db.labels_\n",
      "    else:\n",
      "        raise Exception('Unknown algorithm: %s'%algo) \n",
      "    #collect instance ids per cluster id\n",
      "    from collections import defaultdict\n",
      "    clusters = defaultdict(list)\n",
      "    for i in range(len(predictions)):\n",
      "        clusters[predictions[i]]+=[i]\n",
      "    return clusters\n",
      "\n",
      "\n",
      "def graph_motif_cluster(seqs, size=100, complexity=3, negative_ratio=2, n_neighbors=10, algo='greedy_density', nn_algo='NearestNeighbors', n_clusters=4, eps=0.3, min_samples=3, min_subarray_size=9, max_subarray_size=15, verbosity=0):    \n",
      "    from time import time\n",
      "    import random\n",
      "    start=time()\n",
      "    training_seqs = random.sample(seqs, size)\n",
      "    vectorizer, estimator = fit_predictive_model(training_seqs, complexity=complexity, negative_ratio=negative_ratio)\n",
      "    end=time()\n",
      "    if verbosity>0: print 'model induction: %d secs'%(end-start)\n",
      "    \n",
      "    start=time()\n",
      "    motives = graph_motif(seqs, vectorizer=vectorizer, estimator=estimator, min_subarray_size=min_subarray_size, max_subarray_size=max_subarray_size, multiprocess=True)\n",
      "    motif_list = list(motives)\n",
      "    end=time()\n",
      "    if verbosity>0: print '%d motives extraction: %d secs'%(len(motif_list), end-start)\n",
      "    \n",
      "    start=time()\n",
      "    clusters = cluster(motif_list, complexity=complexity, n_neighbors=n_neighbors, algo=algo, nn_algo=nn_algo, n_clusters=n_clusters, eps=eps, min_samples=min_samples)\n",
      "    end=time()\n",
      "    if verbosity>0: print 'clustering for %d clusters: %d secs'%(len(clusters), end-start)\n",
      "    \n",
      "    return clusters,motif_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extract_and_cluster_motives(seqs, **args):\n",
      "    clusters,motif_list = graph_motif_cluster(seqs,**args)\n",
      "    for cluster_id in clusters:\n",
      "        if cluster_id != -1:\n",
      "            print 'Cluster id:%s size:%d'%(cluster_id, len(clusters[cluster_id]))\n",
      "            for seq_ids in clusters[cluster_id]:\n",
      "                print motif_list[seq_ids]\n",
      "            print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Experimental Setup"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#setup parameters\n",
      "alphabet='ACGU'\n",
      "motives=['AAAAAAAAAA','CCCCCCCCCC','GGGGGGGGGG','UUUUUUUUUU']\n",
      "sequence_length=200\n",
      "n_sequences=1000\n",
      "p=0.3\n",
      "\n",
      "#make dataset\n",
      "motives, seqs = make_artificial_dataset(alphabet=alphabet,motives=motives,sequence_length=sequence_length,n_sequences=n_sequences,p=p)\n",
      "\n",
      "#display\n",
      "print 'Motives and sample of their perturbed variants:'\n",
      "alphabet_list=[c for c in alphabet]\n",
      "for motif in motives: \n",
      "    print\n",
      "    print motif,\n",
      "    for i in range(9):\n",
      "        print perturb(motif,alphabet_list,p=p),\n",
      "#for seq in seqs: print seq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Motives and sample of their perturbed variants:\n",
        "\n",
        "AAAAAAAAAA AGAAAAACGA UAGAAAAGAA AAAAAAGAAA UAAAAAAGAA CAAAACAAAA AAAAAUAGAC GAUACAAAAG AAAACAAACA CGACUAUAAA\n",
        "CCCCCCCCCC CUGCCCCCCC GCACCCCCAA CCACCCUCCU GCCACCCCCC CCCCCCCCAC CGCCCCCCUC CACCCCCCCC CCACCUCACC GCCCGCCGCC\n",
        "GGGGGGGGGG GGGGAGUGGA GCGGGGGGCG CGGGGGAGGG GGGGGGGGGG GGGGGGGGGG GGAGUGUGGG GGGGGGGGCG GGGGGGGGGG GUGGGCUGGG\n",
        "UUUUUUUUUU UUUUUUUUAU UUAUUUUUUU UUUUUUCCUU UUUCUUUAAU UUUGUUAUAU AUUUCUCUUU UCCUUUUUAU CAGUUCUUUC UUUUUUGUCU\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#global parameters for motif and cluster extraction\n",
      "args={'size':200,\n",
      "      'complexity':4,\n",
      "      'negative_ratio':4,\n",
      "      'n_neighbors':5,\n",
      "      'algo':'greedy_density',\n",
      "      'nn_algo':'NearestNeighbors',\n",
      "      'n_clusters':4, \n",
      "      'eps':0.3, \n",
      "      'min_samples':3,\n",
      "      'min_subarray_size':7,\n",
      "      'max_subarray_size':9,\n",
      "      'verbosity':1}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "args.update({'algo':'greedy_density','nn_algo':'NearestNeighbors','n_neighbors':20})\n",
      "extract_and_cluster_motives(seqs,**args)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "model induction: 82 secs\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "383 motives extraction: 82 secs\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "clustering for 7 clusters: 0 secs\n",
        "Cluster id:4 size:18\n",
        "ACCCCCCCA\n",
        "GGACCAGGG\n",
        "ACCCCCCCG\n",
        "ACCCCCCCA\n",
        "AUACCCCCG\n",
        "ACCCCCCCA\n",
        "UCCACCCCC\n",
        "ACCCCCCCG\n",
        "ACACCCCCU\n",
        "ACCCCCCCA\n",
        "ACCACCCCA\n",
        "ACCCCCCCU\n",
        "AUACAUACC\n",
        "ACCCCCCCA\n",
        "UCCCCACCG\n",
        "ACCCCCCCG\n",
        "ACCCCCCCG\n",
        "GGGACCCCC\n",
        "\n",
        "Cluster id:174 size:106\n",
        "GAGAGGGGG\n",
        "GGGGGGGGG\n",
        "CUGGUGAGG\n",
        "GGGGGGGGU\n",
        "UGGGUCCAU\n",
        "GGGGUUGGG\n",
        "ACCAGGAAA\n",
        "GGGGGGGGG\n",
        "AGAGGGGGA\n",
        "GGGGAGGGG\n",
        "CCCAGGGGG\n",
        "GGGCGGGGG\n",
        "AGGGGGAGG\n",
        "AGAGAGAGG\n",
        "GGGGGGGGG\n",
        "AGGGGGGAG\n",
        "UGGGGGAGC\n",
        "GGGGGGGGG\n",
        "GGGGGGGGG\n",
        "UGAGGGGGG\n",
        "GAGGGAGGA\n",
        "GGGGGGAGA\n",
        "UGGGGGGGA\n",
        "GAGGGGGGG\n",
        "GGGGGGGGU\n",
        "GGGGGGGGG\n",
        "AGGGGGGGG\n",
        "GGGGGGGGG\n",
        "AGAGAGAGA\n",
        "GGGGGGGGG\n",
        "GGAGAGCCC\n",
        "UGGGGGAAA\n",
        "GGGGGGGGU\n",
        "GGGGGGGGG\n",
        "UGGGGGGGC\n",
        "UUGGUCCAC\n",
        "UGGGGGAGG\n",
        "CGCGGGGGU\n",
        "CGGGGGGGA\n",
        "GGGGGUGGG\n",
        "UGAGGGAGC\n",
        "AGGGGGGGG\n",
        "GGGGGGGGG\n",
        "GGGGGGGGG\n",
        "GGGGGGGGG\n",
        "CAGGUUGGG\n",
        "AGGGGGGGU\n",
        "UGGGGUUGG\n",
        "AGGGGGGGU\n",
        "GGAGGGGGG\n",
        "UGAGAGGGU\n",
        "AGGGGGGGA\n",
        "GGGAGAGGU\n",
        "UGGGGGGGC\n",
        "UGGGGGGGA\n",
        "AGGUGGGGU\n",
        "GGGGGGGGG\n",
        "CGGUGGGGG\n",
        "UGGGUGGGC\n",
        "CGGGGGGGU\n",
        "GGGGGGGGG\n",
        "AGGGGGAGG\n",
        "UGGGGGGGU\n",
        "GCUAUGAGC\n",
        "AGAGGGAGA\n",
        "GGGGGAGGG\n",
        "UGGUGGGGU\n",
        "UGAGAGAGG\n",
        "GGAUGGGAC\n",
        "GGGGGGAGG\n",
        "GGGCGGGGG\n",
        "GAGAGUUGU\n",
        "GGGGGGGGG\n",
        "GGGGGGGGA\n",
        "GGGGGGGGG\n",
        "UGAGGGGGG\n",
        "GAGAGGGGG\n",
        "GGGAGGGGU\n",
        "CGGGGGGGU\n",
        "CCUGGGGGU\n",
        "GGGGGAGGG\n",
        "GGGGGGGGA\n",
        "AGGGGGGGA\n",
        "UGAGAGGAC\n",
        "GGGGGGGGG\n",
        "CGCGAGGGA\n",
        "GGGAGGGGG\n",
        "GGGGGGGGG\n",
        "GGGGGGGGG\n",
        "GGAGAGAGC\n",
        "UGGGGGGGA\n",
        "GGGGGUGGU\n",
        "GGGGGGGGU\n",
        "GGAGAGGGG\n",
        "GGGGGUGGG\n",
        "GGGGGGGGA\n",
        "AGGGGGGG\n",
        "GGGGGGGGG\n",
        "UGGGGGGGA\n",
        "GGGGGGGGG\n",
        "GAGGGGAC\n",
        "UCAUGGGAC\n",
        "AGGGGGGGU\n",
        "GGGGGGGGG\n",
        "UGGGGGGGU\n",
        "AGGGGAGAA\n",
        "\n",
        "Cluster id:241 size:77\n",
        "GUUUUUUUU\n",
        "UUUUUGUUU\n",
        "UUUUUUUCU\n",
        "AUUGUUUUU\n",
        "UUUUUUUUU\n",
        "UUUUUUUUC\n",
        "AUUUUUUUA\n",
        "CUCUUUUUC\n",
        "CUUCUAGUA\n",
        "GUUUCUUUG\n",
        "UUUUUUUUU\n",
        "CUCUUUUUU\n",
        "UUUUUAUUU\n",
        "UCUUUUUUU\n",
        "GUUUUUUUG\n",
        "AUCUUUUUU\n",
        "UUUUUAUUG\n",
        "UUUUUUUCU\n",
        "GUUUUUUUG\n",
        "UAUUUUUUC\n",
        "AUUUUUUUA\n",
        "UUGGUUUUU\n",
        "UUGUUUUUG\n",
        "UUUUUUUUU\n",
        "AGCUAGUAC\n",
        "UUUUUUGUU\n",
        "CUUUUUUUU\n",
        "GUUUUUCUU\n",
        "UUUUUGUUU\n",
        "UUUUUUUUG\n",
        "GUUUUUUUG\n",
        "UUUUUUUUU\n",
        "UUUUUUUUU\n",
        "UUUUUUUUU\n",
        "UUUUUUUUU\n",
        "UUUUUUUUU\n",
        "GUUUUUUUU\n",
        "UUUUUUUUU\n",
        "GUUUUGUUU\n",
        "CUUCUUUUC\n",
        "CUUUUUUUU\n",
        "UUUUUUUCU\n",
        "UUUUUUUUU\n",
        "UGUUUUUUU\n",
        "UUUGGAGGG\n",
        "UUUUUUGUC\n",
        "UUUUUUUUU\n",
        "CUUUUCUAU\n",
        "GUUUUUUUC\n",
        "GUUUUUUUG\n",
        "GCUAGUAUG\n",
        "GAGUUGUUA\n",
        "UUUUUUUUU\n",
        "GUUGUUUUC\n",
        "GAGUUGGAG\n",
        "UUUUUUUUU\n",
        "AUUUUUUUA\n",
        "UUGUUUUUU\n",
        "UUUUUGUUU\n",
        "UUUUUUUUU\n",
        "UUUGUUUUU\n",
        "UUUUUUUUU\n",
        "CUGUUUUUU\n",
        "UUUUUUUUG\n",
        "GUUUUUUUU\n",
        "UUUUUUUUU\n",
        "AUUUUUGUC\n",
        "AUAUUUUUG\n",
        "UUUUUUUUU\n",
        "UUAUUUUUU\n",
        "AUUUUUUUA\n",
        "CUCUUUUUA\n",
        "GUUGUUUUU\n",
        "GUUAUUUUC\n",
        "UUUUGUUGC\n",
        "AUUUUUUUC\n",
        "UUUUUUUUU\n",
        "\n",
        "Cluster id:154 size:73\n",
        "UCCCCCCCG\n",
        "CCCCCCCCG\n",
        "CCCCCCCCC\n",
        "CCCCGCCCC\n",
        "GCCCCCCCA\n",
        "UCCACUGUC\n",
        "CCCCCCCUC\n",
        "CACCUACCU\n",
        "UCCCCCGCC\n",
        "CCCACCCCU\n",
        "GCCCCCCCG\n",
        "GCCCCCCCA\n",
        "AGCCCCCCA\n",
        "CCCCCCCCC\n",
        "ACCCCACCU\n",
        "GCCCCCCAG\n",
        "CCAUCCCCA\n",
        "CUCCACCUA\n",
        "CCCCCACCC\n",
        "CCCCCCCCC\n",
        "CCCCCCCCC\n",
        "CCCCGCGAG\n",
        "UCCACCAAA\n",
        "CCCCCCCCC\n",
        "CCCCCCCCC\n",
        "UCCCCCCCC\n",
        "CCCCCCCCC\n",
        "GCCCCCCCC\n",
        "UCCAUAUAC\n",
        "UCCGCCCCG\n",
        "CCCCCCCCA\n",
        "CCCCCCCCC\n",
        "ACCCGCCCC\n",
        "CCCCCCCCG\n",
        "CCCACCCCA\n",
        "CCCCCCCCU\n",
        "CCCCCCCCC\n",
        "CCCCCCCCC\n",
        "UCCCCCCCC\n",
        "CCCCCCCCC\n",
        "CCCCCCCCC\n",
        "CCACCUCC\n",
        "UCCCCCUAU\n",
        "CCCCCGCCC\n",
        "ACCCGACCA\n",
        "CCCCCCCCC\n",
        "CCCCCCCCC\n",
        "CCCACCCCG\n",
        "CCCCCCCCC\n",
        "GCCCCUACA\n",
        "CCCCCCCCC\n",
        "CCCCCCCCC\n",
        "CCCCCGCCC\n",
        "GCCCCCCCC\n",
        "CCCCCCCCC\n",
        "CACAUCCAU\n",
        "UCCCCCCCG\n",
        "CCCCGCCCC\n",
        "GCCCCCCCG\n",
        "UCCCCCCCG\n",
        "CCCCCCCCC\n",
        "CCCCCCCCG\n",
        "CCCCCACCA\n",
        "AGCCCCCCG\n",
        "AGCCCCUCG\n",
        "ACCCGCCCG\n",
        "GCCCCCCCC\n",
        "CCCCCCCCC\n",
        "CCCAUGAUU\n",
        "GCCCCGAGA\n",
        "AGCCCCUCG\n",
        "CCCCCCCCC\n",
        "GCCCCGACC\n",
        "\n",
        "Cluster id:26 size:8\n",
        "CCUCCCCCC\n",
        "GCCUCCCCU\n",
        "CCCUCCCCG\n",
        "CCUCCUCCC\n",
        "CCUCCUCCC\n",
        "ACCUCCCCU\n",
        "GCUCCCCCA\n",
        "GCUCCCCCA\n",
        "\n",
        "Cluster id:30 size:16\n",
        "GCCCCCUCU\n",
        "GCCCCCUCC\n",
        "UCUCCUCCG\n",
        "CCCUCGCCC\n",
        "GCCCCUCUA\n",
        "UCCCCUCCC\n",
        "GCCCCUCCC\n",
        "CCUCUACUC\n",
        "CCCCCUCCC\n",
        "CCCCCUCCU\n",
        "CCUCCGCCC\n",
        "AGCCCCCUC\n",
        "CCCUCCCCC\n",
        "ACAUCUACA\n",
        "GCCCCUCCA\n",
        "CCCUCCUUG\n",
        "\n",
        "Cluster id:383 size:85\n",
        "AAAAAAAAA\n",
        "AAAAUAAAA\n",
        "AAAAAAAAA\n",
        "AAAAAAAAU\n",
        "AAAAAAUAG\n",
        "AAAAAAGAA\n",
        "GAAAAAAAA\n",
        "AAACAAAAA\n",
        "UUAGAAAAA\n",
        "AAAACAAAA\n",
        "AAAAAAAAA\n",
        "AUAAGAAG\n",
        "UACAUCGAC\n",
        "AAAAAAAGA\n",
        "AAAGAAAAA\n",
        "AAAUAAAAC\n",
        "AAAAAAAAA\n",
        "AAAAAAAAA\n",
        "AAAAAAAAU\n",
        "AAAUAUUUU\n",
        "AAAAGAAAA\n",
        "GAAAAGAUA\n",
        "AAAAAAAAA\n",
        "AAAAAAAAA\n",
        "AAAAAAAAA\n",
        "AAAAAAAAG\n",
        "AAAAAAAAC\n",
        "UAAAAUAAA\n",
        "GCUACAUAU\n",
        "AAAAAAAAA\n",
        "GAAAAAGAC\n",
        "AAGAAAAAA\n",
        "UAAAAAGAG\n",
        "AAAAAAAAG\n",
        "AAUACAUAC\n",
        "AAAAAAAAG\n",
        "GAAUAAAAC\n",
        "GAAAAAAAA\n",
        "CAAAAAAAU\n",
        "GAAAAAAAC\n",
        "GAAAAAAAA\n",
        "AAUACACAG\n",
        "CAAAAAAAC\n",
        "CGAGUAAAA\n",
        "UGAAAAAAC\n",
        "UAAAAAAAG\n",
        "UAAAAAAAU\n",
        "AAAAUAAAA\n",
        "AAAAAAAAU\n",
        "AAAAAAAAA\n",
        "AAAAAAAAA\n",
        "AAAGGAAAA\n",
        "AAAAAAAAA\n",
        "AAAAAAAAA\n",
        "AAAUAAAAA\n",
        "UAAAAAUAA\n",
        "AAAAAAAAA\n",
        "AAAAAAAAA\n",
        "CAAAAAACC\n",
        "AAAAAAAAA\n",
        "AAAAUAAAC\n",
        "AAAAAAAAA\n",
        "UACAUAAAA\n",
        "CCAAAAAAG\n",
        "CAAAAAGAA\n",
        "AAAACAAAA\n",
        "GAAAAAAAC\n",
        "AUAAAAAAA\n",
        "AUAAAAAAC\n",
        "UAAAAAAAA\n",
        "AAAAAAAAA\n",
        "UAAAAAAAA\n",
        "UAAACAUCU\n",
        "CAUACUACA\n",
        "AAAGAAAAU\n",
        "AAAAGAAAA\n",
        "AAAAAAAAA\n",
        "GAAAAAAAG\n",
        "GAAAAAAAG\n",
        "AAAAAAAAA\n",
        "AAAAAAAAA\n",
        "CAAAAAGGG\n",
        "CAGAAAAAC\n",
        "GAAUAAAAG\n",
        "GAAAAAAAC\n",
        "\n",
        "CPU times: user 57.6 s, sys: 3.83 s, total: 1min 1s\n",
        "Wall time: 2min 45s\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "args.update({'algo':'greedy_density','nn_algo':'LSHForest','n_neighbors':20})\n",
      "extract_and_cluster_motives(seqs,**args)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "args.update({'algo':'MiniBatchKMeans','n_clusters':8})\n",
      "extract_and_cluster_motives(seqs,**args)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "args.update({'algo':'DBSCAN','eps':0.2,'min_samples':10})\n",
      "extract_and_cluster_motives(seqs,**args)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}