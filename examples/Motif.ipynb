{
 "metadata": {
  "name": "",
  "signature": "sha256:fd9808dadbcdbeb7cdc1b66b112105734f625bc1088c7f8a9a5fdd01d950259b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Aim\n",
      "\n",
      "Given a large set of sequences or graphs with ordered vertices find small vertex ordered subsequences that are most discriminative for the set.\n",
      "\n",
      "Steps:\n",
      "- devise a negative set\n",
      "- learn a discriminative model\n",
      "- annotate importance on vertices\n",
      "- extract max subarrays \n",
      "- cluster them \n",
      " - use fast EDeN string kernel \n",
      " - LSHForest\n",
      " - custom incremental cluster"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#code for making artificial dataset\n",
      "import random\n",
      "def random_string(length,alphabet_list):\n",
      "    rand_str = ''.join(random.choice(alphabet_list) for i in range(length))\n",
      "    return rand_str\n",
      "\n",
      "def perturb(seed,alphabet_list,p=0.5):\n",
      "    seq=''\n",
      "    for c in seed:\n",
      "        if random.random() < p: c = random.choice(alphabet_list)\n",
      "        seq += c\n",
      "    return seq\n",
      "\n",
      "def make_artificial_dataset(alphabet='ACGU', motives=None, motif_length=6, sequence_length=100, n_sequences=1000, n_motives=2, p=0.2):\n",
      "    alphabet_list=[c for c in alphabet]\n",
      "    \n",
      "    if motives is None:\n",
      "        motives=[]\n",
      "        for i in range(n_motives):\n",
      "            motives.append(random_string(motif_length,alphabet_list))\n",
      "    else:\n",
      "        motif_length = len(motives[0])\n",
      "        n_motives = len(motives)\n",
      "        \n",
      "    flanking_length = (sequence_length - motif_length ) / 2\n",
      "    n_seq_per_motif = n_sequences / n_motives\n",
      "\n",
      "    counter=0\n",
      "    seqs=[]\n",
      "    for i in range(n_seq_per_motif):\n",
      "        for j in range(n_motives):\n",
      "            left_flanking = random_string(flanking_length,alphabet_list)\n",
      "            right_flanking = random_string(flanking_length,alphabet_list)\n",
      "            noisy_motif = perturb(motives[j],alphabet_list,p)\n",
      "            seq = left_flanking + noisy_motif + right_flanking\n",
      "            seqs.append(('>ID%d'%counter,seq))\n",
      "            counter += 1\n",
      "    return motives, seqs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def vectorize_sequences(seqs, vectorizer=None, negative_ratio=2):\n",
      "    #duplicate iterator\n",
      "    from itertools import tee\n",
      "    seqs,seqs_=tee(seqs)\n",
      "    #make graphs for pos\n",
      "    from eden.converter.fasta import sequence_to_eden\n",
      "    iterable_pos = sequence_to_eden(seqs)\n",
      "    #shuffle seqs to obtain negatives\n",
      "    from eden.modifier.seq import seq_to_seq, shuffle_modifier\n",
      "    seqs_neg = seq_to_seq( seqs_, modifier=shuffle_modifier, times=negative_ratio, order=2 )\n",
      "    #make graphs for negs\n",
      "    from eden.converter.fasta import sequence_to_eden\n",
      "    iterable_neg = sequence_to_eden(seqs_neg)\n",
      "    #build data matrix\n",
      "    from eden import vectorize\n",
      "    X_pos = vectorize(iterable_pos, vectorizer=vectorizer)\n",
      "    X_neg = vectorize(iterable_neg, vectorizer=vectorizer)\n",
      "    import numpy as np\n",
      "    from scipy.sparse import vstack\n",
      "    yp = [1] * X_pos.shape[0]\n",
      "    yn = [-1] * X_neg.shape[0]\n",
      "    y = np.array(yp + yn)\n",
      "    X = vstack([X_pos, X_neg], format=\"csr\")\n",
      "    return X,y\n",
      "    \n",
      "def fit_predictive_model(seqs, vectorizer=None, negative_ratio=2):\n",
      "    X,y = vectorize_sequences(seqs, vectorizer=vectorizer, negative_ratio=negative_ratio)\n",
      "    #fit predictive model\n",
      "    from sklearn.linear_model import SGDClassifier\n",
      "    estimator = SGDClassifier(average=True, class_weight='auto', shuffle=True, n_jobs=-1)\n",
      "    estimator.fit(X,y)\n",
      "    return estimator"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def serial_graph_motif(seqs, vectorizer=None, estimator=None, min_subarray_size=5, max_subarray_size=18):\n",
      "    #make graphs \n",
      "    from eden.converter.fasta import sequence_to_eden\n",
      "    iterable = sequence_to_eden(seqs)\n",
      "    #use node importance and 'position' attribute to identify max_subarrays of a specific size\n",
      "    graphs = vectorizer.annotate( iterable, estimator=estimator )\n",
      "    #use compute_max_subarrays to return an iterator over motives \n",
      "    from eden.util.iterated_maximum_subarray import compute_max_subarrays\n",
      "    motives=[]\n",
      "    for graph in graphs:\n",
      "        subarrays = compute_max_subarrays(graph=graph, min_subarray_size=min_subarray_size, max_subarray_size=max_subarray_size)\n",
      "        for subarray in subarrays:\n",
      "            motives.append(subarray['subarray_string'])\n",
      "    return motives\n",
      "\n",
      "def multiprocess_graph_motif(seqs, vectorizer=None, estimator=None, min_subarray_size=5, max_subarray_size=18, n_blocks=5, n_processes=8):\n",
      "    import multiprocessing as mp\n",
      "    size = len(seqs)\n",
      "    block_size=size/n_blocks\n",
      "    pool = mp.Pool(processes=n_processes)\n",
      "    results = [pool.apply_async(serial_graph_motif, args=(seqs[s*block_size:(s+1)*block_size],vectorizer, estimator, min_subarray_size, max_subarray_size)) for s in range(n_blocks-1)]\n",
      "    output = [p.get() for p in results]\n",
      "    import itertools \n",
      "    chain = itertools.chain(*output)\n",
      "    return list(chain)\n",
      "\n",
      "def graph_motif(seqs, vectorizer=None, estimator=None, min_subarray_size=5, max_subarray_size=18, multiprocess=True, n_blocks=5, n_processes=8):\n",
      "    if multiprocess:\n",
      "        return multiprocess_graph_motif(seqs,vectorizer=vectorizer,estimator=estimator, min_subarray_size=min_subarray_size, max_subarray_size=max_subarray_size, n_blocks=n_blocks, n_processes=n_processes)\n",
      "    else:\n",
      "        return serial_graph_motif(seqs, vectorizer=vectorizer, estimator=estimator, min_subarray_size=min_subarray_size, max_subarray_size=max_subarray_size)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "def greedy_density_cluster(density_order, indices):\n",
      "    num=len(indices)\n",
      "    instance_id_to_cluster_id_map=np.zeros((num,),'int64')\n",
      "    #init: the densest neighbourhood constitutes the first cluster\n",
      "    id = density_order[0]\n",
      "    neighbors = indices[id]\n",
      "    instance_id_to_cluster_id_map[neighbors] = id\n",
      "    for id in density_order:\n",
      "        #work only on instances that have not alrady been assigned to clusters\n",
      "        if instance_id_to_cluster_id_map[id] == 0:\n",
      "            neighbors = indices[id]\n",
      "            neighbor_cluster_ids = instance_id_to_cluster_id_map[neighbors]\n",
      "            neighbor_cluster_id_hist = np.bincount(neighbor_cluster_ids) #NOTE:replace with dict\n",
      "            cluster_id = np.argmax(neighbor_cluster_id_hist)\n",
      "            #count the max num occurrences of the cluster_id associated to each neighbor\n",
      "            cluster_count=neighbor_cluster_id_hist[cluster_id]\n",
      "            #print id, neighbors,neighbor_cluster_ids , neighbor_cluster_id_hist, cluster_id, cluster_count\n",
      "            #if we are allocating instance 0 then give it the id num = max_id+1\n",
      "            if id == 0: id = num\n",
      "            #if most of the instances are not assigned and have 0 as representative then create a new cluster\n",
      "            if cluster_id == 0: cluster_id = id\n",
      "            #give to all non-yet-cluster-associated (i.e. with clust_id=0) neighbors the cluster_id of max_count\n",
      "            #or if this corresponds to 0 then give as cluster id the id of the instance\n",
      "            mask=np.array([True if x == 0 else False for x in neighbor_cluster_ids])\n",
      "            instance_id_to_cluster_id_map[neighbors[mask]] = cluster_id    \n",
      "    return instance_id_to_cluster_id_map\n",
      "\n",
      "\n",
      "def kneighbors_greedy_density_clustering(X, n_neighbors=10, nn_algo='NearestNeighbors'):\n",
      "    if nn_algo == 'NearestNeighbors':\n",
      "        from sklearn.neighbors import NearestNeighbors\n",
      "        nn = NearestNeighbors()\n",
      "    elif nn_algo == 'LSHForest':\n",
      "        from sklearn.neighbors import LSHForest\n",
      "        nn = LSHForest()\n",
      "    else:\n",
      "        raise Exception('Unknown algorithm: %s' % nn_algo)\n",
      "    nn.fit(X)\n",
      "    distances, indices = nn.kneighbors(X, n_neighbors=n_neighbors)\n",
      "    avg_distance=[sum(distance) for distance in distances ]\n",
      "    density_order=np.argsort(avg_distance)\n",
      "    predictions = greedy_density_cluster(density_order, indices)\n",
      "    return predictions\n",
      "\n",
      "\n",
      "def cluster(seqs, complexity=3, n_neighbors=10, algo='greedy_density', nn_algo='NearestNeighbors', n_clusters=4, eps=0.3, min_samples=3):\n",
      "    from eden.path import Vectorizer\n",
      "    seq_vectorizer = Vectorizer( complexity = complexity, nbits=14)\n",
      "    from eden import vectorize\n",
      "    X = vectorize(seqs, vectorizer=seq_vectorizer)\n",
      "    if algo == 'greedy_density':\n",
      "        predictions = kneighbors_greedy_density_clustering(X,n_neighbors=n_neighbors, nn_algo=nn_algo)\n",
      "    elif algo == 'MiniBatchKMeans':\n",
      "        from sklearn.cluster import MiniBatchKMeans \n",
      "        cl = MiniBatchKMeans(n_clusters=n_clusters)\n",
      "        predictions = cl.fit_predict(X)\n",
      "    elif algo == 'DBSCAN':\n",
      "        from sklearn.cluster import DBSCAN\n",
      "        db = DBSCAN(eps=eps, min_samples=min_samples)\n",
      "        db.fit(X)\n",
      "        predictions = db.labels_\n",
      "    else:\n",
      "        raise Exception('Unknown algorithm: %s'%algo) \n",
      "    #collect instance ids per cluster id\n",
      "    from collections import defaultdict\n",
      "    clusters = defaultdict(list)\n",
      "    for i in range(len(predictions)):\n",
      "        clusters[predictions[i]]+=[i]\n",
      "    return clusters\n",
      "\n",
      "\n",
      "def graph_motif_cluster(seqs, size=100, complexity=3, negative_ratio=2, n_neighbors=10, algo='greedy_density', nn_algo='NearestNeighbors', n_clusters=4, eps=0.3, min_samples=3, min_subarray_size=9, max_subarray_size=15, verbosity=0):    \n",
      "    #init vectorizer\n",
      "    from eden.graph import Vectorizer\n",
      "    vectorizer = Vectorizer( complexity=complexity )\n",
      "    \n",
      "    from time import time\n",
      "    import random\n",
      "    start=time()\n",
      "    training_seqs = random.sample(seqs, size)\n",
      "    estimator = fit_predictive_model(training_seqs, vectorizer=vectorizer, negative_ratio=negative_ratio)\n",
      "    end=time()\n",
      "    if verbosity>0: print 'model induction: %d secs'%(end-start)\n",
      "    \n",
      "    start=time()\n",
      "    motives = graph_motif(seqs, vectorizer=vectorizer, estimator=estimator, min_subarray_size=min_subarray_size, max_subarray_size=max_subarray_size, multiprocess=True)\n",
      "    motif_list = list(motives)\n",
      "    end=time()\n",
      "    if verbosity>0: print '%d motives extraction: %d secs'%(len(motif_list), end-start)\n",
      "    \n",
      "    start=time()\n",
      "    clusters = cluster(motif_list, complexity=complexity, n_neighbors=n_neighbors, algo=algo, nn_algo=nn_algo, n_clusters=n_clusters, eps=eps, min_samples=min_samples)\n",
      "    end=time()\n",
      "    if verbosity>0: print 'clustering for %d clusters: %d secs'%(len(clusters), end-start)\n",
      "    \n",
      "    return clusters,motif_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def consensus(seqs):\n",
      "    from collections import Counter\n",
      "    cons=''\n",
      "    length =int(np.average([len(seq) for seq in seqs]))\n",
      "    for i in range(length):\n",
      "        col = []\n",
      "        for j in range(len(seqs)):\n",
      "            if len(seqs[j]) >= i:\n",
      "                col.append(seqs[j][i:i+1])\n",
      "        cons += Counter(col).most_common(1)[0][0]\n",
      "    return cons\n",
      "\n",
      "def extract_and_cluster_motives(seqs, min_motif_count=2, min_cluster_size=5, **args):\n",
      "    from collections import defaultdict\n",
      "    clustered_motives=defaultdict(list)             \n",
      "    clusters,motif_list = graph_motif_cluster(seqs,**args)\n",
      "    for cluster_id in clusters:\n",
      "        if cluster_id != -1:\n",
      "            if len(clusters[cluster_id]) > min_cluster_size:\n",
      "                clustered_seqs = []\n",
      "                for seq_ids in clusters[cluster_id]:\n",
      "                    clustered_seqs.append(motif_list[seq_ids])\n",
      "                cons = consensus(clustered_seqs)\n",
      "                for s in clustered_seqs: \n",
      "                    clustered_motives[cons].append(s)\n",
      "                    \n",
      "    #extract x motif count within a cluster\n",
      "    motives_db=defaultdict(list)   \n",
      "    #for all clusters\n",
      "    for cons in clustered_motives:\n",
      "        #consider only non identical motives\n",
      "        motif_set = set(clustered_motives[cons])\n",
      "        for motif_i in motif_set:\n",
      "            #count occurrences of motif in cluster\n",
      "            count=0\n",
      "            for motif_j in clustered_motives[cons]:\n",
      "                if motif_i == motif_j:\n",
      "                    count += 1\n",
      "            #create dict with motives and their counts\n",
      "            motives_db[cons].append((count,motif_i))\n",
      "    for cons in motives_db:\n",
      "        motives_db[cons]=sorted(motives_db[cons], reverse=True)\n",
      "    #print motives\n",
      "    for cons in motives_db:\n",
      "        print\n",
      "        print cons\n",
      "        print '-'*15\n",
      "        for count, motif in motives_db[cons]:\n",
      "            if count >= min_motif_count:\n",
      "                print motif, count\n",
      "    return motives_db "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Experimental Setup"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#setup parameters\n",
      "alphabet='ACGU'\n",
      "motives=['AAAAAAAAAA','CCCCCCCCCC','GGGGGGGGGG','UUUUUUUUUU']\n",
      "sequence_length=200\n",
      "n_sequences=1000\n",
      "p=0.3\n",
      "\n",
      "#make dataset\n",
      "motives, seqs = make_artificial_dataset(alphabet=alphabet,motives=motives,sequence_length=sequence_length,n_sequences=n_sequences,p=p)\n",
      "\n",
      "#display\n",
      "print 'Motives and sample of their perturbed variants:'\n",
      "alphabet_list=[c for c in alphabet]\n",
      "for motif in motives: \n",
      "    print\n",
      "    print motif,\n",
      "    for i in range(9):\n",
      "        print perturb(motif,alphabet_list,p=p),\n",
      "#for seq in seqs: print seq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Motives and sample of their perturbed variants:\n",
        "\n",
        "AAAAAAAAAA AAAAAACAAA CAUAAAAAAA AGAAAGGAAA AAAAAAAAAA AACAGAAUAA ACAAAUAAAA AGGAAAACAA UAAGAAAAAA ACAAAAUCUA\n",
        "CCCCCCCCCC CCGGCCCCCC CCCCCGUGCC CCCCCGCAAC CCCCCCCUCG CCCCCCCCUC CCCCCGACAA GGCCCCCCAU CCCCACCCCG CCCCGCGCCA\n",
        "GGGGGGGGGG GGGGGUGGAG GGGGUGGGGG GGGAGGGGGC GGUGGGGGGU GGGGGGUUGG GGGUGGCGGG GGGGGGGCGU GGGGGGGUGG CGUGGGGUGC\n",
        "UUUUUUUUUU UUUUUUCUUC UUUUUCUUUU UCUUUCUUUU CCUUCCUCUU CUUUUUUUUU UUUUGUUUUA UUUAUAUUUU UUUUUUGUUU UUUUUUUUUU\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#global parameters for motif and cluster extraction\n",
      "args={'size':100,\n",
      "      'complexity':4,\n",
      "      'negative_ratio':4,\n",
      "      'n_neighbors':5,\n",
      "      'algo':'greedy_density',\n",
      "      'nn_algo':'NearestNeighbors',\n",
      "      'n_clusters':4, \n",
      "      'eps':0.3, \n",
      "      'min_samples':3,\n",
      "      'min_subarray_size':9,\n",
      "      'max_subarray_size':11,\n",
      "      'verbosity':1,\n",
      "      'min_cluster_size':10, \n",
      "      'min_motif_count':2}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "args.update({'algo':'greedy_density','nn_algo':'NearestNeighbors','n_neighbors':5})\n",
      "clustered_motives=extract_and_cluster_motives(seqs, **args)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "model induction: 35 secs\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "272 motives extraction: 61 secs\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "clustering for 49 clusters: 0 secs\n",
        "\n",
        "AGGGGGGGGGG\n",
        "---------------\n",
        "AGGGGGGGGGG 5\n",
        "UGAGGGGGGGG 2\n",
        "AGGGGGAGGGU 2\n",
        "AGGGGGAGGGG 2\n",
        "\n",
        "AAAAAAAAAAA\n",
        "---------------\n",
        "\n",
        "GGGGGGGGGGG\n",
        "---------------\n",
        "GGGGGGGGGGA 4\n",
        "GGGGGGGGGGG 3\n",
        "UGGGGGGGGGG 2\n",
        "\n",
        "CCCCCCCCCCA\n",
        "---------------\n",
        "CCCCCCCCCCA 4\n",
        "\n",
        "CCCCCCCCCCC\n",
        "---------------\n",
        "CCCUCCCCCCC 3\n",
        "GCCCUCCCCCA 2\n",
        "CPU times: user 11.8 s, sys: 1.92 s, total: 13.7 s\n",
        "Wall time: 1min 37s\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "args.update({'algo':'greedy_density','nn_algo':'LSHForest','n_neighbors':5})\n",
      "clustered_motives=extract_and_cluster_motives(seqs, **args)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "model induction: 36 secs\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "290 motives extraction: 60 secs\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "clustering for 54 clusters: 1 secs\n",
        "\n",
        "UUUUUUUUUUU\n",
        "---------------\n",
        "UUUUUUUUUUU 5\n",
        "UUUUUUUUUUA 2\n",
        "\n",
        "AGGGAGGGGGA\n",
        "---------------\n",
        "\n",
        "AAAAAAAAAAA\n",
        "---------------\n",
        "AAAAAAAAAAA 5\n",
        "AAAAAAAAAAC 2\n",
        "\n",
        "CCCCCCCCCCC\n",
        "---------------\n",
        "CCCCCCCCCCC 4\n",
        "CCCUCCCCCCC 3\n",
        "CPU times: user 13.4 s, sys: 2.09 s, total: 15.5 s\n",
        "Wall time: 1min 38s\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "args.update({'algo':'MiniBatchKMeans','n_clusters':8})\n",
      "clustered_motives=extract_and_cluster_motives(seqs, **args)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "model induction: 37 secs\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "296 motives extraction: 50 secs\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "clustering for 8 clusters: 0 secs\n",
        "\n",
        "UUUUUUUUUUU\n",
        "---------------\n",
        "UUUUUUUUUUU 8\n",
        "GUUUUUUUUUC 3\n",
        "AUUUUUUUUUG 3\n",
        "AUUUUUUUUUA 3\n",
        "UUUUUUUUUUA 2\n",
        "UUUUUAUUUUU 2\n",
        "UUUAUUUUUUU 2\n",
        "AUUUUUUUUUC 2\n",
        "\n",
        "GGGGGGGGGG\n",
        "---------------\n",
        "UGGGGGGGGGG 4\n",
        "GGGGGGGGGGG 4\n",
        "GGGGGGGGGGA 3\n",
        "GGUGGGGGGGU 2\n",
        "GGGGGGGAGGG 2\n",
        "AGGGGGGGGGG 2\n",
        "\n",
        "AAAAAAAAAAA\n",
        "---------------\n",
        "AAAAAAAAAAA 6\n",
        "UAAAAAAAAAA 3\n",
        "\n",
        "CCCCCCCUGCC\n",
        "---------------\n",
        "\n",
        "UUUUUUUUUUG\n",
        "---------------\n",
        "\n",
        "CCCCCCCCCCC\n",
        "---------------\n",
        "UCCCCCCCCCC 6\n",
        "GCCCCCCCCCC 5\n",
        "ACCCCCCCCCC 5\n",
        "GCCCUCCCCCA 3\n",
        "CCCCCCCCCCC 3\n",
        "CCCCCCCCCCA 3\n",
        "UCCCCCCCUCU 2\n",
        "CCGCCCCCCCU 2\n",
        "CCCGCCCCCCC 2\n",
        "CCCCCCCGCCC 2\n",
        "ACCCCCCCCCU 2\n",
        "CPU times: user 12.8 s, sys: 2.45 s, total: 15.2 s\n",
        "Wall time: 1min 28s\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "args.update({'algo':'DBSCAN','eps':0.3,'min_samples':10})\n",
      "clustered_motives=extract_and_cluster_motives(seqs, **args)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "model induction: 33 secs\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "279 motives extraction: 48 secs\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "clustering for 5 clusters: 0 secs\n",
        "\n",
        "CCCCCCCCCC\n",
        "---------------\n",
        "CCCCCCCCCCU 6\n",
        "ACCCCCCCCCC 6\n",
        "UCCCCCCCCCC 5\n",
        "CCCCCCCUCCC 3\n",
        "CCCCCCCCCCC 3\n",
        "CCCCCCCCCCA 3\n",
        "GCACCCCCCCU 2\n",
        "CCCUCCCCCCC 2\n",
        "\n",
        "GGGGGGGGGG\n",
        "---------------\n",
        "AGGGGGGGGGG 4\n",
        "UGGGGGGGGGG 3\n",
        "UGGGGGGGUGC 2\n",
        "UGGGGGGGGGA 2\n",
        "GGUGGGGGGGU 2\n",
        "GGGUGGGGGGC 2\n",
        "GGGGGGGGGGG 2\n",
        "GGGGGGGAGGG 2\n",
        "CGGGGGGGGGC 2\n",
        "AGGGGGGGCGC 2\n",
        "\n",
        "UUUUUUUUUUU\n",
        "---------------\n",
        "UUUUUUUUUUU 7\n",
        "UUUUUAUUUUU 2\n",
        "CAUUUUUUUUU 2\n",
        "AUUUUUUUUUG 2\n",
        "\n",
        "AAAAAAAAAAA\n",
        "---------------\n",
        "AAAAAAAAAAA 5\n",
        "UAAAAAACAAA 2\n",
        "UAAAAAAAAAA 2\n",
        "AAAAAACAAAA 2\n",
        "AAAAAAAAUAA 2\n",
        "AAAAAAAAAAC 2\n",
        "CPU times: user 11.1 s, sys: 2.17 s, total: 13.2 s\n",
        "Wall time: 1min 22s\n"
       ]
      }
     ],
     "prompt_number": 12
    }
   ],
   "metadata": {}
  }
 ]
}