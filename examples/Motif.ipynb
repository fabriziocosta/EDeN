{
 "metadata": {
  "name": "",
  "signature": "sha256:ddfd2ffe3ebffd080e80a30a6bfca974c5f1c80f186015f05420f098e3cd7e1d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Aim\n",
      "\n",
      "Given a large set of sequences or graphs with ordered vertices find small vertex ordered subsequences that are most discriminative for the set.\n",
      "\n",
      "Steps:\n",
      "- devise a negative set\n",
      "- learn a discriminative model\n",
      "- annotate importance on vertices\n",
      "- extract max subarrays \n",
      "- cluster them \n",
      " - use fast EDeN string kernel \n",
      " - LSHForest\n",
      " - custom incremental cluster"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#code for making artificial dataset\n",
      "import random\n",
      "def random_string(length,alphabet_list):\n",
      "    rand_str = ''.join(random.choice(alphabet_list) for i in range(length))\n",
      "    return rand_str\n",
      "\n",
      "def perturb(seed,alphabet_list,p=0.5):\n",
      "    seq=''\n",
      "    for c in seed:\n",
      "        if random.random() < p: c = random.choice(alphabet_list)\n",
      "        seq += c\n",
      "    return seq\n",
      "\n",
      "def make_artificial_dataset(alphabet='ACGU', motives=None, motif_length=6, sequence_length=100, n_sequences=1000, n_motives=2, p=0.2):\n",
      "    alphabet_list=[c for c in alphabet]\n",
      "    \n",
      "    if motives is None:\n",
      "        motives=[]\n",
      "        for i in range(n_motives):\n",
      "            motives.append(random_string(motif_length,alphabet_list))\n",
      "    else:\n",
      "        motif_length = len(motives[0])\n",
      "        n_motives = len(motives)\n",
      "        \n",
      "    flanking_length = (sequence_length - motif_length ) / 2\n",
      "    n_seq_per_motif = n_sequences / n_motives\n",
      "\n",
      "    counter=0\n",
      "    seqs=[]\n",
      "    for i in range(n_seq_per_motif):\n",
      "        for j in range(n_motives):\n",
      "            left_flanking = random_string(flanking_length,alphabet_list)\n",
      "            right_flanking = random_string(flanking_length,alphabet_list)\n",
      "            noisy_motif = perturb(motives[j],alphabet_list,p)\n",
      "            seq = left_flanking + noisy_motif + right_flanking\n",
      "            seqs.append(('>ID%d'%counter,seq))\n",
      "            counter += 1\n",
      "    return motives, seqs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def vectorize_sequences(seqs, vectorizer=None, negative_ratio=2):\n",
      "    #duplicate iterator\n",
      "    from itertools import tee\n",
      "    seqs,seqs_=tee(seqs)\n",
      "    #make graphs for pos\n",
      "    from eden.converter.fasta import sequence_to_eden\n",
      "    iterable_pos = sequence_to_eden(seqs)\n",
      "    #shuffle seqs to obtain negatives\n",
      "    from eden.modifier.seq import seq_to_seq, shuffle_modifier\n",
      "    seqs_neg = seq_to_seq( seqs_, modifier=shuffle_modifier, times=negative_ratio, order=2 )\n",
      "    #make graphs for negs\n",
      "    from eden.converter.fasta import sequence_to_eden\n",
      "    iterable_neg = sequence_to_eden(seqs_neg)\n",
      "    #build data matrix\n",
      "    from eden import vectorize\n",
      "    X_pos = vectorize(iterable_pos, vectorizer=vectorizer)\n",
      "    X_neg = vectorize(iterable_neg, vectorizer=vectorizer)\n",
      "    import numpy as np\n",
      "    from scipy.sparse import vstack\n",
      "    yp = [1] * X_pos.shape[0]\n",
      "    yn = [-1] * X_neg.shape[0]\n",
      "    y = np.array(yp + yn)\n",
      "    X = vstack([X_pos, X_neg], format=\"csr\")\n",
      "    return X,y\n",
      "    \n",
      "def fit_predictive_model(seqs, vectorizer=None, negative_ratio=2):\n",
      "    X,y = vectorize_sequences(seqs, vectorizer=vectorizer, negative_ratio=negative_ratio)\n",
      "    #fit predictive model\n",
      "    from sklearn.linear_model import SGDClassifier\n",
      "    estimator = SGDClassifier(average=True, class_weight='auto', shuffle=True, n_jobs=-1)\n",
      "    estimator.fit(X,y)\n",
      "    return estimator"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def serial_graph_motif(seqs, vectorizer=None, estimator=None, min_subarray_size=5, max_subarray_size=18):\n",
      "    #make graphs \n",
      "    from eden.converter.fasta import sequence_to_eden\n",
      "    iterable = sequence_to_eden(seqs)\n",
      "    #use node importance and 'position' attribute to identify max_subarrays of a specific size\n",
      "    graphs = vectorizer.annotate( iterable, estimator=estimator )\n",
      "    #use compute_max_subarrays to return an iterator over motives \n",
      "    from eden.util.iterated_maximum_subarray import compute_max_subarrays\n",
      "    motives=[]\n",
      "    for graph in graphs:\n",
      "        subarrays = compute_max_subarrays(graph=graph, min_subarray_size=min_subarray_size, max_subarray_size=max_subarray_size)\n",
      "        for subarray in subarrays:\n",
      "            motives.append(subarray['subarray_string'])\n",
      "    return motives\n",
      "\n",
      "def multiprocess_graph_motif(seqs, vectorizer=None, estimator=None, min_subarray_size=5, max_subarray_size=18, n_blocks=5, n_processes=8):\n",
      "    import multiprocessing as mp\n",
      "    size = len(seqs)\n",
      "    block_size=size/n_blocks\n",
      "    pool = mp.Pool(processes=n_processes)\n",
      "    results = [pool.apply_async(serial_graph_motif, args=(seqs[s*block_size:(s+1)*block_size],vectorizer, estimator, min_subarray_size, max_subarray_size)) for s in range(n_blocks-1)]\n",
      "    output = [p.get() for p in results]\n",
      "    import itertools \n",
      "    chain = itertools.chain(*output)\n",
      "    return list(chain)\n",
      "\n",
      "def graph_motif(seqs, vectorizer=None, estimator=None, min_subarray_size=5, max_subarray_size=18, multiprocess=True, n_blocks=5, n_processes=8):\n",
      "    if multiprocess:\n",
      "        return multiprocess_graph_motif(seqs,vectorizer=vectorizer,estimator=estimator, min_subarray_size=min_subarray_size, max_subarray_size=max_subarray_size, n_blocks=n_blocks, n_processes=n_processes)\n",
      "    else:\n",
      "        return serial_graph_motif(seqs, vectorizer=vectorizer, estimator=estimator, min_subarray_size=min_subarray_size, max_subarray_size=max_subarray_size)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "def greedy_density_cluster(density_order, indices):\n",
      "    num=len(indices)\n",
      "    instance_id_to_cluster_id_map=np.zeros((num,),'int64')\n",
      "    #init: the densest neighbourhood constitutes the first cluster\n",
      "    id = density_order[0]\n",
      "    neighbors = indices[id]\n",
      "    instance_id_to_cluster_id_map[neighbors] = id\n",
      "    for id in density_order:\n",
      "        #work only on instances that have not alrady been assigned to clusters\n",
      "        if instance_id_to_cluster_id_map[id] == 0:\n",
      "            neighbors = indices[id]\n",
      "            neighbor_cluster_ids = instance_id_to_cluster_id_map[neighbors]\n",
      "            neighbor_cluster_id_hist = np.bincount(neighbor_cluster_ids) #NOTE:replace with dict\n",
      "            cluster_id = np.argmax(neighbor_cluster_id_hist)\n",
      "            #count the max num occurrences of the cluster_id associated to each neighbor\n",
      "            cluster_count=neighbor_cluster_id_hist[cluster_id]\n",
      "            #print id, neighbors,neighbor_cluster_ids , neighbor_cluster_id_hist, cluster_id, cluster_count\n",
      "            #if we are allocating instance 0 then give it the id num = max_id+1\n",
      "            if id == 0: id = num\n",
      "            #if most of the instances are not assigned and have 0 as representative then create a new cluster\n",
      "            if cluster_id == 0: cluster_id = id\n",
      "            #give to all non-yet-cluster-associated (i.e. with clust_id=0) neighbors the cluster_id of max_count\n",
      "            #or if this corresponds to 0 then give as cluster id the id of the instance\n",
      "            mask=np.array([True if x == 0 else False for x in neighbor_cluster_ids])\n",
      "            instance_id_to_cluster_id_map[neighbors[mask]] = cluster_id    \n",
      "    return instance_id_to_cluster_id_map\n",
      "\n",
      "\n",
      "def kneighbors_greedy_density_clustering(X, n_neighbors=10, nn_algo='NearestNeighbors'):\n",
      "    if nn_algo == 'NearestNeighbors':\n",
      "        from sklearn.neighbors import NearestNeighbors\n",
      "        nn = NearestNeighbors()\n",
      "    elif nn_algo == 'LSHForest':\n",
      "        from sklearn.neighbors import LSHForest\n",
      "        nn = LSHForest()\n",
      "    else:\n",
      "        raise Exception('Unknown algorithm: %s' % nn_algo)\n",
      "    nn.fit(X)\n",
      "    distances, indices = nn.kneighbors(X, n_neighbors=n_neighbors)\n",
      "    avg_distance=[sum(distance) for distance in distances ]\n",
      "    density_order=np.argsort(avg_distance)\n",
      "    predictions = greedy_density_cluster(density_order, indices)\n",
      "    return predictions\n",
      "\n",
      "\n",
      "def cluster(seqs, complexity=3, n_neighbors=10, algo='greedy_density', nn_algo='NearestNeighbors', n_clusters=4, eps=0.3, min_samples=3):\n",
      "    from eden.path import Vectorizer\n",
      "    seq_vectorizer = Vectorizer( complexity = complexity, nbits=14)\n",
      "    from eden import vectorize\n",
      "    X = vectorize(seqs, vectorizer=seq_vectorizer)\n",
      "    if algo == 'greedy_density':\n",
      "        predictions = kneighbors_greedy_density_clustering(X,n_neighbors=n_neighbors, nn_algo=nn_algo)\n",
      "    elif algo == 'MiniBatchKMeans':\n",
      "        from sklearn.cluster import MiniBatchKMeans \n",
      "        cl = MiniBatchKMeans(n_clusters=n_clusters)\n",
      "        predictions = cl.fit_predict(X)\n",
      "    elif algo == 'DBSCAN':\n",
      "        from sklearn.cluster import DBSCAN\n",
      "        db = DBSCAN(eps=eps, min_samples=min_samples)\n",
      "        db.fit(X)\n",
      "        predictions = db.labels_\n",
      "    else:\n",
      "        raise Exception('Unknown algorithm: %s'%algo) \n",
      "    #collect instance ids per cluster id\n",
      "    from collections import defaultdict\n",
      "    clusters = defaultdict(list)\n",
      "    for i in range(len(predictions)):\n",
      "        clusters[predictions[i]]+=[i]\n",
      "    return clusters\n",
      "\n",
      "\n",
      "def graph_motif_cluster(seqs, size=100, complexity=3, negative_ratio=2, n_neighbors=10, algo='greedy_density', nn_algo='NearestNeighbors', n_clusters=4, eps=0.3, min_samples=3, min_subarray_size=9, max_subarray_size=15, verbosity=0):    \n",
      "    #init vectorizer\n",
      "    from eden.graph import Vectorizer\n",
      "    vectorizer = Vectorizer( complexity=complexity )\n",
      "    \n",
      "    from time import time\n",
      "    import random\n",
      "    start=time()\n",
      "    training_seqs = random.sample(seqs, size)\n",
      "    estimator = fit_predictive_model(training_seqs, vectorizer=vectorizer, negative_ratio=negative_ratio)\n",
      "    end=time()\n",
      "    if verbosity>0: print 'model induction: %d secs'%(end-start)\n",
      "    \n",
      "    start=time()\n",
      "    motives = graph_motif(seqs, vectorizer=vectorizer, estimator=estimator, min_subarray_size=min_subarray_size, max_subarray_size=max_subarray_size, multiprocess=True)\n",
      "    motif_list = list(motives)\n",
      "    end=time()\n",
      "    if verbosity>0: print '%d motives extraction: %d secs'%(len(motif_list), end-start)\n",
      "    \n",
      "    start=time()\n",
      "    clusters = cluster(motif_list, complexity=complexity, n_neighbors=n_neighbors, algo=algo, nn_algo=nn_algo, n_clusters=n_clusters, eps=eps, min_samples=min_samples)\n",
      "    end=time()\n",
      "    if verbosity>0: print 'clustering for %d clusters: %d secs'%(len(clusters), end-start)\n",
      "    \n",
      "    return clusters,motif_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def consensus(seqs):\n",
      "    from collections import Counter\n",
      "    cons=''\n",
      "    length =int(np.average([len(seq) for seq in seqs]))\n",
      "    for i in range(length):\n",
      "        col = []\n",
      "        for j in range(len(seqs)):\n",
      "            if len(seqs[j]) >= i:\n",
      "                col.append(seqs[j][i:i+1])\n",
      "        cons += Counter(col).most_common(1)[0][0]\n",
      "    return cons\n",
      "\n",
      "def extract_and_cluster_motives(seqs, min_motif_count=2, min_cluster_size=5, **args):\n",
      "    from collections import defaultdict\n",
      "    clustered_motives=defaultdict(list)             \n",
      "    clusters,motif_list = graph_motif_cluster(seqs,**args)\n",
      "    for cluster_id in clusters:\n",
      "        if cluster_id != -1:\n",
      "            if len(clusters[cluster_id]) > min_cluster_size:\n",
      "                clustered_seqs = []\n",
      "                for seq_ids in clusters[cluster_id]:\n",
      "                    clustered_seqs.append(motif_list[seq_ids])\n",
      "                cons = consensus(clustered_seqs)\n",
      "                for s in clustered_seqs: \n",
      "                    clustered_motives[cons].append(s)\n",
      "                    \n",
      "    #extract x motif count within a cluster\n",
      "    motives_db=defaultdict(list)   \n",
      "    #for all clusters\n",
      "    for cons in clustered_motives:\n",
      "        #consider only non identical motives\n",
      "        motif_set = set(clustered_motives[cons])\n",
      "        for motif_i in motif_set:\n",
      "            #count occurrences of motif in cluster\n",
      "            count=0\n",
      "            for motif_j in clustered_motives[cons]:\n",
      "                if motif_i == motif_j:\n",
      "                    count += 1\n",
      "            #create dict with motives and their counts\n",
      "            motives_db[cons].append((count,motif_i))\n",
      "    for cons in motives_db:\n",
      "        motives_db[cons]=sorted(motives_db[cons], reverse=True)\n",
      "    #print motives\n",
      "    for cons in motives_db:\n",
      "        print\n",
      "        print cons\n",
      "        print '-'*15\n",
      "        for count, motif in motives_db[cons]:\n",
      "            if count >= min_motif_count:\n",
      "                print motif, count\n",
      "    return motives_db "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Experimental Setup"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#setup parameters\n",
      "alphabet='ACGU'\n",
      "motives=['AAAAAAAAAA','CCCCCCCCCC','GGGGGGGGGG','UUUUUUUUUU']\n",
      "sequence_length=200\n",
      "n_sequences=1000\n",
      "p=0.3\n",
      "\n",
      "#make dataset\n",
      "motives, seqs = make_artificial_dataset(alphabet=alphabet,motives=motives,sequence_length=sequence_length,n_sequences=n_sequences,p=p)\n",
      "\n",
      "#display\n",
      "print 'Motives and sample of their perturbed variants:'\n",
      "alphabet_list=[c for c in alphabet]\n",
      "for motif in motives: \n",
      "    print\n",
      "    print motif,\n",
      "    for i in range(9):\n",
      "        print perturb(motif,alphabet_list,p=p),\n",
      "#for seq in seqs: print seq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Motives and sample of their perturbed variants:\n",
        "\n",
        "AAAAAAAAAA ACAAAUAAAA UAUAAAGAUA AAUAAAAAUA ACAAUAAACA CAAAAGAAAA AAACAAAAAA AACGAAAAAA AAAACUCAAA ACAAAAGUAA\n",
        "CCCCCCCCCC CGCCCCCCAU CUCCCCCACC CCCGCCCCCA CUCUCCCCCU GCACCGCCCA CCCACCCCCC CCCCCACCAC CGCCCACCCC CCCCCACCCC\n",
        "GGGGGGGGGG GGCGCGGUGG GGCGCUGGGG GGGGCGGGCG GGGGGGGAGU CGAGGGGAUG GGUGGGAGGU GGGGGGAUUG GGCGAGGGGG GGUGGAGGGG\n",
        "UUUUUUUUUU UUUUUAUUUG AUCGUUUUAU UGUUUUUUUU AGCUUUUUUU AUUGUUAUUG UUCCUUUUUG UUUUUUUUUU UUACCUUCUA UUUUGUUUUU\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#global parameters for motif and cluster extraction\n",
      "args={'size':100,\n",
      "      'complexity':4,\n",
      "      'negative_ratio':4,\n",
      "      'n_neighbors':5,\n",
      "      'algo':'greedy_density',\n",
      "      'nn_algo':'NearestNeighbors',\n",
      "      'n_clusters':4, \n",
      "      'eps':0.3, \n",
      "      'min_samples':3,\n",
      "      'min_subarray_size':9,\n",
      "      'max_subarray_size':11,\n",
      "      'verbosity':1,\n",
      "      'min_cluster_size':10, \n",
      "      'min_motif_count':2}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "args.update({'algo':'greedy_density','nn_algo':'NearestNeighbors','n_neighbors':5})\n",
      "clustered_motives=extract_and_cluster_motives(seqs, **args)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "model induction: 29 secs\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "285 motives extraction: 44 secs\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "clustering for 64 clusters: 0 secs\n",
        "\n",
        "UUUUUUUUUUU\n",
        "---------------\n",
        "UUUUUUUUUUU 6\n",
        "UUUUUUUUUUG 2\n",
        "\n",
        "UUUUUUUUUU\n",
        "---------------\n",
        "\n",
        "AAAAAAAAAAA\n",
        "---------------\n",
        "AAAAAAAAAAA 3\n",
        "AAAAAAAAAAG 2\n",
        "CPU times: user 9.78 s, sys: 1.38 s, total: 11.2 s\n",
        "Wall time: 1min 14s\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "args.update({'algo':'greedy_density','nn_algo':'LSHForest','n_neighbors':5})\n",
      "clustered_motives=extract_and_cluster_motives(seqs, **args)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "model induction: 30 secs\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "268 motives extraction: 45 secs\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "clustering for 45 clusters: 1 secs\n",
        "\n",
        "AUUUUUUUUUU\n",
        "---------------\n",
        "AUUUUUUUUUU 3\n",
        "\n",
        "GGGGGGGGGGC\n",
        "---------------\n",
        "GGGGGGGGGGG 4\n",
        "GGGGGGGGGGC 3\n",
        "\n",
        "AGGGGGGGGGG\n",
        "---------------\n",
        "GGGAGGGGGGG 2\n",
        "\n",
        "UGGGGGGGGGG\n",
        "---------------\n",
        "UGGGGGGGGGG 6\n",
        "\n",
        "CGGGGGGGGGA\n",
        "---------------\n",
        "\n",
        "AAAAAAAAAAA\n",
        "---------------\n",
        "AAAAAAAAAAA 5\n",
        "AAAAAAAAAAG 2\n",
        "AAAAAAAAAAC 2\n",
        "\n",
        "UUUUUUUUUUA\n",
        "---------------\n",
        "CPU times: user 11.2 s, sys: 1.87 s, total: 13.1 s\n",
        "Wall time: 1min 17s\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "args.update({'algo':'MiniBatchKMeans','n_clusters':8})\n",
      "clustered_motives=extract_and_cluster_motives(seqs, **args)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-11-f89c5999eb35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu\"args.update({'algo':'MiniBatchKMeans','n_clusters':8})\\nclustered_motives=extract_and_cluster_motives(seqs, **args)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m/Library/Python/2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2160\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2162\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2163\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Library/Python/2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
        "\u001b[0;32m/Library/Python/2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Library/Python/2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m             \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
        "\u001b[0;32m<ipython-input-6-83fd35ce93ff>\u001b[0m in \u001b[0;36mextract_and_cluster_motives\u001b[0;34m(seqs, min_motif_count, min_cluster_size, **args)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mclustered_motives\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mclusters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmotif_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_motif_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcluster_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclusters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcluster_id\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-5-5c1b692665f3>\u001b[0m in \u001b[0;36mgraph_motif_cluster\u001b[0;34m(seqs, size, complexity, negative_ratio, n_neighbors, algo, nn_algo, n_clusters, eps, min_samples, min_subarray_size, max_subarray_size, verbosity)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mtraining_seqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_predictive_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_seqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnegative_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'model induction: %d secs'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-3-b0b37209ddf3>\u001b[0m in \u001b[0;36mfit_predictive_model\u001b[0;34m(seqs, vectorizer, negative_ratio)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfit_predictive_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorize_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnegative_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;31m#fit predictive model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSGDClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-3-b0b37209ddf3>\u001b[0m in \u001b[0;36mvectorize_sequences\u001b[0;34m(seqs, vectorizer, negative_ratio)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#build data matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0meden\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvectorize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mX_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mX_neg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_neg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/costa/Desktop/BTSync/Projects/EDeN/EDeN/eden/__init__.pyc\u001b[0m in \u001b[0;36mvectorize\u001b[0;34m(graphs, vectorizer, n_blocks, n_jobs)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mserial_vectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmultiprocess_vectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_blocks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_blocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/costa/Desktop/BTSync/Projects/EDeN/EDeN/eden/__init__.pyc\u001b[0m in \u001b[0;36mmultiprocess_vectorize\u001b[0;34m(graphs, vectorizer, n_blocks, n_jobs)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mintervals\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_blocks\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_blocks\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mblock_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mreminder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserial_vectorize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mintervals\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s.wait(): got it\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "args.update({'algo':'DBSCAN','eps':0.3,'min_samples':10})\n",
      "clustered_motives=extract_and_cluster_motives(seqs, **args)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}