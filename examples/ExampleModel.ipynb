{
 "metadata": {
  "name": "",
  "signature": "sha256:51e6ccdba3c007751d1e40abb2ba42e64d94bc4b15051c84549b0bc19950830d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Sequence Modeling with EDeN\n",
      "##The case for real valued vector labels\n",
      "\n",
      "**Aim:** Suppose you are given two sets of sequences. Each sequence is composed of characters in a finite alphabet. However there are similarity relationships between the characters. We want to build a predictive model that can discriminate between the two sets."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Artificial Dataset\n",
      "\n",
      "Lets build an artificial case. We construct two classes in the following way: for each class we start from a specific but random seed sequence, and the full set is then generated every time by permuting the position of k pairs of characters chosen at random in the seed sequence.\n",
      "\n",
      "To simulate the relationship between characters we do as follows: we select at random some charaters and we capitalize them. For the machine, a capitalized character is completely different from its lowercase counterpart, but it is easier for humans to see them. \n",
      "\n",
      "Assume the similarity between chars is given as a symmetric matrix. We can then perform a low dimensionality embedding of the similarity matrix (e.g. MDS in $\\mathbb{R}^4$) and obtain some vector representation for each char such that their euclidean distance is proportional to their dissimilarity. Lets assume we are already given the vector representation. In our case we just take some random vectors as they will be roughly equally distant from each other. In order to simulate that the capitalized version of a cahr should be similar to its lowercase counterpart, we just add a small amount of noise to the vector representation of one of the two.  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Auxiliary Code"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import random\n",
      "random.seed( 1 )\n",
      "\n",
      "def swap_two_characters(seq):\n",
      "    '''define a function that swaps two characters at random positions in a string '''\n",
      "    line = list(seq)\n",
      "    id_i = random.randint(0,len(line)-1)\n",
      "    id_j = random.randint(0,len(line)-1)\n",
      "    line[id_i], line[id_j] = line[id_j], line[id_i]\n",
      "    return ''.join(line)\n",
      "\n",
      "def swap_characters(seed, n):\n",
      "    seq=seed\n",
      "    for i in range(n):\n",
      "        seq = swap_two_characters(seq)\n",
      "    return seq\n",
      "    \n",
      "def make_seed(start=0, end=26):\n",
      "    seq = ''.join([str(unichr(97+i)) for i in range(start,end)])\n",
      "    return swap_characters(seq, end-start)\n",
      "    \n",
      "def make_dataset(size=None, seed=None, n_swaps=None):\n",
      "    seqs = []\n",
      "    seqs.append( seed )\n",
      "    for i in range(size):\n",
      "        seq = swap_characters( seed, n_swaps )\n",
      "        seqs.append( seq )        \n",
      "    return seqs\n",
      "\n",
      "def random_capitalize(seqs, p=0.5):\n",
      "    new_seqs=[]\n",
      "    for seq in seqs:\n",
      "        new_seq = [c.upper() if random.random() < p else c for c in seq ]\n",
      "        new_seqs.append(''.join(new_seq))\n",
      "    return new_seqs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Experimental Setup"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#problem parameters\n",
      "length = 8 #sequences length\n",
      "size = 40 #num sequences in positive and negative set\n",
      "n_swaps = 3 #num pairs of chars that are swapped at random\n",
      "n_iter_search = 40 #num paramter configurations that are evaluated in hyperparameter optimization\n",
      "complexity=2 #feature complexity for the vectorizer \n",
      "n_encodings=2 #num vector encoding schemes for chars\n",
      "encoding_vector_dimension=8 #vector dimension for char encoding"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Positive examples:'\n",
      "pos_seed = make_seed(start=0, end=length)\n",
      "print 'Seed sequence:',pos_seed\n",
      "seqs = make_dataset(size=size, seed=pos_seed, n_swaps=n_swaps)\n",
      "print 'Sample of %d sequences:'%size,seqs[:8]\n",
      "pos_seqs_orig = seqs\n",
      "train_pos_seqs_orig=seqs[:len(seqs)/2]\n",
      "test_pos_seqs_orig=seqs[len(seqs)/2:]\n",
      "seqs = random_capitalize(seqs, p=0.5)\n",
      "print 'Sample with randomly capitalization:',seqs[:8]\n",
      "pos_seqs=seqs\n",
      "train_pos_seqs=seqs[:len(seqs)/2]\n",
      "test_pos_seqs=seqs[len(seqs)/2:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Positive examples:\n",
        "Seed sequence: dgbcefah\n",
        "Sample of 40 sequences: ['dgbcefah', 'ehbcgfad', 'hdbgefac', 'dcbgefah', 'bfdcageh', 'bgdcefha', 'dgehbafc', 'gdbcefha']\n",
        "Sample with randomly capitalization: ['dGbCEfAH', 'eHBCGfAd', 'HdbGEFAc', 'DCbGeFAH', 'bfdCAgeh', 'bgDcEFHA', 'dGehbAFC', 'GdbCEfha']\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Negative examples:'\n",
      "neg_seed = make_seed(start=0, end=length)\n",
      "print 'Seed sequence:', neg_seed\n",
      "seqs = make_dataset(size=size, seed=neg_seed, n_swaps=n_swaps)\n",
      "print 'Sample of %d sequences:'%size,seqs[:8]\n",
      "neg_seqs_orig = seqs\n",
      "train_neg_seqs_orig=seqs[:len(seqs)/2]\n",
      "test_neg_seqs_orig=seqs[len(seqs)/2:]\n",
      "seqs = random_capitalize(seqs, p=0.5)\n",
      "print 'Sample with randomly capitalization:',seqs[:8]\n",
      "neg_seqs = seqs\n",
      "train_neg_seqs=seqs[:len(seqs)/2]\n",
      "test_neg_seqs=seqs[len(seqs)/2:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Negative examples:\n",
        "Seed sequence: ahcdegfb\n",
        "Sample of 40 sequences: ['ahcdegfb', 'bhedcfga', 'agcfedhb', 'ahebcdfg', 'agfdhecb', 'dghaecfb', 'hdcabgfe', 'hacdbfge']\n",
        "Sample with randomly capitalization: ['AhcdeGfb', 'bhedcFGa', 'agCFedhB', 'aHEBcDFG', 'agfdhecb', 'dgHaECfb', 'hdCabgfE', 'HacdbfgE']\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Discriminative model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#lets estimate the predictive performance of a classifier over the original sequences\n",
      "\n",
      "from eden.graph import Vectorizer\n",
      "vectorizer = Vectorizer(complexity=complexity)\n",
      "\n",
      "from eden.converter.graph.sequence import sequence_to_eden\n",
      "iterable_pos = sequence_to_eden(train_pos_seqs_orig)\n",
      "iterable_neg = sequence_to_eden(train_neg_seqs_orig)\n",
      "\n",
      "print 'Predictive performance on original sequences'\n",
      "from eden.util import  fit, estimate\n",
      "estimator = fit(iterable_pos,iterable_neg, vectorizer, n_iter_search=n_iter_search)\n",
      "\n",
      "from eden.converter.graph.sequence import sequence_to_eden\n",
      "iterable_pos = sequence_to_eden(test_pos_seqs_orig)\n",
      "iterable_neg = sequence_to_eden(test_neg_seqs_orig)\n",
      "estimate(iterable_pos, iterable_neg, estimator, vectorizer)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Predictive performance on original sequences\n",
        "Classifier:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "SGDClassifier(alpha=0.00089793527257, class_weight='auto', epsilon=0.1,\n",
        "       eta0=0.808091736922, fit_intercept=True, l1_ratio=0.15,\n",
        "       learning_rate='optimal', loss='hinge', n_iter=27, n_jobs=1,\n",
        "       penalty='l2', power_t=0.506751928278, random_state=None,\n",
        "       shuffle=True, verbose=0, warm_start=False)\n",
        "--------------------------------------------------------------------------------\n",
        "Predictive performance:\n",
        "            accuracy: 0.800 +- 0.187"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "           precision: 0.867 +- 0.208"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "              recall: 0.750 +- 0.335"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "                  f1: 0.680 +- 0.291"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "   average_precision: 0.929 +- 0.110"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "             roc_auc: 0.875 +- 0.168"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "--------------------------------------------------------------------------------\n",
        "Test set"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Instances: 42 ; Features: 1048577 with an avg of 63 features per instance\n",
        "--------------------------------------------------------------------------------\n",
        "Test Estimate\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "         -1       0.73      0.90      0.81        21\n",
        "          1       0.88      0.67      0.76        21\n",
        "\n",
        "avg / total       0.80      0.79      0.78        42\n",
        "\n",
        "APR: 0.847\n",
        "ROC: 0.855\n",
        "CPU times: user 55.5 s, sys: 2.33 s, total: 57.8 s\n",
        "Wall time: 57.9 s\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/Library/Python/2.7/site-packages/sklearn/metrics/metrics.py:1771: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
        "  'precision', 'predicted', average, warn_for)\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#lets estimate the predictive performance of a classifier over the capitalized sequences\n",
      "\n",
      "from eden.graph import Vectorizer\n",
      "vectorizer = Vectorizer(complexity=complexity)\n",
      "\n",
      "from eden.converter.graph.sequence import sequence_to_eden\n",
      "iterable_pos = sequence_to_eden(train_pos_seqs)\n",
      "iterable_neg = sequence_to_eden(train_neg_seqs)\n",
      "\n",
      "print 'Predictive performance on sequences with random capitalization'\n",
      "from eden.util import  fit\n",
      "estimator = fit(iterable_pos,iterable_neg, vectorizer, n_iter_search=n_iter_search)\n",
      "\n",
      "from eden.converter.graph.sequence import sequence_to_eden\n",
      "iterable_pos = sequence_to_eden(test_pos_seqs)\n",
      "iterable_neg = sequence_to_eden(test_neg_seqs)\n",
      "estimate(iterable_pos, iterable_neg, estimator, vectorizer)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Predictive performance on sequences with random capitalization\n",
        "Classifier:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "SGDClassifier(alpha=0.000609397158088, class_weight='auto', epsilon=0.1,\n",
        "       eta0=0.703793131779, fit_intercept=True, l1_ratio=0.15,\n",
        "       learning_rate='invscaling', loss='hinge', n_iter=49, n_jobs=1,\n",
        "       penalty='elasticnet', power_t=0.693789246092, random_state=None,\n",
        "       shuffle=True, verbose=0, warm_start=False)\n",
        "--------------------------------------------------------------------------------\n",
        "Predictive performance:\n",
        "            accuracy: 0.675 +- 0.225"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "           precision: 0.667 +- 0.236"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "              recall: 0.700 +- 0.400"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "                  f1: 0.627 +- 0.251"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "   average_precision: 0.863 +- 0.191"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "             roc_auc: 0.800 +- 0.269"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "--------------------------------------------------------------------------------\n",
        "Test set"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Instances: 42 ; Features: 1048577 with an avg of 63 features per instance\n",
        "--------------------------------------------------------------------------------\n",
        "Test Estimate\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "         -1       0.52      0.71      0.60        21\n",
        "          1       0.54      0.33      0.41        21\n",
        "\n",
        "avg / total       0.53      0.52      0.51        42\n",
        "\n",
        "APR: 0.584\n",
        "ROC: 0.565\n",
        "CPU times: user 55.1 s, sys: 3.35 s, total: 58.5 s\n",
        "Wall time: 58.6 s\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Note:** as expected the capitalization makes the predicitve task harder since it expands the vocabulary size"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Real Valued Labels"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#lets make a vector encoding for the chars simply using a random encoding \n",
      "#and a small amount of noise for the capitalized versions\n",
      "\n",
      "def make_encoding(encoding_vector_dimension=3, length=None, noise_size=0.01):\n",
      "    #vector encoding for chars\n",
      "    default_encoding = [0]*encoding_vector_dimension\n",
      "    start=0\n",
      "    end=length\n",
      "    #take a list of all chars up to 'length' \n",
      "    char_list = [str(unichr(97+i)) for i in range(start,end)]\n",
      "\n",
      "    encodings={}\n",
      "    import numpy as np\n",
      "    codes = np.random.rand(len(char_list),encoding_vector_dimension)\n",
      "    for i, code in enumerate(codes):\n",
      "        c = str(unichr(97+i))\n",
      "        cc = c.upper()\n",
      "        encoding = list(code)\n",
      "        encodings[c] = encoding\n",
      "        #add noise for the encoding of capitalized chars\n",
      "        noise = np.random.rand(encoding_vector_dimension)*noise_size\n",
      "        encodings[cc] = list(code + noise)\n",
      "    return encodings, default_encoding\n",
      "\n",
      "\n",
      "#we can generate a few encodings and let the algorithm choose the best one.\n",
      "encodings=[]\n",
      "for i in range(n_encodings):\n",
      "    encoding, default_encoding = make_encoding(encoding_vector_dimension=encoding_vector_dimension, \n",
      "                                               length=length, noise_size=0.02*i)\n",
      "    encodings.append(encoding)\n",
      "#print encodings"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#lets define the 3 main machines: 1) pre_processor, 2) vectorizer, 3) estimator\n",
      "\n",
      "def pre_processor( seqs, encoding=None, default_encoding=None, **args ):\n",
      "    #convert sequences to path graphs\n",
      "    from eden.converter.graph.sequence import sequence_to_eden\n",
      "    graphs = sequence_to_eden(seqs)\n",
      "    \n",
      "    #relabel nodes with corresponding vector encoding\n",
      "    from eden.modifier.graph.vertex_attributes import translate \n",
      "    graphs = translate(graphs, label_map = encoding, default = default_encoding)\n",
      "    \n",
      "    return graphs  \n",
      "\n",
      "from eden.graph import Vectorizer\n",
      "vectorizer = Vectorizer()\n",
      "\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "estimator = SGDClassifier(class_weight='auto', shuffle=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Auto Optimizing Model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#make predictive model\n",
      "from eden.model import ActiveLearningBinaryClassificationModel\n",
      "model = ActiveLearningBinaryClassificationModel( pre_processor, estimator=estimator, vectorizer=vectorizer )\n",
      "\n",
      "#optimize hyperparameters and fit a predictive model\n",
      "n_iter=n_iter_search\n",
      "\n",
      "from numpy.random import randint\n",
      "from numpy.random import uniform\n",
      "\n",
      "pre_processor_parameters={'encoding':encodings, 'default_encoding':[default_encoding]}\n",
      "\n",
      "vectorizer_parameters={'complexity':[complexity],\n",
      "                       'discretization_size':randint(3, 100, size=n_iter), \n",
      "                       'discretization_dimension':randint(3, 50, size=n_iter)}\n",
      "\n",
      "estimator_parameters={'n_iter':randint(5, 100, size=n_iter),\n",
      "                      'penalty':['l1','l2','elasticnet'],\n",
      "                      'l1_ratio':uniform(0.1,0.9, size=n_iter), \n",
      "                      'loss':['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
      "                      'power_t':uniform(0.1, size=n_iter),\n",
      "                      'alpha': [10**x for x in range(-8,0)],\n",
      "                      'eta0': [10**x for x in range(-4,-1)],\n",
      "                      'learning_rate': [\"invscaling\", \"constant\", \"optimal\"]}\n",
      "\n",
      "model.optimize(train_pos_seqs, train_neg_seqs,\n",
      "               model_name='my_seq.model', \n",
      "               fit_vectorizer=True, \n",
      "               n_active_learning_iterations=0,\n",
      "               n_iter=n_iter, cv=3, verbose=1,\n",
      "               pre_processor_parameters=pre_processor_parameters, \n",
      "               vectorizer_parameters=vectorizer_parameters, \n",
      "               estimator_parameters=estimator_parameters)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration: 1/40 (at 7.7 sec; 0:00:07.728927)\n",
        "Best score (roc_auc): 0.881066 (0.931973 +- 0.050907)\n",
        "Instances: 40 ; Features: 1048577 with an avg of 1241 features per instance\n",
        "class: 1 count:20 (0.50)\tclass: -1 count:20 (0.50)\t\n",
        "CPU times: user 4min 22s, sys: 1.84 s, total: 4min 23s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Wall time: 4min 24s\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "model.print_model_parameter_configuration()\n",
      "apr, roc = model.estimate(test_pos_seqs, test_neg_seqs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "--------------------------------------------------------------------------------\n",
        "Current parameters:\n",
        "Pre_processor:\n",
        "{'default_encoding': [0, 0, 0, 0, 0, 0, 0, 0],\n",
        " 'encoding': {'A': [0.93628571904322777,\n",
        "                    0.85733417633509335,\n",
        "                    0.92186906999834617,\n",
        "                    0.93257422724408101,\n",
        "                    0.063877130651453506,\n",
        "                    0.78880305855813471,\n",
        "                    0.74312104609086238,\n",
        "                    0.47041062656567878],\n",
        "              'B': [0.24637235622905107,\n",
        "                    0.59070542159195383,\n",
        "                    0.18524368906781408,\n",
        "                    0.82624082608279514,\n",
        "                    0.82673851672943321,\n",
        "                    0.05937769751957378,\n",
        "                    0.98494262406563271,\n",
        "                    0.85392954116444464],\n",
        "              'C': [0.050561755203529568,\n",
        "                    0.48987594407099522,\n",
        "                    0.20905580752950459,\n",
        "                    0.90910183000908462,\n",
        "                    0.84858335706703603,\n",
        "                    0.26600661917556789,\n",
        "                    0.24859359115286439,\n",
        "                    0.53732650524606718],\n",
        "              'D': [0.4273772360009116,\n",
        "                    0.062098603611619674,\n",
        "                    0.89647030534694283,\n",
        "                    0.53571502761059786,\n",
        "                    0.82705478925524323,\n",
        "                    0.37019571391882988,\n",
        "                    0.36025724257442437,\n",
        "                    0.85911673553828172],\n",
        "              'E': [0.18897245852932043,\n",
        "                    0.22328116148321897,\n",
        "                    0.70506516162496569,\n",
        "                    0.98729097423745693,\n",
        "                    0.48994909826723221,\n",
        "                    0.059738942033723208,\n",
        "                    0.70332606482797544,\n",
        "                    0.30881696577526396],\n",
        "              'F': [0.34627466242120897,\n",
        "                    0.20258194674347085,\n",
        "                    0.77525008971348475,\n",
        "                    0.28115759370685744,\n",
        "                    0.86982657671460606,\n",
        "                    0.051130945778175896,\n",
        "                    0.031416627818125709,\n",
        "                    0.54629841311586003],\n",
        "              'G': [0.99904435791807822,\n",
        "                    0.95175508672243159,\n",
        "                    0.087870713939808165,\n",
        "                    0.87328281181833722,\n",
        "                    0.76020504320731364,\n",
        "                    0.5993311757247719,\n",
        "                    0.084936800940194179,\n",
        "                    0.5490796247713734],\n",
        "              'H': [0.81530548115248525,\n",
        "                    0.97850990861224296,\n",
        "                    0.85775284856109935,\n",
        "                    0.32058104128620712,\n",
        "                    0.3298881008275294,\n",
        "                    0.71515260640826439,\n",
        "                    0.0037187946497870827,\n",
        "                    0.32599679915609192],\n",
        "              'a': [0.93628571904322777,\n",
        "                    0.85733417633509335,\n",
        "                    0.92186906999834617,\n",
        "                    0.93257422724408101,\n",
        "                    0.063877130651453506,\n",
        "                    0.78880305855813471,\n",
        "                    0.74312104609086238,\n",
        "                    0.47041062656567878],\n",
        "              'b': [0.24637235622905107,\n",
        "                    0.59070542159195383,\n",
        "                    0.18524368906781408,\n",
        "                    0.82624082608279514,\n",
        "                    0.82673851672943321,\n",
        "                    0.05937769751957378,\n",
        "                    0.98494262406563271,\n",
        "                    0.85392954116444464],\n",
        "              'c': [0.050561755203529568,\n",
        "                    0.48987594407099522,\n",
        "                    0.20905580752950459,\n",
        "                    0.90910183000908462,\n",
        "                    0.84858335706703603,\n",
        "                    0.26600661917556789,\n",
        "                    0.24859359115286439,\n",
        "                    0.53732650524606718],\n",
        "              'd': [0.4273772360009116,\n",
        "                    0.062098603611619674,\n",
        "                    0.89647030534694283,\n",
        "                    0.53571502761059786,\n",
        "                    0.82705478925524323,\n",
        "                    0.37019571391882988,\n",
        "                    0.36025724257442437,\n",
        "                    0.85911673553828172],\n",
        "              'e': [0.18897245852932043,\n",
        "                    0.22328116148321897,\n",
        "                    0.70506516162496569,\n",
        "                    0.98729097423745693,\n",
        "                    0.48994909826723221,\n",
        "                    0.059738942033723208,\n",
        "                    0.70332606482797544,\n",
        "                    0.30881696577526396],\n",
        "              'f': [0.34627466242120897,\n",
        "                    0.20258194674347085,\n",
        "                    0.77525008971348475,\n",
        "                    0.28115759370685744,\n",
        "                    0.86982657671460606,\n",
        "                    0.051130945778175896,\n",
        "                    0.031416627818125709,\n",
        "                    0.54629841311586003],\n",
        "              'g': [0.99904435791807822,\n",
        "                    0.95175508672243159,\n",
        "                    0.087870713939808165,\n",
        "                    0.87328281181833722,\n",
        "                    0.76020504320731364,\n",
        "                    0.5993311757247719,\n",
        "                    0.084936800940194179,\n",
        "                    0.5490796247713734],\n",
        "              'h': [0.81530548115248525,\n",
        "                    0.97850990861224296,\n",
        "                    0.85775284856109935,\n",
        "                    0.32058104128620712,\n",
        "                    0.3298881008275294,\n",
        "                    0.71515260640826439,\n",
        "                    0.0037187946497870827,\n",
        "                    0.32599679915609192]}}\n",
        "Vectorizer:\n",
        "{'complexity': 2, 'discretization_dimension': 27, 'discretization_size': 80}\n",
        "Estimator:\n",
        "{'alpha': 0.01,\n",
        " 'eta0': 0.001,\n",
        " 'l1_ratio': 0.73518066222750189,\n",
        " 'learning_rate': 'optimal',\n",
        " 'loss': 'modified_huber',\n",
        " 'n_iter': 55,\n",
        " 'penalty': 'l1',\n",
        " 'power_t': 0.12979351444827941}\n",
        "--------------------------------------------------------------------------------\n",
        "Classifier:\n",
        "SGDClassifier(alpha=0.01, class_weight='auto', epsilon=0.1, eta0=0.001,\n",
        "       fit_intercept=True, l1_ratio=0.73518066222750189,\n",
        "       learning_rate='optimal', loss='modified_huber', n_iter=55, n_jobs=1,\n",
        "       penalty='l1', power_t=0.12979351444827941, random_state=None,\n",
        "       shuffle=True, verbose=0, warm_start=False)\n",
        "--------------------------------------------------------------------------------\n",
        "Instances: 42 ; Features: 1048577 with an avg of 1244 features per instance"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "--------------------------------------------------------------------------------\n",
        "Test Estimate\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "         -1       0.76      0.76      0.76        21\n",
        "          1       0.76      0.76      0.76        21\n",
        "\n",
        "avg / total       0.76      0.76      0.76        42\n",
        "\n",
        "APR: 0.829\n",
        "ROC: 0.791\n",
        "--------------------------------------------------------------------------------\n",
        "CPU times: user 6.95 s, sys: 21 ms, total: 6.97 s\n",
        "Wall time: 6.99 s\n"
       ]
      }
     ],
     "prompt_number": 10
    }
   ],
   "metadata": {}
  }
 ]
}