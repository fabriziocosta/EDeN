{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from eden.converter.molecule import obabel\n",
    "import networkx as nx\n",
    "import pybel\n",
    "import requests\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Define functions to obtain data from server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_compounds(fname, size, listkey):\n",
    "    PROLOG='https://pubchem.ncbi.nlm.nih.gov/rest/pug/'\n",
    "    with open(fname,'w') as file_handle:\n",
    "        stepsize=50\n",
    "        index_start=0\n",
    "        for chunk, index_end in enumerate(range(0,size+stepsize,stepsize)):\n",
    "            if index_end is not 0 :\n",
    "                print 'Chunk %s) Processing compounds %s to %s (of a total of %s)' % (chunk, index_start, index_end-1, size)\n",
    "                RESTQ = PROLOG + 'compound/listkey/' + str(listkey) + '/SDF?&listkey_start=' + str(index_start) + '&listkey_count=' + str(stepsize)\n",
    "                reply=requests.get(RESTQ)\n",
    "                file_handle.write(reply.text)\n",
    "            index_start = index_end\n",
    "        print 'compounds available in file: ', fname\n",
    "\n",
    "\n",
    "def get_assay(assay_id):\n",
    "    PROLOG='https://pubchem.ncbi.nlm.nih.gov/rest/pug/'\n",
    "    AID=str(assay_id)\n",
    "    #active\n",
    "    RESTQ = PROLOG + 'assay/aid/' + AID + '/cids/JSON?cids_type=active&list_return=listkey'\n",
    "    reply=requests.get(RESTQ)\n",
    "    #extract the listkey\n",
    "    active_listkey = reply.json()['IdentifierList']['ListKey']\n",
    "    active_size = reply.json()['IdentifierList']['Size'] \n",
    "    active_fname = 'data/AID'+AID+'_active.smiles'\n",
    "    get_compounds(fname=active_fname, size=active_size, listkey=active_listkey)\n",
    "\n",
    "    #inactive\n",
    "    RESTQ = PROLOG + 'assay/aid/' + AID + '/cids/JSON?cids_type=inactive&list_return=listkey'\n",
    "    reply=requests.get(RESTQ)\n",
    "    #extract the listkey\n",
    "    inactive_listkey = reply.json()['IdentifierList']['ListKey']\n",
    "    inactive_size = reply.json()['IdentifierList']['Size']\n",
    "    inactive_fname = 'data/AID'+AID+'_inactive.smiles'\n",
    "    get_compounds(fname=inactive_fname, size=inactive_size, listkey=inactive_listkey)\n",
    "\n",
    "    return (active_fname,inactive_fname)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Get the data from PubChem server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 9.78 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#AID=720532\n",
    "AID=825\n",
    "READ_FROM_FILE=True\n",
    "DATA_DIR = 'data'\n",
    "if READ_FROM_FILE:\n",
    "    active_fname=DATA_DIR + '/AID%s_active.smiles'%AID\n",
    "    inactive_fname=DATA_DIR + '/AID%s_inactive.smiles'%AID\n",
    "else:\n",
    "    active_fname, inactive_fname = get_assay(AID)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate conformers for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 µs, sys: 6 µs, total: 14 µs\n",
      "Wall time: 13.1 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if 0:\n",
    "    # Active compounds\n",
    "    if not os.path.exists(DATA_DIR + '/conf_AID%s_active.sdf'%AID):\n",
    "        active_conf = DATA_DIR + '/conf_AID%s_active.sdf'%AID\n",
    "        obabel.generate_conformers(active_fname, active_conf, 10, 'rmsd')\n",
    "    # Inactive compounds\n",
    "    if not os.path.exists(DATA_DIR + '/conf_AID%s_inactive.sdf'%AID):\n",
    "        inactive_conf = DATA_DIR + '/conf_AID%s_inactive.sdf'%AID\n",
    "        obabel.generate_conformers(inactive_fname, inactive_conf, 10, 'rmsd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_iterable(filename):\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            yield line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for training and testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime, time\n",
    "def train_obabel_model(iterable_pos, iterable_neg, model_type = \"default\",\n",
    "                       model_fname=None, n_iter=40, active_set_size=1000, \n",
    "                       n_active_learning_iterations=3, threshold=1, train_test_split=0.7, \n",
    "                       verbose=False):\n",
    "    \n",
    "    from numpy.random import randint\n",
    "    from numpy.random import uniform\n",
    "    \n",
    "    # this will be passed as an argument to the model later on\n",
    "    def pre_processor(data, **args):\n",
    "        from eden.converter.molecule import obabel\n",
    "        iterable = obabel.obabel_to_eden(data, **args)\n",
    "        return iterable\n",
    "    \n",
    "    from eden.graph import Vectorizer\n",
    "    #vectorizer_parameters={'complexity':[1,2,3,4],\n",
    "    #                       'discretization_size':randint(3, 100,size=n_iter),\n",
    "    #                       'discretization_dimension':randint(3, 50, size=n_iter)}\n",
    "    #vectorizer_parameters={'complexity':[1,2,3,4],\n",
    "    #                       'discretization_size':3,\n",
    "     #                      'discretization_dimension':3}\n",
    "    vectorizer = Vectorizer()\n",
    "\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "    estimator = SGDClassifier(class_weight='auto', shuffle=True)\n",
    "\n",
    "    #create iterable from files\n",
    "    '''\n",
    "    from eden.converter.molecule import obabel\n",
    "    if model_type == \"default\":\n",
    "        iterable_pos=obabel.obabel_to_eden(pos_fname)\n",
    "        iterable_neg=obabel.obabel_to_eden(neg_fname)\n",
    "    elif model_type == \"3d\":\n",
    "        iterable_pos=obabel.obabel_to_eden3d(pos_fname)\n",
    "        iterable_neg=obabel.obabel_to_eden3d(neg_fname)\n",
    "    '''\n",
    "    \n",
    "    from itertools import tee\n",
    "    iterable_pos, iterable_pos_ = tee(iterable_pos)\n",
    "    iterable_neg, iterable_neg_ = tee(iterable_neg)\n",
    "    \n",
    "    import time\n",
    "    start = time.time()\n",
    "    print('# positives: %d  # negatives: %d (%.1f sec %s)'%(sum(1 for x in iterable_pos_), sum(1 for x in iterable_neg_), time.time() - start, str(datetime.timedelta(seconds=(time.time() - start)))))\n",
    "    \n",
    "    iterable_pos, iterable_pos_ = tee(iterable_pos)\n",
    "    iterable_neg, iterable_neg_ = tee(iterable_neg)\n",
    "    \n",
    "    #split train/test\n",
    "    from eden.util import random_bipartition_iter\n",
    "    iterable_pos_train, iterable_pos_test = random_bipartition_iter(iterable_pos, relative_size=train_test_split)\n",
    "    iterable_neg_train, iterable_neg_test = random_bipartition_iter(iterable_neg, relative_size=train_test_split)\n",
    "\n",
    "\n",
    "\n",
    "    #make predictive model\n",
    "    from eden.model import ActiveLearningBinaryClassificationModel\n",
    "    model = ActiveLearningBinaryClassificationModel( pre_processor, estimator=estimator, vectorizer=vectorizer )\n",
    "\n",
    "    #optimize hyperparameters and fit model\n",
    "\n",
    "    pre_processor_parameters={'mode':['3d'], 'knn':randint(1, 10,size=n_iter)} \n",
    "\n",
    "    vectorizer_parameters={'complexity':[2,3,4],  \n",
    "                           'discretization_size':randint(3, 100,size=n_iter),                     \n",
    "                           'discretization_dimension':randint(3, 100,size=n_iter)}\n",
    "    \n",
    "    estimator_parameters={'n_iter':randint(5, 100, size=n_iter),\n",
    "                          'penalty':['l1','l2','elasticnet'],\n",
    "                          'l1_ratio':uniform(0.1,0.9, size=n_iter), \n",
    "                          'loss':['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "                          'power_t':uniform(0.1, size=n_iter),\n",
    "                          'alpha': [10**x for x in range(-8,-2)],\n",
    "                          'eta0': [10**x for x in range(-4,-1)],\n",
    "                          'learning_rate': [\"invscaling\", \"constant\", \"optimal\"]}\n",
    "\n",
    "    model.optimize(iterable_pos_train, iterable_neg_train, \n",
    "                   model_name=model_fname,\n",
    "                   fit_vectorizer=True,\n",
    "                   n_active_learning_iterations=n_active_learning_iterations,\n",
    "                   size_positive=-1,\n",
    "                   size_negative=active_set_size,\n",
    "                   n_iter=n_iter, cv=3, n_jobs=1, verbose=verbose,\n",
    "                   pre_processor_parameters=pre_processor_parameters, \n",
    "                   vectorizer_parameters=vectorizer_parameters, \n",
    "                   estimator_parameters=estimator_parameters)\n",
    "  \n",
    "    #estimate predictive performance\n",
    "    #model.estimate( iterable_pos_test, iterable_neg_test, cv=5 )\n",
    "    # Had to change this call, estimate has no cv parameter\n",
    "    model.estimate( iterable_pos_test, iterable_neg_test )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def test_obabel_model(fname, model_type = \"default\", model_fname=None):\n",
    "    from eden.model import ActiveLearningBinaryClassificationModel\n",
    "\n",
    "    model = ActiveLearningBinaryClassificationModel()\n",
    "    model.load(model_fname)\n",
    "\n",
    "    #create iterable from files\n",
    "    from eden.converter.molecule import obabel\n",
    "    if model_type == \"default\":\n",
    "        iterable=obabel.obabel_to_eden(fname)\n",
    "    elif model_type == \"3d\":\n",
    "        iterable=obabel.obabel_to_eden3d(fname)\n",
    "    \n",
    "    predictions= model.decision_function( iterable )\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3D model**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# positives: 48  # negatives: 50 (9.0 sec 0:00:09.016883)\n",
      "\n",
      "Iteration: 1/40 (at 228.3 sec; 0:03:48.251326)\n",
      "Best score (roc_auc): 0.522859 (0.614005 +- 0.091145)\n",
      "Instances: 49 ; Features: 1048577 with an avg of 19401 features per instance\n",
      "class: 1 count:24 (0.49)\tclass: -1 count:25 (0.51)\t\n",
      "\n",
      "Iteration: 2/40 (at 376.0 sec; 0:06:16.000950)\n",
      "Best score (roc_auc): 0.583875 (0.647569 +- 0.063694)\n",
      "Instances: 49 ; Features: 1048577 with an avg of 12709 features per instance\n",
      "class: 1 count:24 (0.49)\tclass: -1 count:25 (0.51)\t\n",
      "\n",
      "Failed iteration: 4/40 (at 605.5 sec; 0:10:05.536730)\n",
      "Inappropriate argument value (of correct type).\n",
      "Floating-point under-/overflow occurred at epoch #10. Scaling input data with StandardScaler or MinMaxScaler might help.\n",
      "\n",
      "Iteration: 5/40 (at 1127.2 sec; 0:18:47.188618)\n",
      "Best score (roc_auc): 0.616265 (0.671875 +- 0.055610)\n",
      "Instances: 49 ; Features: 1048577 with an avg of 99462 features per instance\n",
      "class: 1 count:24 (0.49)\tclass: -1 count:25 (0.51)\t\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-85701b3ca6a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                            \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                            \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                            verbose=1)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-9fce7f80ae42>\u001b[0m in \u001b[0;36mtrain_obabel_model\u001b[0;34m(pos_fname, neg_fname, model_type, model_fname, n_iter, active_set_size, n_active_learning_iterations, threshold, train_test_split, verbose)\u001b[0m\n\u001b[1;32m     82\u001b[0m                    \u001b[0mpre_processor_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_processor_parameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                    \u001b[0mvectorizer_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectorizer_parameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                    estimator_parameters=estimator_parameters)\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m#estimate predictive performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jl/anaconda/lib/python2.7/site-packages/eden/model.pyc\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, iterable_pos, iterable_neg, model_name, n_active_learning_iterations, size_positive, size_negative, lower_bound_threshold_positive, upper_bound_threshold_positive, lower_bound_threshold_negative, upper_bound_threshold_negative, n_iter, fit_vectorizer, pre_processor_parameters, vectorizer_parameters, estimator_parameters, verbose, n_jobs, cv, scoring)\u001b[0m\n\u001b[1;32m    222\u001b[0m                     \u001b[0miterable_neg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable_neg_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtee\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_neg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mn_active_learning_iterations\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# if no active learning mode, just produce data matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_matrices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_pos_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable_neg_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_vectorizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_vectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# otherwise use the active learning strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                         X, y = self._active_learning_data_matrices(iterable_pos_, iterable_neg_,\n",
      "\u001b[0;32m/Users/jl/anaconda/lib/python2.7/site-packages/eden/model.pyc\u001b[0m in \u001b[0;36m_data_matrices\u001b[0;34m(self, iterable_pos, iterable_neg, fit_vectorizer, n_jobs)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mXpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0miterator_neg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_neg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_processor_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mXneg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator_neg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assemble_data_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXneg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jl/anaconda/lib/python2.7/site-packages/eden/graph.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, graphs, n_jobs, block_size)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mblock_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mG_block_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jl/anaconda/lib/python2.7/site-packages/eden/graph.py\u001b[0m in \u001b[0;36m_transform_block\u001b[0;34m(self, graphs, n_jobs)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_transform_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_serial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jl/anaconda/lib/python2.7/site-packages/eden/graph.py\u001b[0m in \u001b[0;36m_transform_serial\u001b[0;34m(self, graphs)\u001b[0m\n\u001b[1;32m    274\u001b[0m             raise Exception(\n\u001b[1;32m    275\u001b[0m                 'ERROR: something went wrong, no graphs are present in current iterator.')\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_dict_to_sparse_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jl/anaconda/lib/python2.7/site-packages/eden/graph.py\u001b[0m in \u001b[0;36m_convert_dict_to_sparse_matrix\u001b[0;34m(self, feature_dict)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "pos_iterator=make_iterable(active_fname) #this is a SMILES file \n",
    "neg_iterator=make_iterable(inactive_fname) #this is a SMILES file \n",
    "model_fname='AID%s.model3d'%AID\n",
    "model = train_obabel_model(pos_iterator, neg_iterator,\n",
    "                           model_type = \"3d\",\n",
    "                           model_fname=model_fname,\n",
    "                           n_iter=40, \n",
    "                           active_set_size=500, \n",
    "                           n_active_learning_iterations=0, \n",
    "                           threshold=1, \n",
    "                           train_test_split=0.5, \n",
    "                           verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Original model**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model_fname='AID%s.modeld'%AID\n",
    "model = train_obabel_model(active_fname, inactive_fname,\n",
    "                           model_type = \"default\",\n",
    "                           model_fname=model_fname,\n",
    "                           n_iter=40, \n",
    "                           active_set_size=500, \n",
    "                           n_active_learning_iterations=0, \n",
    "                           threshold=1, \n",
    "                           train_test_split=0.8, \n",
    "                           verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Test the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from eden.util.display import draw_graph\n",
    "from itertools import islice\n",
    "\n",
    "for G in islice(iterable_pos, 3):\n",
    "    draw_graph(G, vertex_label=\"atom_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
